<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Rust Algorithm Club</title>
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="Learn algorithms and data structures with Rust">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" rel="stylesheet" type="text/css">
        <link href="https://fonts.googleapis.com/css?family=Source+Code+Pro:500" rel="stylesheet" type="text/css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        

        
        <!-- MathJax -->
        <script type="text/x-mathjax-config">
          MathJax.Hub.Config({
            tex2jax: {
              inlineMath: [['$','$']],
            },
          });
        </script>
        <script async type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_SVG"></script>
        
    </head>
    <body class="light">
        <!-- Provide site root to javascript -->
        <script type="text/javascript">var path_to_root = "";</script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = 'light'; }
            document.body.className = theme;
            document.querySelector('html').className = theme + ' js';
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <ol class="chapter"><li class="affix"><a href="index.html">Rust Algorithm Club</a></li><li class="spacer"></li><li><a href="concepts/index.html">基礎概念</a></li><li><ol class="section"><li><a href="concepts/asymptotic-notation/index.html">漸進符號 Asymptotic Notation</a></li></ol></li><li><a href="searching/index.html">搜尋</a></li><li><ol class="section"><li><a href="searching/linear_search/index.html">線性搜尋 Linear search</a></li><li><a href="searching/binary_search/index.html">二元搜尋 Binary search</a></li><li><a href="searching/interpolation_search/index.html">🚧 內插搜尋 Interpolation search</a></li><li><a href="searching/exponential_search/index.html">指數搜尋 Exponential search</a></li></ol></li><li><a href="sorting/index.html">排序</a></li><li><ol class="section"><li><a href="sorting/simple-sorts.html">簡單排序</a></li><li><ol class="section"><li><a href="sorting/insertion_sort/index.html">插入排序 Insertion sort</a></li><li><a href="sorting/selection_sort/index.html">選擇排序 Selection sort</a></li><li><a href="sorting/bubble_sort/index.html">氣泡排序 Bubble sort</a></li><li><a href="sorting/shellsort/index.html">希爾排序 Shellsort</a></li></ol></li><li><a href="sorting/efficient-sorts.html">高效排序</a></li><li><ol class="section"><li><a href="sorting/heapsort/index.html">堆積排序 Heapsort</a></li><li><a href="sorting/quicksort/index.html">快速排序 Quicksort</a></li><li><a href="sorting/mergesort/index.html">合併排序 Mergesort</a></li></ol></li><li><a href="sorting/hybrid-sorts.html">混合排序</a></li><li><ol class="section"><li><a href="sorting/introsort/index.html">🚧 內省排序 Introsort</a></li><li><a href="sorting/timsort/index.html">🚧 自適應合併排序 Timsort</a></li><li><a href="sorting/pdqsort/index.html">🚧 模式消除快速排序 Pdqsort</a></li></ol></li><li><a href="sorting/special-purpose-sorts.html">特殊排序</a></li><li><ol class="section"><li><a href="sorting/counting_sort/index.html">計數排序 Counting sort</a></li><li><a href="sorting/bucket_sort/index.html">桶排序 Bucket sort</a></li><li><a href="sorting/radix_sort/index.html">基數排序 Radix sort</a></li></ol></li></ol></li><li><a href="collections/index.html">資料結構</a></li><li><ol class="section"><li><a href="collections/stack-queue.html">🚧 堆疊與佇列</a></li><li><ol class="section"><li><a href="collections/stack/index.html">🚧 堆疊 Stack</a></li><li><a href="collections/queue/index.html">🚧 佇列 Queue</a></li><li><a href="collections/deque/index.html">🚧 雙端佇列 Deque</a></li></ol></li><li><a href="collections/linked_list/index.html">鏈結串列</a></li><li><ol class="section"><li><a href="collections/singly_linked_list/index.html">單向鏈結串列 Singly linked list</a></li><li><a href="collections/doubly_linked_list/index.html">🚧 雙向鏈結串列 Doubly linked list</a></li><li><a href="collections/circular_linked_list/index.html">🚧 循環鏈結串列 Circular linked list</a></li></ol></li><li><a href="collections/associative-container/index.html">關聯容器</a></li><li><ol class="section"><li><a href="collections/hash_map/index.html">雜湊表 Hash map</a></li><li><a href="collections/ordered_map/index.html">🚧 有序映射表 Ordered map</a></li><li><a href="collections/multimap/index.html">🚧 多重映射表 Multimap</a></li><li><a href="collections/set/index.html">🚧 集合 Set</a></li><li class="spacer"></li></ol></li></ol></li><li><a href="CONTRIBUTING.html">貢獻指南</a></li><li class="affix"><a href="LICENSE.html">授權條款</a></li></ol>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar" class="menu-bar">
                    <div id="menu-bar-sticky-container">
                        <div class="left-buttons">
                            <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                                <i class="fa fa-bars"></i>
                            </button>
                            <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                                <i class="fa fa-paint-brush"></i>
                            </button>
                            <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                                <li role="none"><button role="menuitem" class="theme" id="light">Light <span class="default">(default)</span></button></li>
                                <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                                <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                                <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                                <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                            </ul>
                            
                            <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                                <i class="fa fa-search"></i>
                            </button>
                            
                        </div>

                        <h1 class="menu-title">Rust Algorithm Club</h1>

                        <div class="right-buttons">
                            <a href="https://github.com/weihanglo/rust-algorithm-club" title="Edit" aria-label="Edit on GitHub">
                                <i id="print-button" class="fa fa-github"> Edit</i>
                            </a>
                        </div>
                    </div>
                </div>

                
                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" name="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <p align="center">
  <img src="logo.svg" alt="logo">
<p>
<a class="header" href="#rust-algorithm-club" id="rust-algorithm-club"><h1>Rust Algorithm Club</h1></a>
<p>歡迎來到 Rust 演算法俱樂部！本專案受 <a href="https://github.com/raywenderlich/swift-algorithm-club">Swift Algorithm Club</a> 啟發，專案中的演算法皆使用 <a href="https://www.rust-lang.org/">Rust 程式語言</a>撰寫說明與實作！您可以在 <a href="https://rust-algo.club">Rust Algorithm Club</a> 一站，依您的意願，挑選有興趣的演算法知識學習；若您夠大膽，推薦您閱讀<a href="https://rust-algo.club/doc/rust_algorithm_club/">自動生成的 API 文件</a>，直接單挑程式原始碼。</p>
<p>本專案原始碼放在 <a href="https://github.com/weihanglo/rust-algorithm-club">GitHub</a> 上，非常期待您的貢獻。</p>
<p><a href="https://rust-lang-nursery.github.io/edition-guide/rust-2018"><img src="https://img.shields.io/badge/Rust_Edition-2018-green.svg" alt="Rust Edition" /></a>
<a href="https://travis-ci.com/weihanglo/rust-algorithm-club"><img src="https://travis-ci.com/weihanglo/rust-algorithm-club.svg?token=jBygxQ3kLkkfxSeAJnP2&amp;branch=master" alt="Build Status" /></a>
<a href="https://rust-algo.club/doc/rust_algorithm_club/"><img src="https://img.shields.io/badge/doc-available-blue.svg" alt="Documentation" /></a></p>
<a class="header" href="#a基礎概念" id="a基礎概念"><h2>基礎概念</h2></a>
<ul>
<li><a href="concepts/asymptotic-notation">漸進符號 Asymptotic Notation</a></li>
</ul>
<a class="header" href="#a演算法" id="a演算法"><h2>演算法</h2></a>
<a class="header" href="#a搜尋" id="a搜尋"><h3>搜尋</h3></a>
<ul>
<li><a href="searching/linear_search">線性搜尋 Linear search</a></li>
<li><a href="searching/binary_search">二元搜尋 Binary search</a></li>
<li><a href="searching/interpolation_search">🚧 內插搜尋 Interpolation search</a></li>
<li><a href="searching/exponential_search">指數搜尋 Exponential search</a></li>
</ul>
<a class="header" href="#a排序" id="a排序"><h3>排序</h3></a>
<p>簡單排序：</p>
<ul>
<li><a href="sorting/insertion_sort">插入排序 Insertion sort</a></li>
<li><a href="sorting/selection_sort">選擇排序 Selection sort</a></li>
<li><a href="sorting/bubble_sort">氣泡排序 Bubble sort</a></li>
<li><a href="sorting/shellsort">希爾排序 Shellsort</a></li>
</ul>
<p>高效排序：</p>
<ul>
<li><a href="sorting/heapsort">堆積排序 Heapsort</a></li>
<li><a href="sorting/quicksort">快速排序 Quicksort</a></li>
<li><a href="sorting/mergesort">合併排序 Mergesort</a></li>
</ul>
<p>混合排序（更高效）：</p>
<ul>
<li>🚧 <a href="sorting/introsort">內省排序 Introsort</a></li>
<li>🚧 <a href="sorting/timsort">自適應的合併排序 Timsort</a></li>
<li>🚧 <a href="sorting/pdqsort">模式消除快速排序 Pdqsort</a></li>
</ul>
<p>特殊排序：</p>
<ul>
<li><a href="sorting/counting_sort">計數排序 Counting sort</a></li>
<li><a href="sorting/bucket_sort">桶排序 Bucket sort</a></li>
<li><a href="sorting/radix_sort">基數排序 Radix sort</a></li>
</ul>
<a class="header" href="#a資料結構" id="a資料結構"><h2>資料結構</h2></a>
<a class="header" href="#a堆疊與佇列" id="a堆疊與佇列"><h3>堆疊與佇列</h3></a>
<ul>
<li><a href="collections/stack">🚧 堆疊 Stack</a></li>
<li><a href="collections/queue">🚧 佇列 Queue</a></li>
<li><a href="collections/deque">🚧 雙端佇列 Deque</a></li>
</ul>
<a class="header" href="#a鏈結串列" id="a鏈結串列"><h3>鏈結串列</h3></a>
<p><a href="collections/linked_list">鏈結串列概述</a></p>
<ul>
<li><a href="collections/singly_linked_list">單向鏈結串列 Singly linked list</a></li>
<li><a href="collections/doubly_linked_list">🚧 雙向鏈結串列 Doubly linked list</a></li>
<li><a href="collections/circular_linked_list">🚧 循環鏈結串列 Circular linked list</a></li>
</ul>
<a class="header" href="#a關聯容器" id="a關聯容器"><h3>關聯容器</h3></a>
<p><a href="collections/associative-container">關聯容器概述</a></p>
<ul>
<li><a href="collections/hash_map">雜湊表 Hash map</a></li>
<li><a href="collections/ordered_map">🚧 有序映射表 Ordered map</a></li>
<li><a href="collections/multimap">🚧 多重映射表 Multimap</a></li>
<li><a href="collections/set">🚧 集合 Set</a></li>
</ul>
<a class="header" href="#a學習資源" id="a學習資源"><h2>學習資源</h2></a>
<p>有許多優秀的網站與學習資源，分享給大家學習演算法。</p>
<ul>
<li><a href="https://visualgo.net/">VisuAlgo</a> - 也許是最好的演算法視覺化專案。</li>
<li><a href="http://bigocheatsheet.com/">Big-O Cheat Sheet</a> - 最全面的 Big O cheat sheet。</li>
<li><a href="http://rosettacode.org">Rosetta Code</a> - 使用各種程式語言，解答上百種不同程式問題。</li>
<li><a href="https://cses.fi/book.html">Competitive Programmer’s Handbook</a> - 讓你更有競爭力。這書本身也很有競爭力。</li>
</ul>
<a class="header" href="#a維護者" id="a維護者"><h2>維護者</h2></a>
<ul>
<li><a href="https://github.com/weihanglo">@weihanglo</a></li>
</ul>
<a class="header" href="#a授權條款" id="a授權條款"><h2>授權條款</h2></a>
<p>本專案分為兩部分授權：</p>
<ul>
<li>程式碼與函式庫依據 <a href="LICENSE">The MIT License (MIT)</a> 授權條款發佈。</li>
<li>文章與相關著作依據 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons 4.0 (CC BY-NC-SA 4.0)</a> 授權條款發佈。</li>
</ul>
<p>Copyright © 2017 - 2018 Weihang Lo</p>
<a class="header" href="#a基礎概念-1" id="a基礎概念-1"><h1>基礎概念</h1></a>
<ul>
<li><a href="asymptotic-notation">漸進符號 Asymptotic Notation</a></li>
</ul>
<a class="header" href="#a漸進符號-asymptotic-notation" id="a漸進符號-asymptotic-notation"><h1>漸進符號 Asymptotic Notation</h1></a>
<p>日常生活中，你會如何描述處理事情的效率？</p>
<p>「原來她五分鐘內可以吃掉一頭牛！」</p>
<p>「房間這麼小你還能擺一堆雜物？還不快收拾！」</p>
<p>這些描述方法，著重在處理事情的花費時間，或單位空間內的儲存量。描述演算法的效率也如此，就是「測量演算法的執行成本」，例如這個排序法花了 10 秒鐘跑完兩萬筆資料，或是這個模擬演算法很吃資源需要 32 GB 的記憶體。</p>
<p>然而，在不同的機器規格、環境溫濕度、程式語言、實作方式，以及有沒有放乖乖的變異影響下，相同演算法的執行成本常常不一致。為了消弭這些外部因素，讓分析演算法能夠更科學化。科學家抽絲剝繭，發明一個方法：</p>
<p><strong>「統計演算法內所需操作步驟的數目。」</strong></p>
<p>這是最簡單，最粗淺比較不同演算法效率的作法。</p>
<a class="header" href="#a用數學表示演算法效率" id="a用數學表示演算法效率"><h2>用數學表示演算法效率</h2></a>
<p>「計算步驟數目」很像中小學的數學題目：某公司有三個能力相異的工程師，有的工程師一天解決一個 bug，有的工程師連續工作後效率大幅滑落。每個工程師的除蟲效率可以畫成「bug 數 - 解決 bug 所需時數」函數，橫軸為待處理的臭蟲數，縱軸為解決臭蟲所需時數，如圖一與表所示。</p>
<table><thead><tr><th> 時數       </th><th> $\log N$ </th><th> $N$ </th><th> $N \log N$ </th></tr></thead><tbody>
<tr><td> $N=5$  </td><td> 2.236        </td><td> 5       </td><td> 8.046          </td></tr>
<tr><td> $N=30$ </td><td> 5.477        </td><td> 30      </td><td> 102.036        </td></tr>
</tbody></table>
<p><img src="fig1.png" alt="Fig. 1" /></p>
<p>不論從圖或表，我們都可以明確看出，當 bug 數目小時，每個工程師耗時差不多；當 bug 數目成長到一定程度時，效率好與效率差的工程師差距就很明顯了。</p>
<p>我們把場景拉回演算法的範疇，再闡明一次。上述的除蟲效率函數關係，可以簡單視為為「輸入資料量 - 運算成本」關係之函數。例如 $f(x)=x^2+3x+6$。當輸入資料量增大時，成本也隨之上升，這個用來描述演算法執行成本與輸入資料量之關係的函數，我們稱之為該演算法的「複雜度」。</p>
<a class="header" href="#a何謂漸進符號" id="a何謂漸進符號"><h2>何謂漸進符號</h2></a>
<p>了解每個演算法的時間複雜度之後，就能比較何者效率佳。但往往天不從人願，給了我們兩個演算法進行比較。</p>
<p>$$f(x)=\sqrt{\frac{182777}{286}}\pi x^4+5\log_{3}^{26}88x^3-e^{777^{log_2^9}}$$</p>
<p>$$g(x)=3x^6-2x^2$$</p>
<p>「天啊！這樣要怎麼分析執行效率呀！」</p>
<p>為了有統一的加薪標準，我們不能假定產品只會產生特定數量的臭蟲，也不能以單一天的工作表現判定員工能力，我們知道老舊系統有無限多個 bug，因此，優秀的老闆關心的是工程師長期處理「海量臭蟲」，在極限下的<strong>成長趨勢</strong>，這些成長趨勢才是衡量 KPI 的關鍵。再次強調，優秀老闆關心如何榨出是工程師的「極限成長趨勢」，而非一時半刻賣弄學識。</p>
<p>同樣地，有太多因素干擾影響一個演算法的複雜度，假使我們只觀察當輸入資料量 $n$ 接近無窮大時，演算法的成長趨勢為何，就很接近所謂漸進符號（asymptotic notation）的定義。漸進符號 只關心演算法在極限下的漸進行為，不同的演算法可能使用相同的漸進符號表示。</p>
<p>我們比較兩個簡單函數，$f(x) = 10x + 29$ 以及 $g(x) = x^2 + 1$。從圖二可以看出一開始 $g(x)$ 的執行時間比 $f(x)$ 多了不少，但隨著輸入資料量 $n$ 增多，$g(x)$ 的執行時間成長愈來愈快速，最後遠遠大於 $f(x)$。</p>
<p><img src="fig2.png" alt="Fig. 2" /></p>
<p>若以 $an^2 + bn + c$  表示複雜度，就是當存在一個 $a &gt; 0$ 時，一定會有 $n$ 符合 $an^2 &gt; bn + c$，這個差距隨著 $n$ 越大越明顯，這是因為首項（leading term），也就是帶有最高指數的那一項，隨著 輸入大小改變，執行時間變化幅度較大。因此，可捨去複雜度函數中其他較不重要的次項與常數，留下最大次項，「<strong>透過簡單的函數來表述函數接近極限的行為</strong>」,讓複雜度函數更易理解，這就是「漸進符號」的概念。</p>
<p>這裡介紹常見的幾種漸進符號：</p>
<a class="header" href="#obig-o" id="obig-o"><h3>$O$：Big O</h3></a>
<p>當我們談論演算法複雜度時，通常關心的是演算法「最糟糕的情況下」，「最多」需要執行多久。Big O 就是描述演算法複雜度上界的漸進符號，當一個演算法「實際」的複雜度（或執行成本對輸入資料量函數）為 $f(n)$ 時，欲以 Big O 描述其複雜度上界時，必須滿足以下定義：</p>
<p>$$f(n) = O(g(n)) \colon {\exists k&gt;0\ \exists n_0\ \forall n&gt;n_0\ |f(n)| \leq k \cdot g(n)}$$</p>
<p>假設有一演算法實際複雜度為 $f(n) = 3n + 4$，有一組 $k = 4;\ g(n) = n;\ n_0 = 4$ 滿足</p>
<p>$$\forall n &gt; 4,\ 0 \leq f(n) = 3n + 4 \leq 4n$$</p>
<p>意思是「$f(n)$ 的複雜度上界成長趨勢最終不會超過 $g(n) = 4n$ 」，再代入 $O(g(n))$，可得演算法最差複雜度為 $f(n) = O(n)$，也就是「該演算法的成長趨勢不會比 $g(n)$ 來得快」（見圖三）。</p>
<p><img src="fig3.png" alt="Fig. 3" /></p>
<p>再多看一個例子，若 $f(n) = 4n^2 + n$ 有一組 $k = 5;\ g(n) = n^2;\ n_0 = 5$ 滿足</p>
<p>$$\forall n &gt; 5,\ 0 \leq f(n) = 4n^2 + n \leq 5n^2$$</p>
<p>則此函數的複雜度為 $f(n) = O(n^2)$。</p>
<blockquote>
<p>注意：也寫作 $f(n) \in O(g(n))$，因為實際上 $O(g(n))$ 是所有可描述演算法成長趨勢，並滿足上述條件的函數之「集合」。</p>
</blockquote>
<a class="header" href="#omegabig-omega" id="omegabig-omega"><h3>$\Omega$：Big Omega</h3></a>
<p>相較於 Big O 描述演算法成長趨勢的上界，Big Omega 則是對應成長趨勢的「下界」，定義如下：</p>
<p>$$f(n) = \Omega(g(n)) \colon {\exists k&gt;0\ \exists n_0\ \forall n&gt;n_0\ |f(n)| \geq k \cdot g(n)}$$</p>
<p>以 $f(n) = 3n + 4$ 為例，有一組 $k = 2;\ g(n) = n;\ n_0 = 0$ 滿足上式，因此這個演算法在輸入資料夠大時，「至少」會達到 $\Omega(n)$ 的複雜度，也就是「該演算法的成長趨勢不會比 $g(n)$ 來得慢」。</p>
<a class="header" href="#thetabig-theta" id="thetabig-theta"><h3>$\Theta$：Big Theta</h3></a>
<p>Big Theta 則是 Big O 與 Big Omega 兩個漸進上下界所夾出的範圍，表示該演算法在輸入資料夠大時，最終的複雜度會成長到這個範圍中。其定義如下：</p>
<p>$$f(n) = \Theta(g(n)) \colon {\exists k_1&gt;0\ \exists k_2&gt;0\ \exists n_0\ \forall n&gt;n_0\ k_1 \cdot g(n) \leq |f(n)| \leq k_2 \cdot g(n)}$$</p>
<p>繼續以 $f(n) = 3n + 4$ 為例，同樣有一組 $k_1 = 1;\ k_2 = 5;\ g(n) = n;\ n_0 = 2$，滿足</p>
<p>$$\forall n \geq 2,\ n \leq f(n) = 3n + 4 \leq 5n$$</p>
<p>可得知，$f(n) = 3n + 4 \in \Theta(n)$，表示「該演算法的成長趨勢與 $g(n) = n$ 相同」（見圖四）。</p>
<p><img src="fig4.png" alt="Fig. 4" /></p>
<a class="header" href="#a常見的複雜度" id="a常見的複雜度"><h2>常見的複雜度</h2></a>
<p>看完了讓人昏昏欲睡的數學定義，現在來認識一些常見的複雜度，從最快最有效率，到最慢最拖台錢的通通一起認識。</p>
<ul>
<li>$O(1)$：常數時間，演算法執行時間與資料量毫無瓜葛。例如讀取 array 首個元素。</li>
<li>$O(\log n)$：執行時間隨資料量呈對數比例成長。常見的例子是<a href="../../searching/binary_search">二元搜索（Binary search）</a>。</li>
<li>$O(n)$：執行時間隨資料量呈線性成長，例如在無序的 array 中尋找特定值。</li>
<li>$O(n \log n)$：執行時間隨資料量呈線性對數成長，常見的<a href="../../sorting/mergesort">合併排序（Mergesort）</a>的複雜度即如斯。</li>
<li>$O(n^2)$：執行時間隨資料量呈平方成長，例如一些效率不彰的排序法如<a href="../../sorting/bubble_sort">氣泡排序（Bubble sort）</a>。</li>
<li>$O(n^3)$：執行時間隨資料量呈立方成長，常見例子為 naïve 實作的矩陣乘法。</li>
<li>$O(c^n)$：執行時間隨資料量呈指數成長。</li>
<li>$O(n!)$：執行時間隨資料量呈階乘成長，大部分情況下，這是非常差勁的複雜度。</li>
</ul>
<p>若想一窺各種常見演算法的複雜度，可以參考這個最全面的 <a href="http://bigocheatsheet.com/">Big-O Cheat Sheet</a>，圖表非常精美直觀！</p>
<blockquote>
<p>再次強調，漸進符號也可以代表其他執行成本如記憶體空間，並不一定代表執行時間。</p>
</blockquote>
<!-- -->
<blockquote>
<p>其他的漸進符號還有 little-o、little-omega 等等，有興趣的朋友可以參考文末的資料。</p>
</blockquote>
<a class="header" href="#a你可能不適合漸進符號" id="a你可能不適合漸進符號"><h2>你可能不適合漸進符號</h2></a>
<p>善用漸進符號，可以讓原本複雜艱澀的實際複雜度，簡化至人類容易理解的簡單數學符號，也讓分析演算法效率更為客觀。但實際上，漸進符號省略了常數項與低次項，僅保留最高次項，這種「漸進行為下」的效能表現，在真實世界中，若輸入資料量不夠大，實際複雜度的低次項係數又比高次項大上許多，很可能這個演算法實際上根本沒辦法使用。</p>
<p>另外，漸進符號僅考慮最差與最佳複雜度，沒有考慮到平均複雜度。舉例來說，<a href="../../sorting/quicksort">Quicksort</a> 最差複雜度為 $O(n^2)$，乍看之下不是很理想，但這種情況非常稀少；其平均複雜度落在 $O(n \log n)$，且其係數相對較低，額外開銷少，自然成為最熱門的排序法之一。</p>
<p>還有，漸進符號也沒有考慮到不同語言、平台的基礎操作開銷，例如實作排序法時，有些語言「比較」兩個元素的開銷比「置換」來得大，實作上就需要盡量減少置換元素。同樣的，CPU 快取也非常容易忽略，一些快速的搜尋法很可能因為不是<a href="../../searching/linear_search">線性搜尋</a>，沒辦法充分利用 CPU cache，效能不一定理想。</p>
<p>總之，漸進符號只能告訴你「當輸入資料量夠大時，演算法的複雜度表現如何」，並不總是適用每個情境，端看你怎麼使用他。</p>
<a class="header" href="#a參考資料" id="a參考資料"><h2>參考資料</h2></a>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Time_complexity">Wiki: Time complexity</a></li>
<li><a href="https://en.wikipedia.org/wiki/Big_O_notation">Wiki: Big O notation</a></li>
<li><a href="https://brilliant.org/wiki/big-o-notation/">Brilliant: Big O Notation</a></li>
<li><a href="http://program-lover.blogspot.com/2008/10/complexity-analysis.html">Infinite Loop: Complexity Analysis</a></li>
</ul>
<a class="header" href="#a搜尋演算法" id="a搜尋演算法"><h1>搜尋演算法</h1></a>
<p>記錄常見的搜尋演算法。</p>
<a class="header" href="#a線性搜尋-linear-search" id="a線性搜尋-linear-search"><h1>線性搜尋 Linear Search</h1></a>
<p>線性搜尋，又稱為循序搜尋（sequential search），是一個在序列中找尋目標的方法。正如字面上的意義，線性搜尋會按照順序迭代序列，挨家挨戶比對每個元素與目標值是否相等，若相等則停止迭代，並回傳搜尋所得結果。</p>
<p>線性搜尋乍看之下，是最簡單實作也最 naïve 的實作，效能應該不怎麼好。事實上，在資料量不多時（少於 100 個元素），線性搜尋的效能也不會太差，因為其他搜尋演算法可能需要建立特殊資料結構，就會導致時空間初始開銷暴增，複雜度的常數項成本變大。</p>
<a class="header" href="#a效能" id="a效能"><h2>效能</h2></a>
<table><thead><tr><th>              </th><th> Complexity </th></tr></thead><tbody>
<tr><td> Worst        </td><td> $O(n)$     </td></tr>
<tr><td> Best         </td><td> $O(1)$     </td></tr>
<tr><td> Average      </td><td> $O(n)$     </td></tr>
<tr><td> Worst space  </td><td> $O(1)$     </td></tr>
</tbody></table>
<p>若序列中總共有 $n$ 個元素，則線性搜尋最差的狀況為元素不在序列中，就是全部元素都比較一次，共比較 $n - 1$ 次，最差複雜度為  $O(n)$。</p>
<a class="header" href="#a實作" id="a實作"><h2>實作</h2></a>
<p>線性搜尋就是用一個 for-loop 解決。要注意的是，<code>T</code> 泛型參數至少要實作 <code>PartialEq</code> 才能比較。程式碼中使用了迭代器的 <a href="https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.enumerate">enumerate</a>，建立一個新迭代器，每次迭代產生迭代次數與對應的值。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn linear_search&lt;T&gt;(arr: &amp;[T], target: &amp;T) -&gt; Option&lt;usize&gt;
    where T: PartialEq
{
    for (index, item) in arr.iter().enumerate() {
        if item == target {
            return Some(index);
        }
    }
    None
}
#}</code></pre></pre>
<p>事實上，若利用 Rust 內建的 <a href="https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.position"><code>iterator.position</code></a>，程式碼也許會更簡潔。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn linear_search&lt;T&gt;(arr: &amp;[T], obj: &amp;T) -&gt; Option&lt;usize&gt;
    where T: PartialEq
{
    arr.iter().position(|x| x == obj)
}
#}</code></pre></pre>
<a class="header" href="#a參考資料-1" id="a參考資料-1"><h2>參考資料</h2></a>
<p><a href="https://en.wikipedia.org/wiki/Linear_search">Wiki: Linear search</a></p>
<a class="header" href="#a二元搜尋-binary-search" id="a二元搜尋-binary-search"><h1>二元搜尋 Binary Search</h1></a>
<p>Binary search，又稱對數搜尋（logarithmic search），是一個在已排序的序列中，快速找出特定元素的搜尋演算法。二元搜尋的步驟就像玩猜數字，先猜一個數字，告訴你你的猜測比正確答案大或小，再繼續往對的方向猜，捨棄猜錯的另一半。這樣持續進行好幾次猜測，每猜一次，搜尋範圍就縮小一半，因此稱為「二元」搜尋。</p>
<p>二元搜尋有以下幾個特點：</p>
<ul>
<li>概念簡單，搜尋高效，達到對數執行時間 $O(\log n)$。</li>
<li>不需額外實作資料結構或配置記憶體空間。</li>
<li>只能搜尋<strong>已排序</strong>的序列。</li>
</ul>
<a class="header" href="#a步驟" id="a步驟"><h2>步驟</h2></a>
<ol>
<li>從序列中間的元素開始，比較其與目標值</li>
<li>若該元素為搜尋目標，則結束搜尋。</li>
<li>若該元素較大或小，則將序列切一半，往較小或較大的一半搜尋。</li>
<li>繼續從一半的序列中間的元素開始，重複步驟一到三，直到欲搜尋的序列為空。</li>
</ol>
<a class="header" href="#a說明" id="a說明"><h2>說明</h2></a>
<p>這裡有一個排好序的序列，共有 15 個元素，現在要找尋 9 是否在序列中。</p>
<pre><code>                       *
[2, 3, 3, 6, 6, 7, 9, 13, 15, 19, 20, 22, 23, 24, 25]
</code></pre>
<p>首先，先找到中間的元素 15 / 2 ~= 8，第八個元素為 13，比 9 大，因此捨棄第八個元素之後的所有元素。</p>
<pre><code>          *
[2, 3, 3, 6, 6, 7, 9, _, _, _, _, _, _, _, _]
</code></pre>
<p>接下來繼續對半搜尋，8 / 2 = 4，找尋第四個元素來比對，6 比 9 小，，因此捨棄第四個元素前的所有元素。</p>
<pre><code>             *
[_, _, _, 6, 6, 7, 9, _, _, _, _, _, _, _, _]
</code></pre>
<p>對剩下的元素二元搜尋，4 / 2 = 2，並從第四個元素開始計算中點 4 + 2 = 6，取得第六個元素為 7，比 9 小，捨棄 7 之前的元素。</p>
<pre><code>                   *
[_, _, _, _, _, 7, 9, _, _, _, _, _, _, _, _]
</code></pre>
<p>繼續切一半來搜尋，繼續找中間的元素 2 / 2 = 1，並從第六個元素計算索引位置 6 + 1 = 7，查看第七個元素是 9，終於找到了！</p>
<a class="header" href="#a效能-1" id="a效能-1"><h2>效能</h2></a>
<table><thead><tr><th>              </th><th> Complexity  </th></tr></thead><tbody>
<tr><td> Worst        </td><td> $O(\log n)$ </td></tr>
<tr><td> Best         </td><td> $O(1)$      </td></tr>
<tr><td> Average      </td><td> $O(\log n)$ </td></tr>
<tr><td> Worst space  </td><td> $O(1)$      </td></tr>
</tbody></table>
<p>二元搜尋可以透過分治法（Divide and conquer）遞迴求解，而遞迴的終止條件是序列不能在切兩半。由此可知，二元搜尋的複雜度奠基在要切幾次，子序列長度才會等於 1。設 $n$ 為資料數目，$k$ 為要切幾次才會達成終止條件，可得：</p>
<p>$$ \frac{n}{2^k} = 1 $$</p>
<p>接下來同乘 $2^k$ 並取對數。
$$
\frac{n}{2^k} = 1 \\
\Rightarrow 2^k = n \\
$$</p>
<p>再將左式整理一下，得到 $k$。</p>
<p>$$
\log_2 2^k = log_2 n \\
\Rightarrow k \cdot \log_2 2 = log_2 n \\
\Rightarrow k = log_2 n
$$</p>
<p>於是，我們得到二元搜尋時間複雜度為 $O(k) = O(\log_2 n) = O(\log n)$。</p>
<p>寫這種式子也許不好理解，我們可以把搜尋過程和每個分支寫成樹狀圖，方便觀察。假設一個數列有七個元素 <code>[1, 2, 3, 4, 5, 6, 7]</code>，其二元搜尋所有可能路徑的樹狀圖如下：</p>
<pre><code>          +---+
          | 4 |
          +---+
        /       \
     +---+      +---+
     | 2 |      | 6 |
     +---+      +---+
    /    \      /   \
+---+  +---+  +---+  +---+
| 1 |  | 3 |  | 5 |  | 7 |
+---+  +---+  +---+  +---+
</code></pre>
<p>樹中每一條路徑都代表任意搜尋會經過的步驟，總共有 7 種不同的搜尋路徑，最短路徑僅需要 $\lfloor{\log_2 n} = 3 \rfloor$ 個操作，也就是需要執行「樹高」次的操作。</p>
<a class="header" href="#a實作-1" id="a實作-1"><h2>實作</h2></a>
<a class="header" href="#a函式宣告" id="a函式宣告"><h3>函式宣告</h3></a>
<p>二元搜尋概念看似簡單，實際上誤區一堆，不易寫出完全正確的演算法。我們參考 <a href="https://doc.rust-lang.org/std/primitive.slice.html#method.binary_search">Rust slice binary_search</a> 的實作。先來看看 function signature（函式的宣告）。</p>
<pre><code>pub fn binary_search&lt;T&gt;(arr: &amp;[T], target: &amp;T) -&gt; Result&lt;usize, usize&gt;
    where T: PartialOrd
</code></pre>
<p>二元搜尋函式宣告中，回傳值大概是最特別的部分。如果有找到目標元素，<code>Result</code> 會是 <code>Ok(目標索引位置)</code>，如果沒有找到則回傳 <code>Err(目標值若插入後，不會影響序列排序的位置)</code>。<code>Err</code> 回傳值提供了插入點，非常方便。</p>
<p>再來，<code>T</code> 泛型參數需是 <a href="https://doc.rust-lang.org/std/cmp/trait.PartialOrd.html"><code>PartialOrd</code></a>，這是由於二元搜尋使用排序過後的元素，比起線性搜尋，仍需元素之間相互比較。</p>
<a class="header" href="#a函式主體" id="a函式主體"><h3>函式主體</h3></a>
<p>市面上常見的實作通常以兩個變數 <code>l</code> 與 <code>r</code> 記錄搜尋範圍的上下界，而我們另闢蹊徑，記錄了</p>
<ul>
<li><code>base</code>：搜尋範圍的下界，</li>
<li><code>size</code>：搜尋範圍的長度。</li>
</ul>
<p>以下是完整實作：</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn binary_search&lt;T&gt;(arr: &amp;[T], target: &amp;T) -&gt; Result&lt;usize, usize&gt;
    where T: PartialOrd
{
    let mut size = arr.len();       // 1
    if size == 0 {
        return Err(0);
    }
    let mut base = 0_usize;

    while size &gt; 1 {                // 2
        // mid: [base..size)
        let half = size / 2;        // 2.1
        let mid = base + half;
        if arr[mid] &lt;= *target {    // 2.2
            base = mid
        }
        size -= half;               // 2.3
    }

    if arr[base] == *target {       // 3
        Ok(base)
    } else {
        Err(base + (arr[base] &lt; *target) as usize)
    }
}
#}</code></pre></pre>
<ol>
<li>第一部分先取得搜尋範圍 <code>size</code> 以及確定下界為 <code>0_usize</code>。這裡同時檢查若序列長度為零，直接回傳 <code>Err(0)</code>，告知呼叫端可直接在 index 0 新增元素。</li>
<li>第二部分就是精髓了，將終止條件設在 <code>size &lt;= 1</code>，以確保迴圈能夠正常結束。
<ol>
<li>先將搜尋範圍對半切，再與下界 <code>base</code> 相加，算出中點。</li>
<li>另中間元素與目標值比較，如果比較小，則移動下界至中點。</li>
<li>將 <code>size</code> 減半，縮小搜尋範圍。</li>
</ol>
</li>
<li>到了第三部分，<code>base</code> 已經是切到長度為一的序列了，若匹配目標值就直接回傳；若否，需要傳可供目標值插入的位置，將 bool 判斷是轉型成 <code>usize</code>，若 <code>arr[base]</code> 比目標值小，則目標值要加到其後 +1 位置，反之則加在其前 -1 位置。</li>
</ol>
<a class="header" href="#a常見誤區與解法" id="a常見誤區與解法"><h2>常見誤區與解法</h2></a>
<ol>
<li>
<p>只適用已排序序列： 這是使用二元搜尋的前提，千萬不能忽略這重要特性，否則後果絕對大錯特錯。</p>
</li>
<li>
<p>處理重複元素：一般的實作通常是回傳任意符合目標值的索引位置，就算有重複的元素，仍然不可預期。若要回傳特定位置（leftmost 或 rightmost），則需特別處理。</p>
</li>
<li>
<p>整數溢位：部分二元搜尋實作會 以兩個變數儲存搜尋範圍上下界的索引位置，而取中點時千萬不可直接將上下界相加再除二，否則很可能整數溢位（integer overflow）。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
let mid = (end + start) / 2           // Wrong: integer overflow
let mid = start + (end - start) / 2   // Correct
#}</code></pre></pre>
</li>
<li>
<p>終止條件錯誤：無論如何實作，請將終止條件設為「搜尋範圍為空」，也就是下界大於上界，而不要只比較上下界是否相等。其實搜尋範圍低於一定長度，即可使用線性搜尋替代，避免處理邊界值的麻煩，實務上也幾乎沒有太多效能損失。</p>
</li>
</ol>
<a class="header" href="#a變形與衍生" id="a變形與衍生"><h2>變形與衍生</h2></a>
<a class="header" href="#interpolation-search" id="interpolation-search"><h3>Interpolation Search</h3></a>
<p><a href="../interpolation_search">Interpolation search</a> 改良自二元搜尋，差別在於，二元搜尋選擇中間的元素作為二分點，而 interpolation search 人如其名，以內插法找尋二分點。在資料平均分佈時，比二元搜尋更高效。欲知後續，待下回<a href="../interpolation_search">內插搜尋 Interpolation search</a> 分曉。</p>
<a class="header" href="#exponential-search" id="exponential-search"><h3>Exponential Search</h3></a>
<p><a href="../exponential_search">Exponential search</a> 是一種特殊的二元搜尋，主要用在搜尋無限、無邊界的已排序序列，由於邊界未知長度就未知，無法以傳統二元搜尋找尋中點。Exponential 顧名思義就是不斷比較在 $2^0$，$2^1$ 直到 $2^n$ 的位置上資料是否比目標值大，若較大，再從該位置執行二元搜尋回頭找。詳情請看<a href="../exponential_search">指數搜尋 Exponential search</a>。</p>
<a class="header" href="#binary-insertion-sort" id="binary-insertion-sort"><h3>Binary Insertion Sort</h3></a>
<p>Insertion sort 有一個步驟是在前面已經排完序的資料中，找到適合的地方插入待排序的元素，這部分可透過二元搜尋加快在已排序資料搜尋的速度。詳情請參考 <a href="../../sorting/insertion_sort/#binary-insertion-sort">Binary insertion sort</a>。</p>
<a class="header" href="#a參考資料-2" id="a參考資料-2"><h2>參考資料</h2></a>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Binary_search_algorithm">Wiki: Binary search algorithm</a></li>
<li><a href="https://www.zhihu.com/question/36132386">知乎：二分查找有几种写法？它们的区别是什么？</a></li>
</ul>
<a class="header" href="#a內插搜尋-interpolation-search" id="a內插搜尋-interpolation-search"><h1>內插搜尋 Interpolation Search</h1></a>
<a class="header" href="#a參考資料-3" id="a參考資料-3"><h2>參考資料</h2></a>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Interpolation_search">Wiki: Interpolation search</a></li>
<li><a href="http://program-lover.blogspot.com/2008/12/interpolation-search.html">Infinite Loop: Interpolation Search</a></li>
</ul>
<a class="header" href="#a指數搜尋-exponential-search" id="a指數搜尋-exponential-search"><h1>指數搜尋 Exponential Search</h1></a>
<p>指數搜尋，又稱為 galloping search，是一種特殊的<a href="../binary_search">二元搜尋</a>，主要用在搜尋無限、無邊界的已排序序列。由於邊界未知長度就未知，無法以傳統二元搜尋來找中點。而 Exponential 顧名思義就是從底數為 2，指數為 0 的索引（$2^0$ ）開始，不斷比較在 $2^1$、$2^2$ 直到 $2^k$ 位置上的值，若比目標值大，則停止指數成長，直接從該位置執行二元搜尋，回頭尋找目標值。</p>
<p>指數搜尋的特點如下：</p>
<ul>
<li>可以搜尋邊界未知的已排序序列。</li>
<li>縮小搜尋範圍，可比 naïve 的二元搜尋效率高些。</li>
<li>若目標值實際位置很靠近序列前端，效率會非常棒。</li>
</ul>
<a class="header" href="#a步驟-1" id="a步驟-1"><h2>步驟</h2></a>
<p>指數搜尋的步驟只有非常簡單的兩步驟：</p>
<ol>
<li>依照目標值大小，劃出搜尋範圍。</li>
<li>在上述範圍內執行二元搜尋。</li>
</ol>
<p>而劃出搜尋範圍這部分也很直觀：</p>
<ol>
<li>選定一個底數 $k$，通常為 2。</li>
<li>比較 $k^i$ 索引下的值是否比目標值大，$i$ 從零開始。</li>
<li>若較小，指數加一 $k^{i + 1}$ 後繼續重複步驟二比較。</li>
<li>若較大，停止比較，得搜尋範圍為 $k^{i - 1}$ 到 $k^i$。</li>
</ol>
<a class="header" href="#a說明-1" id="a說明-1"><h2>說明</h2></a>
<p>這裡有個排好序的序列，我們要尋找其中是否有 22 這個數字。</p>
<pre><code>    *
[2, 3, 3, 6, 6, 7, 9, 13, 15, 19, 20, 22, 23, 24, 25]
</code></pre>
<p>首先，先尋找 $2^0 = 1$ 位置上的數字是否超過 22。<code>3 &lt; 22</code>，很明顯沒有。</p>
<pre><code>       *     *            *
[2, 3, 3, 6, 6, 7, 9, 13, 15, 19, 20, 22, 23, 24, 25]
</code></pre>
<p>再來，連續看看</p>
<ul>
<li>$2^1$：<code>3 &lt; 22</code></li>
<li>$2^2$：<code>6 &lt; 22</code></li>
<li>$2^3$：<code>15 &lt; 22</code></li>
</ul>
<p>也都沒有超越 22。</p>
<pre><code>                                                           *
[2, 3, 3, 6, 6, 7, 9, 13, 15, 19, 20, 22, 23, 24, 25]  _,  _
</code></pre>
<p>最後，一口氣將指數加到 4，看看$2^4$ 上的數字是否大於 22。哎呀，$2^4 = 16$，的位置已經超出序列長度，因此取至序列最後一個數字作為比較對象。<code>25 &gt; 22</code>，找到了！</p>
<p>得到搜尋的範圍是 $$2^{4-1} &lt; x &lt; \text{array.length} &lt; 2^{4}$$</p>
<a class="header" href="#a效能-2" id="a效能-2"><h2>效能</h2></a>
<table><thead><tr><th>              </th><th> Complexity  </th></tr></thead><tbody>
<tr><td> Worst        </td><td> $O(\log i)$ </td></tr>
<tr><td> Best         </td><td> $O(1)$      </td></tr>
<tr><td> Average      </td><td> $O(\log i)$ </td></tr>
<tr><td> Worst space  </td><td> $O(1)$      </td></tr>
</tbody></table>
<blockquote>
<p>$i$：目標值在序列中實際的索引位置。</p>
</blockquote>
<p>指數搜尋的複雜度分為兩部分分析：</p>
<a class="header" href="#a劃定搜尋範圍" id="a劃定搜尋範圍"><h3>劃定搜尋範圍</h3></a>
<p>設 $i$ 為目標值在序列中實際的索引位置，則搜尋上界，指數增加的操作需執行 $\lceil \log(i) \rceil$ 次，例如匹配目標值的搜尋結果位於序列第 9 個，則指數需增加 $\lceil \log(9) \rceil = 4$ 次，上界才會超過目標值。我們設這部分的複雜度為 $O(log i)$。</p>
<a class="header" href="#a執行二元搜尋" id="a執行二元搜尋"><h3>執行二元搜尋</h3></a>
<p>第二部分就是二元搜尋，複雜度為 $O(log n)$，$n$ 為搜尋範圍的長度。根據第一部分，可以得知範圍長度為 $2^{\log i} - 2^{\log{i - 1}} = 2^{log{i - 1}}$ 個元素，帶入二元搜尋的複雜度，計算出第二部分的複雜度為 $log (2^{\log{i - 1}}) = \log{(i)} - 1 = O(\log i)$。</p>
<p>最後，將兩部分的複雜度合起來，就是指數搜尋的時間複雜度了。</p>
<p>$$O(\log i) + O(\log i) = 2 O(\log i) = O(\log i)$$</p>
<a class="header" href="#a實作-2" id="a實作-2"><h2>實作</h2></a>
<p>本次實作有邊界的指數搜尋，主要分為三個部分：</p>
<ol>
<li>處理空序列的狀況。</li>
<li>利用指數，決定搜尋範圍。</li>
<li>執行二元搜尋，並將輸出結果映射回原始序列。</li>
</ol>
<p>話不多說，直接看程式碼。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
use crate::searching::binary_search;

pub fn exponential_search&lt;T&gt;(arr: &amp;[T], target: &amp;T) -&gt; Result&lt;usize, usize&gt;
    where T: PartialOrd
{
    // 1. Handle empty scenario.
    let size = arr.len();
    if size == 0 {
        return Err(0);
    }

    // 2. Determine searching boundaries.
    let mut hi = 1_usize; // Upper bound.
    while hi &lt; size &amp;&amp; arr[hi] &lt; *target {
        hi &lt;&lt;= 1;
    }
    let lo = hi &gt;&gt; 1; // Lower bound.

    // 3. Do binary search.
    binary_search(&amp;arr[lo..size.min(hi + 1)], target)
        .map(|index| lo + index)
        .map_err(|index| lo + index)
}
#}</code></pre></pre>
<ol>
<li>和二元搜尋同，遇到空序列就返回 <code>Err(0)</code> 告知呼叫端可新增資料在位置 0。</li>
<li>決定搜尋上下界，只要 上界不超過序列長度，且 <code>arr[hi]</code> 小於目標值，就讓上界指數成長。這裡用位元左移運算子（bitwise left shift）實作乘以 2。<br />
找到上界後，再將上界除以 2（位元右移），就是下界了。</li>
<li>確定範圍後，利用上下界切序列的 sub slice 作為引數，傳遞給二元搜尋。要注意的是，為了避免 sub slice 超出邊界，上界需在 <code>size</code> 與 <code>hi + 1</code> 之間找最小值。<br />
由於回傳結果的位置是以 sub slice 起始，需加上位移量（下界 <code>lo</code>）才會對應原始 slice 的位置。</li>
</ol>
<a class="header" href="#a參考資料-4" id="a參考資料-4"><h2>參考資料</h2></a>
<p><a href="https://en.wikipedia.org/wiki/Exponential_search">Wiki: Exponential search</a></p>
<a class="header" href="#a排序演算法" id="a排序演算法"><h1>排序演算法</h1></a>
<p>記錄常見的排序演算法。</p>
<a class="header" href="#a編排慣例" id="a編排慣例"><h2>編排慣例</h2></a>
<p>為了避免泛型宣告降低程式碼可讀性，部分文章內的示範程式不撰寫泛型，排序結果訂為「由小至大」。若需要了解如何撰寫泛型排序演算法，請逕行閱讀對應的 Rust 程式碼。</p>
<a class="header" href="#a簡單排序" id="a簡單排序"><h1>簡單排序</h1></a>
<ul>
<li><a href="insertion_sort">插入排序 Insertion sort</a></li>
<li><a href="selection_sort">選擇排序 Selection sort</a></li>
<li><a href="bubble_sort">氣泡排序 Bubble sort</a></li>
<li><a href="shellsort">希爾排序 Shellsort</a></li>
</ul>
<a class="header" href="#a插入排序-insertion-sort" id="a插入排序-insertion-sort"><h1>插入排序 Insertion Sort</h1></a>
<p>Insertion sort 是最簡單的排序法之一，比起 quicksort 等高效的排序法，對大資料的處理效能較不理想。其演算法是將欲排序元素直接插入正確位置，因而得名。</p>
<p>Insertion sort 基本特性如下：</p>
<ul>
<li>實作簡單易理解。</li>
<li>資料量少時較高效，且比其他 $O(n^2) $ 的排序法高效（selection sort/bubble sort）。</li>
<li><strong>自適應排序</strong>：可根據當前資料排序情形加速排序，資料越接近排序完成，效率越高。</li>
<li><strong>穩定排序</strong>：相同鍵值的元素，排序後相對位置不改變。</li>
<li><strong>原地排序</strong>：不需額外花費儲存空間來排序。</li>
<li><strong>即時演算法</strong>：可處理逐步輸入的資料，不需等資料完全備妥。</li>
</ul>
<a class="header" href="#a步驟-2" id="a步驟-2"><h2>步驟</h2></a>
<p>將序列分為未排序與部分排序兩個區域。</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/3/32/Insertionsort-before.png" alt="" /></p>
<ol>
<li><strong>取第一個元素</strong>，將該元素視為已排序。</li>
<li><strong>取出下一元素</strong>，該元素將插入序列的部分排序區域。</li>
<li><strong>尋找正確位置</strong>：若部分排序元素比新元素大，則互換位置。並重複步驟 2 - 3，直到部分排序元素小於等於新元素。</li>
<li><strong>插入元素</strong>：將新元素<strong>插入</strong>最後的位置。</li>
<li>重複步驟 2 - 4，直到排序完成。</li>
</ol>
<p>簡而言之，即是每次取一個元素，尋找並插入該元素在部分排序區域的排序位置，再逐步把序列單邊排序完成。</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/d/d9/Insertionsort-after.png" alt="" /></p>
<p>Insertion sort 非常簡單，看動畫就能明瞭。
<img src="https://upload.wikimedia.org/wikipedia/commons/0/0f/Insertion-sort-example-300px.gif" alt="" /></p>
<a class="header" href="#a效能-3" id="a效能-3"><h2>效能</h2></a>
<table><thead><tr><th>              </th><th> Complexity    </th></tr></thead><tbody>
<tr><td> Worst        </td><td> $O(n^2) $ </td></tr>
<tr><td> Best         </td><td> $O(n) $   </td></tr>
<tr><td> Average      </td><td> $O(n^2) $ </td></tr>
<tr><td> Worst space  </td><td> $O(1) $ auxiliary </td></tr>
</tbody></table>
<p>最佳時間複雜度發生在資料已完成排序的狀況下，insertion sort 只需執行最外層的迴圈 $n $ 次。</p>
<p>最差時間複雜度發生在資料完全相反時，insertion sort 每取得一個新元素是，都需將資料插入序列最前面，，因此所需的操作如下（ $c $ 為任意常數）：</p>
<p>$$ c \cdot 1 + c \cdot 2 + c \cdot 3 \cdots + c \cdot (n - 1) = \frac{c(n - 1 + 1)(n - 1)}{2}$$</p>
<p>最後等於</p>
<p>$$\frac{cn^2}{2} - \frac{cn}{2}$$</p>
<p>捨去低次項，得到時間複雜度為 $O(n^2) $。</p>
<a class="header" href="#a實作-3" id="a實作-3"><h2>實作</h2></a>
<p>簡單實作的程式碼如下：</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn insertion_sort(arr: &amp;mut [i32]) {
    for i in 1..arr.len() {                   // 1
        let mut j = i;
        while j &gt; 0 &amp;&amp; arr[j - 1] &gt; arr[j] {  // 2
            arr.swap(j - 1, j);
            j -= 1;
        }
    }
}
#}</code></pre></pre>
<ol>
<li>外層迴圈迭代整個序列。並取出 index <code>i</code>，<code>arr[i]</code> 是待排序的元素，index 比 <code>i</code> 小的元素則組成已排序的部分序列。</li>
<li>內層迴圈負責元素比較，決定待排序元素該從何處插入，若前一個元素比待排元素大，則置換兩元素，並繼續往下尋找正確的插入點。直到 <code>j == 0</code> 或待排元素比任何已排序元素都大為止。</li>
</ol>
<a class="header" href="#a變形" id="a變形"><h2>變形</h2></a>
<a class="header" href="#binary-insertion-sort-1" id="binary-insertion-sort-1"><h3>Binary Insertion Sort</h3></a>
<p>在一般演算法討論中，通常以簡單的型別如 <code>i32</code> 來探討並實作。在真實世界中，做哪種操作，用哪種語言，都會影響到實際效能。例如 Python 的比較操作相對於置換元素，成本高出不少，是因為每個物件在 Python 的比較需動態檢查是否實作 <code>__lt__</code> <code>__gt__</code> 等方法才能進行比較。所以 Python 排序法實作就要特別注意減少比較操作的次數。</p>
<p>Binary insertion sort 的目的就是減少內層迴圈的比較次數。在內層迴圈開始之前，使用 <a href="https://en.wikipedia.org/wiki/Binary_search">binary search</a> 搜尋新元素應要插入哪個位置，最多僅需 $\log_2n $ 次比較。但 binary insertion sort 的複雜度依舊是 $O(n^2) $，因為除了比較之外，仍需置換（swap）、賦值（assign）等基礎操作。</p>
<p>Binary insertion sort 的程式碼和一般的 insertion sort 差不了多少，我們這裡使用 <code>slice</code> 內建的 <code>binary_search</code> 來找尋插入點。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn binary_insertion_sort(arr: &amp;mut [i32]) {
    for i in 1..arr.len() {
        let val = arr[i];
        let mut j = i;
        let pos = match arr[..i].binary_search(&amp;val) { // 1
            Ok(pos) =&gt; pos,                            // 2
            Err(pos) =&gt; pos,
        };
        while j &gt; pos {                                // 3
            arr.swap(j - 1, j);
            j -= 1;
        }
    }
}
#}</code></pre></pre>
<ol>
<li>先限制 <code>binary_search</code> 範圍，取出 sorted pile <code>arr[..i]</code>。再對 slice 執行 <code>binary_search</code>。</li>
<li><code>binary_search</code> 回傳一個 <code>Result&lt;usize, usize&gt;</code> 型別，找到時回傳 <code>Ok(index 值)</code>，找無時回傳 <code>Err(不影響排序穩定度的插入點)</code>，這個 <code>Err</code> 的設計巧妙解決新值插入的問題。</li>
<li>和普通 insertion sort 雷同，從插入點至 sorted pile 迭代到末端以進行排序，省下不少比較操作。</li>
</ol>
<a class="header" href="#a參考資料-5" id="a參考資料-5"><h2>參考資料</h2></a>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Insertion_sort">Wiki: Insertion sort</a></li>
<li><a href="https://github.com/python/cpython/blob/15f44ab043b37c064d6891c7864205fed9fb0dd1/Objects/listsort.txt#L686-L703">CPython: listsort note</a></li>
<li>Sorting GIF by Swfung8 (Own work) <a href="https://creativecommons.org/licenses/by-sa/3.0">CC BY-SA 3.0</a> via Wikimedia Commons.</li>
</ul>
<a class="header" href="#a選擇排序-selection-sort" id="a選擇排序-selection-sort"><h1>選擇排序 Selection sort</h1></a>
<p>Selection sort 是最易實作的入門排序法之一，會將資料分為 sorted pile 與 unsorted pile，每次從 unsorted pile 尋找最大／最小值，加入 sorted pile 中。</p>
<p>Selection sort 的特性如下：</p>
<ul>
<li>最簡單的排序法之一。</li>
<li>對小資料序列排序效率較高。</li>
<li><strong>不穩定排序</strong>：排序後，相同鍵值的元素相對位置可能改變。</li>
<li><strong>原地排序</strong>：不需額外花費儲存空間來排序。</li>
</ul>
<a class="header" href="#a步驟-3" id="a步驟-3"><h2>步驟</h2></a>
<ol>
<li>將資料分為 sorted pile 與 unsorted pile。</li>
<li>從 unsorted pile 尋找最小值。</li>
<li>置換該最小值元素與 unsorted pile 第一個元素。</li>
<li>重複步驟 2 - 3，直到排序完成。</li>
</ol>
<blockquote>
<p>注意，這個 naïve 的 selection sort 實作為<strong>不穩定排序</strong>。</p>
</blockquote>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/9/94/Selection-Sort-Animation.gif" alt="" /></p>
<p><em>Joestape89 - CC BY-SA 3.0</em></p>
<a class="header" href="#a說明-2" id="a說明-2"><h2>說明</h2></a>
<p>為什麼 naïve 的 selection sort 會是不穩定排序？</p>
<p>假定有一個序列要遞增排序，其中有重複的 <code>2</code> 元素，我們將其標上 <code>2a</code>、<code>2b</code> 以利辨識。</p>
<pre><code>[2a, 3, 4, 2b, 1]
</code></pre>
<p>開始迭代找出最小值並指環。</p>
<pre><code class="language-bash"> *             *
[1, 3, 4, 2b, 2a] # 1. 置換 2a, 1

     *     *
[1, 2b, 4, 3, 2a] # 2. 置換 3, 2b

        *       *
[1, 2b, 2a, 3, 4] # 3. 置換 4, 2a
</code></pre>
<p>有沒有發現，<code>2a</code> 與 <code>2b</code> 的相對順序顛倒了呢？</p>
<p>首先，回想一下穩定排序的定義：<strong>相同鍵值的元素，排序後相對位置不改變。</strong></p>
<p>問題出在 naïve selection sort 是以置換的方式排序每次迭代的最小值。若我們將置換（swap）改為插入（insert），那麼 selection sort 就會是穩定排序，但相對地，需要位移剩餘未排序的元素，除非使用 linked list 或其他提供 $O(1) $ insertion 的資料結構，不然就會多出額外 $O(n^2) $ 的寫入成本。</p>
<a class="header" href="#a效能-4" id="a效能-4"><h2>效能</h2></a>
<table><thead><tr><th>              </th><th> Complexity    </th></tr></thead><tbody>
<tr><td> Worst        </td><td> $O(n^2) $ </td></tr>
<tr><td> Best         </td><td> $O(n^2) $ </td></tr>
<tr><td> Average      </td><td> $O(n^2) $ </td></tr>
<tr><td> Worst space  </td><td> $O(1) $ auxiliary </td></tr>
</tbody></table>
<p>對於接近排序完成的序列，selector sort 並無法有自適應的方式加快排序迭代。第一個元素要做 $n - 1 $ 次比較，第二個 $n - 2 $ 次，總比較次數如下：</p>
<p>$$ (n -1) + (n-2) + \cdots + 1 = \sum_{i=1}^{n-1} i = \frac{n(n - 1)}{2}$$</p>
<p>因此無論序列是否排序完成，selection sort 仍需執行 $n^2 $ 次比較，時間複雜度為 $O(n^2) $。</p>
<a class="header" href="#a實作-4" id="a實作-4"><h2>實作</h2></a>
<p>簡單實作如下：</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn selection_sort(arr: &amp;mut [i32]) {
    let len = arr.len();
    for i in 0..len {                     // 1
        let mut temp = i;
        for j in (i + 1)..len {           // 2
            if arr[temp] &gt; arr[j] {
                temp = j;
            }
        }
        arr.swap(i, temp);                // 3
    }
}
#}</code></pre></pre>
<ol>
<li>外層迴圈負責儲存當前要排序的 index <code>i</code> 的位置。</li>
<li>內層迴圈負責在 unsorted pile 範圍 [<code>i</code>, <code>len</code>) 找最小值。</li>
<li>外層迴圈在找到最小值之後，置換兩元素。</li>
</ol>
<p>眼尖的人會發現，內外兩層迴圈的 upper bound 都是 <code>len</code>，這樣是否內側迴圈會 out of bound？Rust 的 range operator（<code>core::ops::Range</code>）實作 <a href="https://doc.rust-lang.org/core/ops/struct.Range.html#impl-Iterator"><code>Iterator</code></a> trait 時，有檢查 <code>range.start &lt; range.end</code>，因此這個寫法並不會有出界問題，但會多跑一次無意義的迭代。</p>
<a class="header" href="#a變形-1" id="a變形-1"><h2>變形</h2></a>
<a class="header" href="#heapsort" id="heapsort"><h3>Heapsort</h3></a>
<p><a href="../heapsort/">Heapsort</a> 是一個高效的排序法，使用 selection sort 融合 <a href="https://en.wikipedia.org/wiki/Heap_(data_structure)">heap</a> 這種半排序的資料結構，讓時間複雜度進化至 $O(n \log n) $。更多詳情可以參考<a href="../heapsort/">這篇介紹</a>。</p>
<a class="header" href="#a參考資料-6" id="a參考資料-6"><h2>參考資料</h2></a>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Selection_sort">Wiki: Selection sort</a></li>
<li><a href="https://stackoverflow.com/questions/20761396/">Why Selection sort can be stable or unstable</a></li>
<li>Sorting GIF by Joestape89 <a href="http://creativecommons.org/licenses/by-sa/3.0/">CC-BY-SA-3.0</a> via Wikimedia Commons.</li>
</ul>
<a class="header" href="#a氣泡排序-bubble-sort" id="a氣泡排序-bubble-sort"><h1>氣泡排序 Bubble sort</h1></a>
<p>Bubble sort 是最簡單的排序法之一，由於排序時每個元素會如同泡泡般，一個一個浮出序列頂部，因而得名。由於其簡單好理解，名稱又有趣，常作為第一個學習的入門排序法。不過其效率不彰，甚至不如同為 quardratic time 的 insertion sort。Bubble sort 的原理很平凡，就是相鄰兩兩元素互相比較，如果大小順序錯了，就置換位置。再往下一個 pair 比較。</p>
<p>Bubble sort 的特性如下：</p>
<ul>
<li>又稱為 <strong>sinking sort</strong>。</li>
<li><strong>穩定排序</strong>：相同鍵值的元素，排序後相對位置不改變。</li>
<li><strong>原地排序</strong>：不需額外花費儲存空間來排序。</li>
</ul>
<a class="header" href="#a步驟-4" id="a步驟-4"><h2>步驟</h2></a>
<ol>
<li>比較兩個相鄰元素，若首個元素比次個元素大，置換兩者的位置。</li>
<li>依序對相鄰元素執行步驟一，直到抵達序列頂端，此時頂端元素排序完成。</li>
<li>重複步驟 1 - 2 的整個序列迭代，直到任何一次迭代沒有執行元素置換。</li>
</ol>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/c/c8/Bubble-sort-example-300px.gif" alt="" />
<em>Swfung8 - CC BY-SA 3.0</em></p>
<a class="header" href="#a說明-3" id="a說明-3"><h2>說明</h2></a>
<p>給定一組序列 <code>[5, 3, 8, 7, 2]</code>，以 bubble sort 遞增排序。以 ASCII diagram 表示：</p>
<p><strong>第一次迭代</strong></p>
<pre><code class="language-bash"> *  *               *  *
[5, 3, 8, 7, 4] -&gt; [3, 5, 8, 7, 4] # 置換 3 與 5

    *  *               *  *
[3, 5, 8, 7, 4] -&gt; [3, 5, 8, 7, 4] # 不需置換

       *  *               *  *
[3, 5, 8, 7, 4] -&gt; [3, 5, 7, 8, 4] # 置換 7 與 8

          *  *               *  *
[3, 5, 7, 8, 4] -&gt; [3, 5, 7, 4, 8] # 置換 4 與 8，8 已排好序
</code></pre>
<p><strong>第二次迭代</strong></p>
<pre><code class="language-bash"> *  *               *  *
[3, 5, 7, 4, 8] -&gt; [3, 5, 7, 4, 8] # 不需置換

    *  *               *  *
[3, 5, 7, 4, 8] -&gt; [3, 5, 7, 4, 8] # 不需置換

       *  *               *  *
[3, 5, 7, 4, 8] -&gt; [3, 5, 4, 7, 8] # 置換 4 與 7

          *  *               *  *
[3, 5, 4, 7, 8] -&gt; [3, 5, 4, 7, 8] # 不需置換
</code></pre>
<blockquote>
<p>naïve bubble sort 會跑完整個序列，即是已排序完成。</p>
</blockquote>
<p><strong>第三次迭代</strong></p>
<pre><code class="language-bash"> *  *               *  *
[3, 5, 4, 7, 8] -&gt; [3, 5, 4, 7, 8] # 不需置換

    *  *               *  *
[3, 5, 4, 7, 8] -&gt; [3, 4, 5, 7, 8] # 置換 4 與 5

       *  *               *  *
[3, 5, 4, 7, 8] -&gt; [3, 4, 5, 7, 8] # 不需置換

          *  *               *  *
[3, 5, 4, 7, 8] -&gt; [3, 4, 5, 7, 8] # 不需置換
</code></pre>
<p><strong>第四次迭代</strong></p>
<pre><code class="language-bash"> *  *               *  *
[3, 4, 5, 7, 8] -&gt; [3, 4, 5, 7, 8] # 不需置換

    *  *               *  *
[3, 4, 5, 7, 8] -&gt; [3, 4, 5, 7, 8] # 不需置換

       *  *               *  *
[3, 4, 5, 7, 8] -&gt; [3, 4, 5, 7, 8] # 不需置換

          *  *               *  *
[3, 4, 5, 7, 8] -&gt; [3, 4, 5, 7, 8] # 不需置換
</code></pre>
<p>很簡單的排序法！</p>
<a class="header" href="#a效能-5" id="a效能-5"><h2>效能</h2></a>
<table><thead><tr><th>              </th><th> Complexity    </th></tr></thead><tbody>
<tr><td> Worst        </td><td> $O(n^2) $ </td></tr>
<tr><td> Best         </td><td> $O(n) $   </td></tr>
<tr><td> Average      </td><td> $O(n^2) $ </td></tr>
<tr><td> Worst space  </td><td> $O(1) $ auxiliary </td></tr>
</tbody></table>
<a class="header" href="#time-complexity" id="time-complexity"><h3>Time complexity</h3></a>
<p>Bubble sort 總共需要 $n - 1 $ 次迭代，每次迭代至少需要執行 $n - 1 - i $ 置換（ $i $ 為第幾次迭代），總共需要迭代</p>
<p>$$\sum_{i=0}^{n-1} (n - i - 1) = n^2 - \sum_{i=0}^{n-1}i - n = n^2 - \frac{n(n - 1)}{2} - n = \frac{n^2}{2} - \frac{n}{2}$$</p>
<p>次，因此，時間複雜度為 $O(n^2) $。</p>
<p>Bubble sort 在已排序完成的序列上，只需要迭代序列一次，發現完全沒有置換任何元素，即停止排序，可達到最佳時間複雜度。</p>
<a class="header" href="#a實作-5" id="a實作-5"><h2>實作</h2></a>
<p>Bubble sort 簡單實作如下：</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn bubble_sort(arr: &amp;mut [i32]) {
    let mut swapped = true;                 // 1
    while swapped {
        swapped = false;
        for i in 1..arr.len() {             // 2
            if arr[i - 1] &gt; arr[i] {
                arr.swap(i - 1, i);
                swapped = true              // 3
            }
        }
    }
}
#}</code></pre></pre>
<ol>
<li>建立一個旗標，標誌該次迭代是否有元素置換。</li>
<li>內層迴圈依序比較兩兩相鄰元素。</li>
<li>若有任何置換動作，將旗標標誌為「已置換（<code>true</code>）」。</li>
</ol>
<p>倘若記錄已排好序的元素位置，雖然複雜度仍是 $O(n^2) $，但如此以來，每次迭代都可少一次元素比較，對比較操作成本高的語言或實作來說，仍不失為最佳化的方法。程式碼如下：</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn bubble_sort_optimized(arr: &amp;mut [i32]) {
    let mut new_len: usize;
    let mut len = arr.len();            // 1
    loop {
        new_len = 0;
        for i in 1..len {
            if arr[i - 1] &gt; arr[i] {
                arr.swap(i - 1, i);
                new_len = i;            // 2
            }
        }
        if new_len == 0 {               // 3
            break;
        }
        len = new_len;                  // 4
    }
}
#}</code></pre></pre>
<ol>
<li>將當前的序列長度記錄到 <code>len</code>。</li>
<li>內層迴圈負責比較、置換，以及記錄未排序部分的序列長度到 <code>new_len</code>。</li>
<li>若未排序部分 <code>new_len</code> 為零，代表排序完成。</li>
<li>外層迴圈將新長度值 <code>new_len</code> 賦予 <code>len</code>，下一次迭代就可少做一次比較。</li>
</ol>
<a class="header" href="#a參考資料-7" id="a參考資料-7"><h2>參考資料</h2></a>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Bubble_sort">Wiki: Bubble sort</a></li>
<li>Sorting GIF was created by Swfung8 (Own work) <a href="https://creativecommons.org/licenses/by-sa/3.0">CC BY-SA 3.0</a> via Wikimedia Commons.</li>
</ul>
<a class="header" href="#a希爾排序-shellsort" id="a希爾排序-shellsort"><h1>希爾排序 Shellsort</h1></a>
<p>眾所周知，<a href="../insertion_sort">Insertion sort</a> 用在幾乎完成排序的序列上非常高效，換句話說，當元素置換不需移動太遠時，效率很高。反之，如果有元素錯位非常遙遠，效能就會大打折扣。Shellsort 以一個 gap sequence 將資料依指定的間隔（gap）分組進行 insertion sort，使得較遠的元素能夠快速歸位，下一次的排序就會因前次排序結果愈來愈接近完成而加速。</p>
<p>Shellsort 最後一個 gap 必定是 1，也就是排序會退化成 insertion sort，此時大部分元素皆排序完成，insertion sort 會非常高效。</p>
<p>Shellsort 特性如下：</p>
<ul>
<li><strong>自適應排序</strong>：可根據當前資料排序情形加速排序，資料越接近排序完成，效率越高。</li>
<li><strong>不穩定排序</strong>：排序後，相同鍵值的元素相對位置可能改變。</li>
<li><strong>原地排序</strong>：不需額外花費儲存空間來排序。</li>
<li>可視為一般化（Generalizaion）的 <a href="../insertion_sort">insertion sort</a>。</li>
</ul>
<a class="header" href="#a步驟-5" id="a步驟-5"><h2>步驟</h2></a>
<p>Shellsort 分為兩個步驟：</p>
<ol>
<li>決定一組 gap sequence。</li>
<li>迭代 gap sequence 進行分組排序，每次執行有間隔的 insertion sort。也就是每個元素與其相鄰 gap 的元素比較與置換。</li>
</ol>
<blockquote>
<p>最後一次排序（gap = 1）會退化為 insertion sort，完成整個排序。</p>
</blockquote>
<a class="header" href="#gap-sequneces" id="gap-sequneces"><h3>Gap Sequneces</h3></a>
<p>Shellsort 的效率取決於 gap sequence 的選擇，這邊舉幾個常見的 gap sequence：</p>
<table><thead><tr><th>              </th><th> Sequence                        </th></tr></thead><tbody>
<tr><td> Marcin Ciura </td><td> 1, 4, 10, 23, 57, 132, 301, 701 </td></tr>
<tr><td> $2^{k} - 1 $  </td><td> 1, 3, 7, 15, 31, 63,...         </td></tr>
<tr><td> $\lfloor {\frac {N}{2^k}} \rfloor $ </td><td> $\lfloor {\frac {N}{2}} \rfloor $, $\lfloor {\frac {N}{4}} \rfloor $, ..., 1</td></tr>
</tbody></table>
<p>感受一下 gap sequence 為 23, 10, 4, 1 的 shellsort 吧。</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/d/d8/Sorting_shellsort_anim.gif" alt="" /></p>
<a class="header" href="#a說明-4" id="a說明-4"><h2>說明</h2></a>
<p>Shellsort 其實就是進行好幾次不同 gap 的 insertion sort，以下用 ASCII diagram 解釋。</p>
<p>假定這裡有一個序列需要遞增排序。</p>
<pre><code>[5, 3, 8, 7, 4, 9, 6, 2]
</code></pre>
<p>我們選擇最簡單的 $\lfloor {\frac {N}{2^k}} \rfloor $ gap sequence 來排序。我們以<strong>星號</strong>標示出每次 insertion sort 對應排序</p>
<p>首先算出第一個 gap 為 $8 / 2^1 = 4 $。開始 insertion sort。</p>
<pre><code> *           *
[5, 3, 8, 7, 4, 9, 6, 2]

-&gt; (sort subsequence [5, 4])

    *           *
[4, 3, 8, 7, 5, 9, 6, 2]

-&gt; (skip)
       *           *
[4, 3, 8, 7, 5, 9, 6, 2]

-&gt; (sort subsequence [8, 6])
          *           *
[4, 3, 6, 7, 5, 9, 8, 2]

-&gt; (sort subsequence [7, 2])

[4, 3, 8, 2, 5, 9, 6, 7]
</code></pre>
<p>再來算出第二個 gap 為 $8 / 2^2 = 2 $。開始 insertion sort。</p>
<pre><code> *     *
[4, 3, 8, 2, 5, 9, 6, 7]

-&gt; (skip)
    *     *
[4, 3, 8, 2, 5, 9, 6, 7]

-&gt; (sort subsequence [3, 2])
 *     *     *
[4, 2, 8, 3, 5, 9, 6, 7]

-&gt; (sort subsequence [4, 8, 5])
    *     *     *
[4, 2, 5, 3, 8, 9, 6, 7]

-&gt; (skip)
 *     *     *     *
[4, 2, 5, 3, 8, 9, 6, 7]

-&gt; (sort subsequence [4, 5, 8, 6])
    *     *     *     *
[4, 2, 5, 3, 6, 9, 8, 7]

-&gt; (sort subsequence [2, 3, 9, 7])
[4, 2, 5, 3, 6, 7, 8, 9]
</code></pre>
<p>再來進行第三次排序。gap 為 $8 / 2^3 = 1 $，shellsort 退化至 insertion sort，但前一次結果已經很接近排序完成，insertion sort 可以幾乎在 one pass 完成排序。</p>
<blockquote>
<p>Insertion sort 的 ASCII diagram 我們就不展示了，請參考 <a href="../insertion_sort">Insertion sort</a>。</p>
</blockquote>
<a class="header" href="#a效能-6" id="a效能-6"><h2>效能</h2></a>
<table><thead><tr><th>              </th><th> Complexity                                            </th></tr></thead><tbody>
<tr><td> Worst        </td><td> $O(n^2) $ ~  $O(n \log^2 n) $ (Depends on gap sequence) </td></tr>
<tr><td> Best         </td><td> $O(n \log n) $                                    </td></tr>
<tr><td> Average      </td><td> Depends on gap sequence                               </td></tr>
<tr><td> Worst space  </td><td> $O(1) $ auxiliary                                 </td></tr>
</tbody></table>
<p>Shellsort 的複雜度不容易計算，取決於 gap sequence 怎麼安排，太少 gap 會讓速度太接近 insertion sort，太多 gap 則會有過多額外開銷。目前已知的 gap sequence 中，最差時間複雜度可以達到 $O(n \log^2 n) $，有著不錯的表現。有興趣可以參考<a href="http://www.dtic.mil/get-tr-doc/pdf?AD=AD0740110">這篇文章</a>。</p>
<a class="header" href="#a實作-6" id="a實作-6"><h2>實作</h2></a>
<p>我們這裡以 <a href="http://sun.aei.polsl.pl/%7Emciura/publikacje/shellsort.pdf">Marcin 的 Paper</a> 中提到的經驗式為例，首先，先建立一個 gap sequence 的常數。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
/// Marcin Ciura's gap sequence.
pub const MARCIN_GAPS: [usize; 8] = [701, 301, 132, 57, 23, 10, 4, 1];
#}</code></pre></pre>
<p>再來就是主程式的部分，總共會有三個迴圈，</p>
<ul>
<li>最外層是迭代 gap sequence，</li>
<li>中間層是迭代整個資料序列，</li>
<li>內層就是每個元素的插入排序動作。</li>
</ul>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
/// Shellsort
pub fn shellsort(arr: &amp;mut [i32]) {
    let len = arr.len();
    for gap in MARCIN_GAPS.iter() {                     // 1
        let mut i = *gap;                               // 4
        while i &lt; len {                                 // 2
            let mut j = i;
            while j &gt;= *gap &amp;&amp; arr[j - gap] &gt; arr[j] {  // 3
                arr.swap(j - *gap, j);
                j -= *gap;
            }
            i += 1;
        }
    }
}
#}</code></pre></pre>
<ol>
<li>最外層的迴圈，利用 <code>iter()</code> trait 產生迭代器，迭代 gap sequence。</li>
<li>中間層迴圈，控制 <code>i</code> 是否超出資料序列，以迭代整合資料序列。</li>
<li>最內層迴圈，執行插入動作，將每個元素置換到正確位置。</li>
<li>由於 <code>gap</code> 的型別是 <code>&amp;usize</code>，需透過 <code>*gap</code> dereference 得到 <code>usize</code> 型別。</li>
</ol>
<a class="header" href="#a參考資料-8" id="a參考資料-8"><h2>參考資料</h2></a>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Shellsort">Wiki: Shellsort</a></li>
<li><a href="http://sun.aei.polsl.pl/%7Emciura/publikacje/shellsort.pdf">Best Increments for the Average Case of Shellsort, M. Ciura, 2001</a></li>
<li><a href="http://www.dtic.mil/get-tr-doc/pdf?AD=AD0740110">Shellsort and Sorting Networks (Outstanding Dissertations in the Computer Sciences)</a></li>
</ul>
<a class="header" href="#a高效排序" id="a高效排序"><h1>高效排序</h1></a>
<ul>
<li><a href="heapsort">堆積排序 Heapsort</a></li>
<li><a href="quicksort">快速排序 Quicksort</a></li>
<li><a href="mergesort">合併排序 Mergesort</a></li>
</ul>
<a class="header" href="#a堆積排序-heapsort" id="a堆積排序-heapsort"><h1>堆積排序 Heapsort</h1></a>
<p>Heapsort（堆積排序）可以看作是 <a href="../selection_sort">selection sort</a> 的變形，同樣會將資料分為 sorted pile 與 unsorted pile，並在 unsorted pile 中尋找最大值（或最小值），加入 sorted pile 中。</p>
<p>和 selection sort 不同之處是，heapsort 利用<a href="https://en.wikipedia.org/wiki/Heap_(data_structure)">堆積（heap）</a>這種半排序（partially sorted）的資料結構輔助並加速排序。</p>
<p>Heapsort 的特性如下：</p>
<ul>
<li>使用 <a href="https://en.wikipedia.org/wiki/Heap_(data_structure)">heap</a> 資料結構輔助，通常使用 <a href="https://en.wikipedia.org/wiki/Binary_heap">binary heap</a>。</li>
<li><strong>不穩定排序</strong>：排序後，相同鍵值的元素相對位置可能改變。</li>
<li><strong>原地排序</strong>：不需額外花費儲存空間來排序。</li>
<li><strong>較差的 CPU 快取</strong>：heap 不連續存取位址的特性，不利於 <a href="https://en.wikipedia.org/wiki/CPU_cache">CPU 快取</a>。</li>
</ul>
<a class="header" href="#a步驟-6" id="a步驟-6"><h2>步驟</h2></a>
<p>Heapsort 的演算法分為兩大步驟：</p>
<ol>
<li>將資料轉換為 heap 資料結構（遞增排序用 max-heap, 遞減排序選擇 min-heap）。</li>
<li>逐步取出最大／最小值，並與最後一個元素置換。具體步驟如下：
<ol>
<li>交換 heap 的 root 與最後一個 node，縮小 heap 的範圍（排序一筆資料，故 heap 長度 -1）。</li>
<li>更新剩下的資料，使其滿足 heap 的特性，稱為 heap ordering property。</li>
<li>重複前兩個步驟，直到 heap 中剩最後一個未排序的資料。</li>
</ol>
</li>
</ol>
<p>透過 GIF 動畫感受一下 heapsort 的威力吧！</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/1/1b/Sorting_heapsort_anim.gif" alt="" /></p>
<a class="header" href="#a說明-5" id="a說明-5"><h2>說明</h2></a>
<p>在開始之前，定義幾個 heap 常用名詞：</p>
<ul>
<li><strong>Heap ordering property</strong>：一個 heap 必須要滿足的條件。以 heap 種類不同有幾種變形。
<ul>
<li><strong>min-heap property</strong>：每個結點皆大於等於其父節點的值，且最小值在 heap root。</li>
<li><strong>max-heap property</strong>：每個結點皆小於等於其父節點的值，且最大值在 heap root。</li>
</ul>
</li>
</ul>
<p>而 heapsort 主要分為兩個部分：</p>
<ol>
<li><strong>Heapify</strong>：將陣列轉換為 heap 資料結構（heapify）。</li>
<li><strong>Sorting</strong>：不斷置換 heap root 與最後一個元素來排序，並修正剩餘未排序資料使其符合 heap order。</li>
</ol>
<p>這裡有一個未排序的序列，將以遞增方向排序之。</p>
<pre><code>[17, 20, 2, 1, 3, 21]
</code></pre>
<p>首先，將資料轉換為 heap 資料結構，這個步驟即時 <strong>heapify</strong>。由於是遞增排序，我們採用 max-heap（最大元素在 root）。</p>
<pre><code>[21, 20, 17, 1, 3, 2]
</code></pre>
<p>對應的二元樹（binary tree）的圖形如下：</p>
<p><img src="tree.png" height="300px" /></p>
<p>再來就是<strong>排序的部分</strong>，Max-heap 會將最大的元素擺在 root 的位置，我們先將最後一個 node 與 root 進行交換，完成第一個排序步驟。</p>
<blockquote>
<p>若不熟悉 heap，可以閱讀 <a href="https://en.wikipedia.org/wiki/Heap_(data_structure)">Wiki 的介紹</a>，其實 heap 就是用陣列實作的二元樹。</p>
</blockquote>
<pre><code>[21, 20, 17, 1, 3, 2]
 *                 *
(swap) --&gt;

        unsorted | sorted
[2, 20, 17, 1, 3 | 21]
</code></pre>
<p>接下來，將未排序的資料區塊重整為符合 max-heap 的結構。</p>
<pre><code>[2, 20, 17, 1, 3 | 21]

(sift down) --&gt;

[20, 3, 17, 1, 2 | 21]
</code></pre>
<p>有沒有看出一些端倪？</p>
<p>只要不斷將 root 和最後一個 node 交換，並將剩餘資料修正至滿足 heap ordering，就完成排序了。</p>
<pre><code>[20, 3, 17, 1, 2 | 21]
 *             *
(swap) --&gt;

[2, 3, 17, 1 | 20, 21]

(sift down)--&gt;

[17, 3, 2, 1 | 20, 21]
 *         *
(swap) --&gt;

[1, 3, 2 | 17, 20, 21]

(sift down)--&gt;

[3, 1, 2 | 17, 20, 21]
 *     *
(swap) --&gt;

[1, 2 | 3, 17, 20, 21]

(Done!)
</code></pre>
<p>以上便是 heapsort 演算法的簡單流程，是不是和 selection sort 非常相似呢！</p>
<a class="header" href="#a效能-7" id="a效能-7"><h2>效能</h2></a>
<table><thead><tr><th>              </th><th> Complexity         </th></tr></thead><tbody>
<tr><td> Worst        </td><td> $O(n \log n) $ </td></tr>
<tr><td> Best         </td><td> $O(n \log n) $ </td></tr>
<tr><td> Average      </td><td> $O(n \log n) $ </td></tr>
<tr><td> Worst space  </td><td> $O(1) $ auxiliary </td></tr>
</tbody></table>
<p>Heapsort 最佳、最差、平均的時間複雜度皆為 $O(n \log n) $，同樣分為兩部分簡單解釋。</p>
<a class="header" href="#build-heap-heapify" id="build-heap-heapify"><h3>Build heap (heapify)</h3></a>
<p>建立一個 binary heap 有兩種方法，一種是一個個元素慢慢加入 heap 來建立；另一種則是給定隨意的序列，再透過 heapify 演算法修正序列為有效的 heap。一般來說 heapsort 常用實作後者。</p>
<p><strong>Heapify</strong> 是指將序列修正至符合 heap ordering 的序列。給定一個元素，假定其為非法的 heap order，而該元素之後的 subtree 視為符合 heap ordering property。欲修正這個在錯誤位置的元素，必須透過與其 children node 置換往下篩，這個往下篩的過程就稱為 <strong>sift down</strong>，在<a href="#%E5%AF%A6%E4%BD%9C">實作</a>一節會詳細解釋，這邊只要知道 sift down 會不斷將該元素與其 child node 比較，若不符合 heap order 則與 child node 置換，並繼續迭代每一個 level。所以 sift down 的時間複雜度為 $O(\lceil {\log_2(n)} \rceil) = O(\log n) $， $n $ 為陣列元素個數。</p>
<p>Heapify 從最末個元素開始反向迭代，每個元素都調用 <code>sift_down</code> 調整 heap 符合 heap ordering。總共要做 $n $ 次 <code>sift_down</code> 操作，但由於最後一層所以 leaf 已符合 heap order（因為沒有 child node），我們的迴圈可以跳過所有 leaf node 直接從非 leaf node 開始，因此複雜度為</p>
<p>$$\lfloor n / 2 \rfloor \cdot O(\log n) = O(n \log n)$$</p>
<blockquote>
<p>實際上，build heap 步驟的複雜度可達到 $O(n) $，可以看看 UMD 演算法課程 <a href="http://www.cs.umd.edu/%7Emeesh/351/mount/lectures/lect14-heapsort-analysis-part.pdf">Lecture note 的分析</a>。</p>
</blockquote>
<a class="header" href="#sorting-sift-down" id="sorting-sift-down"><h3>Sorting (sift down)</h3></a>
<p>講完了 heapify，就換到排序部分，所謂的排序其實就是利用 max-heap（或 min-heap）的最大值（最小值）會在首個元素的特性，與最後一個元素置換，完成排序，並將剩餘的部分透過 <strong>sift down</strong> 修正符合 heap order。所以總共需要做 $n $ 次 sift down，複雜度為 $O(n \log n) $。</p>
<a class="header" href="#sum-up" id="sum-up"><h3>Sum up</h3></a>
<p>綜合這兩部分，可以看出 Sorting part 對複雜度有決定性影響，最佳複雜度為 $O(n \log n) $。</p>
<a class="header" href="#a實作-7" id="a實作-7"><h2>實作</h2></a>
<p>Heapsort 的實作相對簡單，只需要不斷調用 heap 內部的 <code>sift_down</code> 方法就可以完成排序。整個演算法架構如下：</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn heapsort(arr: &amp;mut [i32]) {
    // -- Heapify part --
    // This procedure would build a valid max-heap.
    // (or min-heap for sorting descendantly)
    let end = arr.len();
    for start in (0..end / 2).rev() {                   // 1
        sift_down(arr, start, end - 1);
    }

    // -- Sorting part --
    // Iteratively sift down unsorted part (the heap).
    for end in (1..arr.len()).rev() {                   // 2
        arr.swap(end, 0);                               // 3
        sift_down(arr, 0, end - 1);                     // 4
    }
}
#}</code></pre></pre>
<ol>
<li>這部分是 heapify，從最小 non-leaf node 開始（<code>end</code> / 2），修正序列至滿足 heap order，再反向迭代做 heapify。</li>
<li>這部分負責排序，每次迭代都將排序 heap 的 root 元素，步驟如 3 - 4：</li>
<li>不斷將 max-heap 中最大值（在 root 上）與 heap 最後一個元素 <code>end</code> 置換，</li>
<li>並利用 <code>sift_down</code> 將序列修正至 max-heap 資料結構，依照定義，此時 unsorted pile 首個元素成為 max-heap root，是最大值。</li>
</ol>
<p>Heapsort 全靠 <code>sift_down</code> 神救援，那 <code>sift_down</code> 到底有什麼神奇魔力，一探究竟吧！</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
fn sift_down(arr: &amp;mut [i32], start: usize, end: usize) {
    let mut root = start;
    loop {
        let mut child = root * 2 + 1; // Get the left child   // 1
        if child &gt; end {
            break;
        }
        if child + 1 &lt;= end &amp;&amp; arr[child] &lt; arr[child + 1] {  // 2
            // Right child exists and is greater.
            child += 1;
        }

        if arr[root] &lt; arr[child] {                           // 3
            // If child is greater than root, swap'em!
            arr.swap(root, child);
            root = child;
        } else {
            break;
        }
    }
}
#}</code></pre></pre>
<p><code>sift_down</code> 的功能是將 node 往下移。通常用在 heap 刪除或取代 node 時，將序列修正為有效的 heap。 這裡實作的版本有三個參數：</p>
<ul>
<li><code>arr</code>：欲修正為符合 heap 定義的序列。</li>
<li><code>start</code>：欲往下移動的 node index，可視為需要被修正的元素。</li>
<li><code>end</code>：此 node 以內（包含）的序列都會被修正為有效的 heap。</li>
</ul>
<p><code>sift_down</code> 有些假設條件：從 <code>start</code> index 出發的子樹，除了 <code>start</code> 本身以外，其他皆符合 heap ordering。</p>
<p>再來看看 <code>sift_down</code> 實作內容，<code>loop</code> 中幹的活就是不斷將 <code>start</code> index 上的元素與其子樹比較，若不符合 heap ordering，則兩者置換。</p>
<ol>
<li><strong>是否有子結點</strong>：依照 binary heap 的定義找出 root 的左子樹（left substree），若左子樹的 index <code>child</code> 比 <code>end</code> 還大，表示沒有 heap 沒有子結點，停止迭代。</li>
<li><strong>檢查右子樹值較大</strong>：若 root 下有右子樹且較大，我們會標記右子樹，並在下一步對右子樹進行處理。</li>
<li><strong>置換</strong>：若 <code>root</code> 元素比 <code>child</code> 的元素小，則置換兩者，並將 <code>child</code> 設置為下個迭代的 <code>root</code>，繼續檢查最初的 <code>start</code> 元素是否滿足 heap ordering。</li>
</ol>
<p>以上就是簡單的 <code>sift_down</code> 實作，也是整個 heapsort 的精髓。</p>
<a class="header" href="#a參考資料-9" id="a參考資料-9"><h2>參考資料</h2></a>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Heap_(data_structure)">Wiki: Heap</a></li>
<li><a href="https://en.wikipedia.org/wiki/Heapsort">Wiki: Heapsort</a></li>
<li><a href="www.cs..html">CMSC 351 Algorithms, Fall, 2011, University of Maryland.</a></li>
<li>Sorting GIF by RolandH <a href="http://creativecommons.org/licenses/by-sa/3.0/">CC-BY-SA-3.0</a> via Wikimedia Commons.</li>
</ul>
<a class="header" href="#a快速排序-quicksort" id="a快速排序-quicksort"><h1>快速排序 Quicksort</h1></a>
<p>Quicksort 是一個非常熱門且應用廣泛的排序法，相對簡單的實作就可達到 $O(n \log n) $ 的平均時間複雜度。雖然最差時間複雜度與 <a href="../bubble_sort">bubble sort</a> 同為 $O(n^2) $，但這種情形非常少見。簡單的最佳化實作下，Quicksort 僅需 $O(\log n) $ 的額外儲存空間，比它的競爭對手 <a href="../mergesort">mergesort</a> 來得節省。非常適合運用在真實世界中的排序法。</p>
<p>Quicksort 基本特性如下：</p>
<ul>
<li>實作簡單，速度快。</li>
<li><strong>不穩定排序</strong>：排序後，相同鍵值的元素相對位置可能改變。</li>
<li><strong>非原地排序</strong>：除了資料本身，仍需額外花費儲存空間來排序。</li>
<li><strong>分治演算法</strong>：將主問題化作數個子問題，各個擊破。</li>
</ul>
<a class="header" href="#a步驟-7" id="a步驟-7"><h2>步驟</h2></a>
<p>Quicksort 是一個分治演算法（divide-and-conquer），不斷遞迴下列三個步驟：</p>
<ol>
<li><strong>選擇 Pivot</strong>：在序列中任意選擇一個元素，稱為 <strong>Pivot</strong>。</li>
<li><strong>分割序列</strong>：將序列重新排序，分為兩部分，比 pivot 小 的元素置換到 pivot 之前，比 pivot 大的元素置換到 pivot 之後，而 pivot 本身會座落在它最終的正確位置。</li>
<li><strong>遞迴</strong>：分別將_比 pivot 小_，以及_比 pivot 大_ 兩部分分別重複上述步驟，直到新序列的長度小於等於 1，無法繼續分割為止，此時排序完成。</li>
</ol>
<a class="header" href="#lomuto-partition-scheme" id="lomuto-partition-scheme"><h3>Lomuto partition scheme</h3></a>
<p>為了達成上述條件，Quicksort 有許多不同的分割序列實作方案（partition scheme），其中以 Lomuto partition 最易理解，常被做為教材。</p>
<ol>
<li>以序列最後一個元素當做 pivot。</li>
<li>利用兩個指標 <code>i</code> <code>j</code>，其中 <code>j</code> 從頭迭代整個序列
<ul>
<li>若有序列第 j 個元素小於 pivot，則與第 i 個元素置換。</li>
<li>第 i 個元素已落在小於 pivot 的範圍，將 i 指標往後移一個，處理下個元素。</li>
</ul>
</li>
<li>迭代完成後，小於 pivot 的元素全都置換至序列前端，此時將 pivot 與第 i 個元素置換，pivot 會剛好在最終正確位置上（符合不等式）。</li>
</ol>
<p>ASCII 畫出來的分割圖如下：</p>
<pre><code>[ values &lt;= pivot | values &gt; pivot | not checked yet | pivot ]
  low           i   i+1        j-1   j        high-1   high
</code></pre>
<ul>
<li><code>arr[low...i]</code> 包含所有小於等於 pivot 的元素。</li>
<li><code>arr[i+1...j-1]</code> 包含所有大於 pivot 的元素。</li>
<li><code>arr[j...high-1]</code> 包含所有尚未迭代的元素。</li>
<li><code>arr[high]</code> pivot 本身。</li>
</ul>
<a class="header" href="#a說明-6" id="a說明-6"><h2>說明</h2></a>
<p>以 Lomuto partition scheme 為例，使用 ASCII diagram 解釋。</p>
<p>給定一個序列，並選擇最後一個元素作為 pivot，<code>i</code> <code>j</code> 指標則在第一個元素位置。</p>
<pre><code>                      * -&gt; pivot
[17, 20, 2, 1, 3, 21, 8]
 i
 j
</code></pre>
<p>第 <code>j</code> 個元素 17 大於 pivot 8，不置換。</p>
<pre><code>17 &gt; 8, no swap
                       * -&gt; pivot
[17| 20, 2, 1, 3, 21, 8]
 i
 j
</code></pre>
<p>第 <code>j</code> 個元素 20 大於 pivot 8，不置換。</p>
<pre><code>20 &gt; 8, no swap
                      * -&gt; pivot
[17, 20| 2, 1, 3, 21, 8]
 i
     j
</code></pre>
<p>第 <code>j</code> 個元素 2 小於 pivot 8，置換 <code>i</code> <code>j</code>。<code>i</code> 往後一個位置。</p>
<pre><code>2 &lt;= 8,
swap i, j
                      * -&gt; pivot
[2, 20, 17| 1, 3, 21, 8]
 i-&gt;i
        j
</code></pre>
<p>第 <code>j</code> 個元素 1 小於 pivot 8，置換 <code>i</code> <code>j</code>。<code>i</code> 往後一個位置。</p>
<pre><code>1 &lt;= 8
swap i, j
                      * -&gt; pivot
[2, 1, 17, 20| 3, 21, 8]
    i-&gt;i
            j
</code></pre>
<p>第 <code>j</code> 個元素 3 小於 pivot 8，置換 <code>i</code> <code>j</code>。<code>i</code> 往後一個位置。</p>
<pre><code>3 &lt;= 8
swap i, j
                      * -&gt; pivot
[2, 1, 3, 20, 17| 21, 8]
       i-&gt;i
               j
</code></pre>
<p>第 <code>j</code> 個元素 21 大於 pivot 8，不置換。</p>
<pre><code>21 &gt; 8, no swap
                      * -&gt; pivot
[2, 1, 3, 20, 17, 21| 8]
           i
                   j
</code></pre>
<p>最後，將 pivot 與第 <code>i</code> 個元素置換，此時 pivot 已在最終位置上，前面的元素皆小於等於 8，其後的元素皆大於 8。</p>
<pre><code>swap pivot, i
          i    &lt;-&gt;   * -&gt; pivot
[2, 1, 3, 8, 17, 21, 20]
</code></pre>
<p>這樣就完成一次的 partition 了！</p>
<p>之後再遞迴分割 subarray 即可完成 Quicksort。</p>
<pre><code>[2, 1, 3, 8, 17, 21, 20]
 #     #     *       *
 |     |     |       |
 -------     ---------
 quicksort    quicksort
</code></pre>
<a class="header" href="#a效能-8" id="a效能-8"><h2>效能</h2></a>
<table><thead><tr><th>              </th><th> Complexity         </th></tr></thead><tbody>
<tr><td> Worst        </td><td> $O(n^2) $      </td></tr>
<tr><td> Best         </td><td> $O(n \log n) $ </td></tr>
<tr><td> Average      </td><td> $O(n \log n) $ </td></tr>
<tr><td> Worst space  </td><td> $O(\log n) $ or $O(n) $ auxiliary </td></tr>
</tbody></table>
<a class="header" href="#time-complexity-1" id="time-complexity-1"><h3>Time complexity</h3></a>
<p>Quicksort 僅有「<strong>選擇 Pivot</strong>」與「<strong>分割序列</strong>」兩步驟，不同的實作的效能各異，也影響 Quicksort 的時間複雜度。</p>
<a class="header" href="#a最差情況" id="a最差情況"><h4>最差情況</h4></a>
<p>最差的分割序列狀況發生在挑選的 pivot 總是最大或最小值（或在 Lomuto partition 下，所有元素值都一樣）。由於 Lomuto 總是選擇最後一個元素作為 pivot，這種情形好發於已排序或接近排序完成的資料上。</p>
<p>而當每次的 partition 都是最不平衡的分割序列，就會產生最差時間複雜度的狀況。遞迴在序列長度等於 1 時停止，因此整個排序法的 call stack 需要 $n - 1 $ 的嵌套遞迴調用（nested call）；而第 $i $ 次分割會執行 $n - i $ 次基本操作（ $O(n) $），所以總共需執行</p>
<p>$$\sum_{i = 0}^n (n - i) = n^2 - \frac{n(n + 1)}{2}$$</p>
<p>次基本操作，最差時間複雜度為 $O(n^2) $。</p>
<a class="header" href="#a最佳情況" id="a最佳情況"><h4>最佳情況</h4></a>
<p>既然最差情況發生在 pivot 總選到最大或最小值，反之，最佳情況則發生在每次 pivot 都可以順利選到序列的中位數（median），如此一來，每次遞迴分割的序列長度都會減半（ $n / 2 $），call stack 的嵌套遞迴總共需要 $2 \log_2{n} $ 次，序列的長度就會減至 1，而每次分割同樣有 $O(n) $ 的複雜度，因此最佳情況為：</p>
<p>$$O(n \cdot 2 \log_2{n}) = O(n \log n)$$</p>
<a class="header" href="#space-complexity" id="space-complexity"><h3>Space complexity</h3></a>
<p>Quicksort 的空間複雜度取決於實作細節，由於<strong>分割序列</strong>步驟需 $O(1) $ 的空間複雜度，因此僅需分析遞迴式會在 call stack 產生多少 stack frame 即可。</p>
<p><a href="#%E6%9C%80%E5%B7%AE%E6%83%85%E6%B3%81">前面提及</a>，最 naïve 的 Lomuto partition 最糟糕的情形下，會產生 $n - 1 $ 個嵌套遞迴，也就是需額外使用 $O(n) $ 的空間儲存 call stack frame，但只要 compiler 有支援 <a href="https://en.wikipedia.org/wiki/Tail_call">尾端調用</a>最佳化（tail-call optimization，TCO），Quicksort 很容易最佳化至 $O(\log n) $。</p>
<a class="header" href="#a實作-8" id="a實作-8"><h2>實作</h2></a>
<p>Quicksort 實作主要分為兩部分：遞迴，以及分割序列（partition）。</p>
<a class="header" href="#recursion" id="recursion"><h3>Recursion</h3></a>
<p>遞迴函式本身實作非常簡單，分別將小於 pivot 與大於 pivot 兩部分遞迴調用自身即可。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
/// Recursion helper
fn quicksort_helper(arr: &amp;mut [i32], lo: isize, hi: isize) {
    if lo &lt;= hi {                               // 1
        let pivot = partition(arr, lo, hi);     // 2
        quicksort_helper(arr, lo, pivot - 1);   // 3
        quicksort_helper(arr, pivot + 1, hi);   // 4
    }
}
#}</code></pre></pre>
<ol>
<li>利用 <code>lo</code> 與 <code>hi</code> 兩個指標決定每次的遞迴範圍，並在 <code>lo</code> 大於 <code>hi</code> 時停止遞迴，避免重複分割序列。</li>
<li>分割序列步驟，回傳該序列範圍內 pivot 的 index。</li>
<li>遞迴小於 pivot 的部分。</li>
<li>遞迴大於 pivot 的部分。</li>
</ol>
<blockquote>
<p>這邊比較特別的是，<code>lo</code> 和 <code>hi</code> 兩個指標的型別為 <code>isize</code>，因為當 pivot 可能為 0，在第三步驟 - 1 時會產生型別錯誤，故為之。有任何更好的寫法歡迎提供！</p>
</blockquote>
<p>由於外部不需知道排序法實作細節，我們將函式命名為 <code>quicksort_helper</code> ，對外再多封裝一層主函式 <code>quicksort_lomuto</code>，實作如下：</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn quicksort_lomuto(arr: &amp;mut [i32]) {
    let hi = arr.len() as isize - 1;
    quicksort_helper(arr, 0, hi);
}
#}</code></pre></pre>
<a class="header" href="#partitioning" id="partitioning"><h3>Partitioning</h3></a>
<p>一般來說，分割序列的實作有下列兩個步驟：</p>
<ul>
<li>選擇 pivot</li>
<li>遍歷序列置換元素</li>
</ul>
<p>我們以 Lomuto scheme 實作 partition。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
fn partition(arr: &amp;mut [i32], lo: isize, hi: isize) -&gt; isize {
    // -- Determine the pivot --
    // In Lomuto parition scheme,
    // the latest element is always chosen as the pivot.
    let pivot = arr[hi as usize];               // 1
    let mut i = lo;

    // -- Swap elements --
    for j in lo..hi {                           // 2
        if arr[j as usize] &lt; pivot {
            arr.swap(i as usize, j as usize);
            i += 1;                             // 3
        }
    }
    // Swap pivot to the middle of two piles.
    arr.swap(i as usize, hi as usize);          // 4
    i // Return the final index of the pivot
}
#}</code></pre></pre>
<ol>
<li>Lomuto scheme 選擇 pivot 的方式很直接，就是選擇最後一個元素。</li>
<li>利用 <code>i</code>、<code>j</code> 兩個指標迭代指定的序列範圍，若第 j 個值小於 pivot 時，則於第 i 個元素置換。</li>
<li><code>i</code> 指標加一，繼續處理下個元素。</li>
<li>最後置換第 i 個元素於 pivot，此時 pivot 已落在最終正確的位置。</li>
</ol>
<a class="header" href="#a最佳化與變形" id="a最佳化與變形"><h2>最佳化與變形</h2></a>
<p>Quicksort 有數個方向可以探討最佳化：</p>
<ul>
<li><a href="#%E9%99%8D%E4%BD%8E%E9%A1%8D%E5%A4%96%E7%A9%BA%E9%96%93%E8%A4%87%E9%9B%9C%E5%BA%A6">降低額外空間複雜度</a></li>
<li><a href="#%E9%81%B8%E6%93%87-pivot-%E7%9A%84%E6%96%B9%E6%B3%95">選擇 Pivot 的方法</a></li>
<li><a href="#%E5%B0%8D%E4%BB%98%E9%87%8D%E8%A4%87%E7%9A%84%E5%85%83%E7%B4%A0">對付重複的元素</a></li>
<li><a href="%E9%81%B8%E6%93%87%E4%B8%8D%E5%90%8C%E7%9A%84%E5%88%86%E5%89%B2%E6%96%B9%E6%A1%88">選擇不同的分割方案</a></li>
</ul>
<a class="header" href="#a降低額外空間複雜度" id="a降低額外空間複雜度"><h3>降低額外空間複雜度</h3></a>
<p>前述提到最佳情形下（每次 pivot 都選到中位數），僅需 $\log n $ 個嵌套遞迴，額外空間複雜度僅需 $O(\log n) $。
倘若編譯器有實作 <strong>尾端調用最佳化</strong>，Quicksort 可以達到 $O(\log n) $ 對數級別的額外空間使用。</p>
<p>實作尾端調用最佳化的思路很簡單，「<strong>先遞迴較少元素的部分，再利用 tall-call 遞迴另一部分</strong>」，如此以來，較多元素的遞迴則會直接被編譯器展開，消去遞迴時需要的 call stack 空間。剩下較少元素的部分，則與最佳情形相同，最多僅需 $\log n $ 次嵌套遞迴。</p>
<p>簡單實作如下：</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
fn quicksort_helper_optimized(arr: &amp;mut [i32], lo: isize, hi: isize) {
    if lo &lt;= hi {
        let pivot = partition(arr, lo, hi);
        if pivot - lo &lt; hi - pivot {                      // 1
          quicksort_helper_optimized(arr, lo, pivot - 1);
          quicksort_helper_optimized(arr, pivot + 1, hi); // 2
        } else {
          quicksort_helper_optimized(arr, pivot + 1, hi);
          quicksort_helper_optimized(arr, lo, pivot - 1); // 3
        }
    }
}
#}</code></pre></pre>
<ol>
<li>說穿了就只有這個判斷式，決定哪部分該先遞迴而已。</li>
<li>這是一個尾端調用，會展開。</li>
<li>這也是一個尾端調用。</li>
</ol>
<p>實際上，截至 2018.2，Rust Core Team 決定暫緩 TCO 的實作，目前 Rust 並沒有支援 TCO。但我們還是可以手動實作 TCO，減少 call stack。</p>
<p>我們先把原始的 lomuto partition 實作改成手動 TCO 版本。利用 <code>while</code> loop，將 <code>lo</code> 替換成下一個遞迴的引數，減少部分的 call stack。</p>
<pre><code class="language-diff">- fn quicksort_helper_manual_tco(arr: &amp;mut [i32], lo: isize, hi: isize) {
+ fn quicksort_helper_manual_tco(arr: &amp;mut [i32], mut lo: isize, mut hi: isize) {
-     if lo &lt;= hi {
+     while lo &lt; hi {
          let pivot = partition(arr, lo, hi);
          quicksort_helper(arr, lo, pivot - 1);
-         quicksort_helper(arr, pivot + 1, hi);
+         lo = pivot + 1;
      }
  }
</code></pre>
<p>再來，選擇性遞迴較小的部分。Iterative 版本的尾端調用消除（tail-call eliminate）就做完了！</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
fn quicksort_helper_manual_tco(arr: &amp;mut [i32], mut lo: isize, mut hi: isize) {
    while lo &lt; hi {
        let pivot = partition(arr, lo, hi);
        if pivot - lo &lt; hi - pivot {
            quicksort_helper_optimized(arr, lo, pivot - 1);
            lo = pivot + 1;
        } else {
            quicksort_helper_optimized(arr, pivot + 1, hi);
            hi = pivot - 1;
        }
    }
}
#}</code></pre></pre>
<a class="header" href="#a選擇-pivot-的方法" id="a選擇-pivot-的方法"><h3>選擇 Pivot 的方法</h3></a>
<p>選擇 pivot 的方法大致上有以下幾種：</p>
<ul>
<li>總是選擇最後一個元素。</li>
<li>總是選擇第一個元素。</li>
<li>選擇特定位置（如中位數）的元素。</li>
<li>隨機選擇任意元素。</li>
</ul>
<p>選擇第一個或最後一個元素會印序列已經接近排序完成或相反排序，造成 $O(n^2) $ 最壞的時間複雜度。隨機或選擇特定位置的方法較能避免這種情況，但實作上較困難。</p>
<p>除了選擇 pivot 的方法，近幾年來多 pivot（multi-pivot）Quicksort 也愈趨流行，可以減少 20% 的元素置換。相關的討論與證明可以參考<a href="https://cs.stanford.edu/%7Erishig/courses/ref/l11a.pdf">這篇文章</a>。</p>
<a class="header" href="#a對付重複的元素" id="a對付重複的元素"><h3>對付重複的元素</h3></a>
<p>若輸入序列有許多重複的元素，使用原本 Lomuto scheme 實作的 Quicksort 仍然會比較置換等於 pivot 的所有元素。3-way partition scheme 就是將序列多分出「等於 pivot」部分，減少重複置換相等元素的排序法。</p>
<pre><code>[ values &lt; pivot | values == pivot | value &gt; pivot ]
</code></pre>
<p>通常是使用著名的 <a href="https://en.wikipedia.org/wiki/Dutch_national_flag_problem">Dutch national flag algorithm</a> 來解決這個問題。實作上和 Lomuto 非常類似。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
fn partition(arr: &amp;mut [i32], lo: isize, hi: isize) -&gt; (isize, isize) {
    let pivot = arr[hi as usize];
    let mut i = lo;         // smaller
    let mut j = lo;         // equal
    let mut k = hi;         // large

    while j &lt;= k {
        if arr[j as usize] &lt; pivot {
            arr.swap(i as usize, j as usize);
            i += 1;
            j += 1;
        } else if arr[j as usize] &gt; pivot {
            arr.swap(k as usize, j as usize);
            k -= 1;
        } else {
            // No swap when identicial.
            j += 1;
        }
    }

    // Return smaller and larger pointer to avoid iterate duplicate elements.
    (i, k)
}
#}</code></pre></pre>
<a class="header" href="#a選擇不同的分割方案" id="a選擇不同的分割方案"><h3>選擇不同的分割方案</h3></a>
<p>不同的分割方案有著不同的應用場景，如上述的 3-way scheme 就適合重複元素多的序列。這裡再多介紹另一個常見的分割實作方案 Hoare partition，是 Quicksort 發明這 Hoare 自己提出的分割法，Rust 實作演算法如下：</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
fn partition(arr: &amp;mut [i32], lo: usize, hi: usize) -&gt; usize {
    let pivot = arr[lo];
    let mut i = lo;
    let mut j = hi;

    loop {
        // Find element &gt;= pivot from leftmost element.
        while arr[i] &lt; pivot {                            // 1
            i += 1;
        }
        // Find element &lt;= pivot from rightmost element.
        while arr[j] &gt; pivot {                            // 2
            j -= 1;
        }
        if i &gt;= j {
            return j;
        }
        // Two elements are misplaced, swap them.
        arr.swap(i, j);                                   // 3
        i += 1;
        j -= 1;
    }
}
#}</code></pre></pre>
<ol>
<li>從最左邊開始找比 pivot 大或相等的元素。</li>
<li>從最右邊開始找比 pivot 小或相等的元素。</li>
<li>若找到這兩個元素，置換之，以符合小於 pivot 在前，大於 pivot 在後的分割準則。</li>
</ol>
<a class="header" href="#a參考資料-10" id="a參考資料-10"><h2>參考資料</h2></a>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Quicksort">Wiki: Quicksort</a></li>
<li><a href="https://algs4.cs.princeton.edu/23quicksort/">Algorithms, 4th Edition by R. Sedgewick and K. Wayne</a></li>
<li><a href="https://www.geeksforgeeks.org/quick-sort/">GeeksForGeeks: QuickSort</a></li>
<li><a href="https://github.com/raywenderlich/swift-algorithm-club/tree/master/Quicksort">Swift Algorithm Club: Quicksort</a></li>
</ul>
<a class="header" href="#a合併排序-mergesort" id="a合併排序-mergesort"><h1>合併排序 Mergesort</h1></a>
<p>Mergesort 是一個泛用且高效穩定的排序法，最佳與最差時間複雜都是 $O(n \log n) $。Mergesort 可謂著名「Divide and Conquer」手法的經典案例，先將序列分成更小的子序列（Divide），一個個排序後（Conquer），再合併已排序的子序列（Combine）。</p>
<ul>
<li><strong>高效穩定</strong>：最佳、平均，與最差時間複雜度皆為 $O(n \log n) $。</li>
<li><strong>穩定排序</strong>：相同鍵值的元素，排序後相對位置不改變。</li>
<li><strong>非原地排序</strong>：除了資料本身，仍需額外花費儲存空間來排序。</li>
<li><strong>分治演算法</strong>：將主問題化作數個子問題，各個擊破。</li>
</ul>
<a class="header" href="#a步驟-8" id="a步驟-8"><h2>步驟</h2></a>
<p>Mergesort 演算法分為以下步驟：</p>
<ol>
<li><strong>Divide</strong>：將含有 n 個元素的序列分割成含有 n / 2 個子序列。</li>
<li><strong>Conquer</strong>：排序分割後的兩個子序列。</li>
<li><strong>Combine</strong>：合併排序完成的兩子序列，成為一個排好序的序列。</li>
</ol>
<p>其中，Conquer 步驟中的「排序」可以不斷遞迴 Mergesort 自身，因此需要停止遞迴的條件（base case），我們將條件設定為「子序列的長度小於 2」，因為長度為 1 的序列可視為已完成排序。</p>
<p>將 Mergesort 視覺化排序如下：</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/c/c5/Merge_sort_animation2.gif" alt="mergsort" /></p>
<a class="header" href="#a說明-7" id="a說明-7"><h2>說明</h2></a>
<p>以 ASCII diagram 圖解 Mergesort。</p>
<p>先將原始序列分割成數個長度為一的子序列。</p>
<pre><code>Split array into length 1 subarray.

    [8, 7, 1, 2, 4, 6, 5, 3]
                |
   [8, 7, 1, 2] | [4, 6, 5, 3]
                |
  [8, 7] [1, 2] | [4, 6] [5, 3]
                |
[8] [7] [1] [2] | [4] [6] [5] [3]
                V
              split
</code></pre>
<p>再將子序列依序合併成一個排好序的大序列。</p>
<pre><code>Recursively merge subarray respecting the order.

              Merge
                |
[8] [7] [1] [2] | [4] [6] [5] [3]
                |
  [7, 8] [1, 2] | [4, 6] [3, 5]
                |
   [1, 2, 7, 8] | [3, 4, 5, 6]
                V
    [1, 2, 3, 4, 5, 6, 7, 8]
</code></pre>
<a class="header" href="#a效能-9" id="a效能-9"><h2>效能</h2></a>
<table><thead><tr><th>              </th><th> Complexity         </th></tr></thead><tbody>
<tr><td> Worst        </td><td> $O(n \log n) $ </td></tr>
<tr><td> Best         </td><td> $O(n \log n) $ </td></tr>
<tr><td> Average      </td><td> $O(n \log n) $ </td></tr>
<tr><td> Worst space  </td><td> $O(n) $ auxiliary   </td></tr>
</tbody></table>
<a class="header" href="#time-complexity-2" id="time-complexity-2"><h3>Time Complexity</h3></a>
<p>透過遞迴關係式，很容易計算 Mergesort 的時間複雜度。假設排序長度為 $n $ 的序列最多需要 $T(n) $ 時間。可以觀察到，如果序列只有一個元素，Mergesort 僅需要常數時間就可以完成排序，寫成 $T(n) = 1 $。</p>
<p>如果 $n &gt; 2 $，Mergesort 會將序列分為 $\lceil \frac{n}{2} \rceil $ 部分，以及 $\lfloor \frac{n}{2} \rfloor $ 部分。我們可以將排序前者寫成 $T(\lceil \frac{n}{2} \rceil) $，而後者花費時間為 $ T(\lfloor \frac{n}{2} \rfloor) $。</p>
<p>最後，合併兩個子序列僅需 $n $ 個操作。可得下列遞迴關係式。<br />
（為了方便計算，把 floor 和 ceil 捨去）</p>
<p>$$
T(n) =
\begin{cases}
1                   &amp; \text{if } n = 1, \
2T(\frac{n}{2}) + n &amp; \text{otherwise}.
\end{cases}
$$</p>
<p>根據 <a href="master-theorem">Master Theorem</a>，可得複雜度為 $O(n \log n) $。</p>
<a class="header" href="#space-complexity-1" id="space-complexity-1"><h3>Space Complexity</h3></a>
<p>Mergesort 的缺點之一就是在合併子序列時，需要額外的空間依序插入排序資料；若是遞迴版本的 Mergesort 還需額外加上遞迴花費的 call stack 空間，因此額外空間複雜度為 $O(n) + O(\log n) = O(n) $（以陣列實作）。</p>
<a class="header" href="#a實作-9" id="a實作-9"><h2>實作</h2></a>
<p>一般來說，Divide and Conquer 有兩種設計、解決問題的技巧：Top-down（自上而下）與 Buttom-up（自下而上）。前者是先對問題有整體的輪廓概念，再逐步針對細節一一處理；後者則是先準備每個問題需要的基礎步驟與元件，再將這些步驟結合，解決整體的問題。</p>
<p>Mergesort 的實作分為兩部分：</p>
<ul>
<li><code>mergesort</code> 主程式：對外的接口，負責分割序列。對應 Divide 功能。</li>
<li><code>merge</code>：合併子序列，對應到 Conquer 與 Combine 功能。</li>
</ul>
<p>先來看看如何分割序列。</p>
<a class="header" href="#top-down-split" id="top-down-split"><h3>Top-down split</h3></a>
<p>自上而下的解法會不斷以類似 binary search 的方式找中點，進而分割序列。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn mergesort(arr: &amp;mut [i32]) {
    let mid = arr.len() / 2;
    if mid == 0 {                 // 1
        return;
    }

    mergesort(&amp;mut arr[..mid]);   // 2
    mergesort(&amp;mut arr[mid..]);

    // Create an array to store intermediate result.
    let mut ret = arr.to_vec();   // 3

    // Merge the two piles.
    merge(&amp;arr[..mid], &amp;arr[mid..], &amp;mut ret[..]);  // 4

    // Copy back the result back to original array.
    arr.copy_from_slice(&amp;ret);    // 5
}
#}</code></pre></pre>
<ol>
<li>設定遞迴的終止條件（base case），middle index 為 0 表示長度不大於 1。</li>
<li>利用 Rust 的 <a href="https://doc.rust-lang.org/std/ops/struct.Range.html">Range Operator</a>，可快速分割兩個 <code>slice</code>。</li>
<li>建立一個 <code>Vec</code> 儲存排序結果。</li>
<li>將兩個 <code>slice</code> 合併排序至 <code>ret</code> vector 中。</li>
<li>將 <code>ret</code> 的結果複製到原始 <code>arr</code> 中，使回傳值保有相同起始位址。</li>
</ol>
<a class="header" href="#buttom-up-split" id="buttom-up-split"><h3>Buttom-up split</h3></a>
<p>自下而上的解法則是預定好最小的子序列長度，直接使用 for 迴圈從頭開始逐一擊破。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn mergesort_bottom_up(arr: &amp;mut [i32]) {
    let mut width = 1;                                // 1
    // Create an array to store intermediate result.
    let mut ret = arr.to_vec();                       // 2
    let len = arr.len();

    while width &lt; len {
        let mut i = 0;
        while i &lt; len {
            // Check to avoid upper bound and middle index out of bound.
            let upper = ::std::cmp::min(i + 2 * width, len);  // 3
            let mid = ::std::cmp::min(i + width, len);

            merge(&amp;arr[i..mid], &amp;arr[mid..upper], &amp;mut ret[i..upper]);

            // Copy the merged result back to original array.
            arr[i..upper].copy_from_slice(&amp;ret[i..upper]);    // 4

            // Increase start index to merge next two subsequences.
            i += 2 * width;                           // 5
        }
        width *= 2;                                   // 6
    }
}
#}</code></pre></pre>
<ol>
<li>設定最小的子序列長度，這個長度以下的子序列皆視為已排序。</li>
<li>建立一個 <code>Vec</code> 儲存排序結果。</li>
<li>取最小值，避免下標超出邊界，並且維持除了最後一組，其他子序列長度恆為 <code>width</code>。</li>
<li>複製這部分排序結果 <code>ret</code> 到原始的 <code>arr</code> 中。</li>
<li>繼續下兩個子序列的合併步驟。</li>
<li>將下個迭代的子序列長度加倍，繼續合併。</li>
</ol>
<a class="header" href="#the-merge-part" id="the-merge-part"><h3>The merge part</h3></a>
<p>無論是 Top-down 還是 Buttom-up 版本的解法，皆免不了 <code>merge</code> 這個共同步驟，將子序列合併為較大的序列。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
fn merge(arr1: &amp;[i32], arr2: &amp;[i32], ret: &amp;mut [i32]) {
    let mut left = 0; // Head of left pile.             // 1
    let mut right = 0; // Head of right pile.
    let mut index = 0;

    // Compare element and insert back to result array.
    while left &lt; arr1.len() &amp;&amp; right &lt; arr2.len() {     // 2
        if arr1[left] &lt;= arr2[right] {                  // 3
            ret[index] = arr1[left];
            index += 1;
            left += 1;
        } else {
            ret[index] = arr2[right];
            index += 1;
            right += 1;
        }
    }

    // Copy the reset elements to returned array.
    // `memcpy` may be more performant than for-loop assignment.
    if left &lt; arr1.len() {                              // 4
        ret[index..].copy_from_slice(&amp;arr1[left..]);
    }
    if right &lt; arr2.len() {
        ret[index..].copy_from_slice(&amp;arr2[right..]);
    }
}
#}</code></pre></pre>
<ol>
<li>建立三個指標，分別給 <code>arr1</code>、<code>arr2</code> 與回傳陣列 <code>ret</code> 使用。</li>
<li>這部分依序比較兩個子序列，排序較小者先進入回傳 <code>ret</code>。直到其中一序列所有元素都進入 <code>ret</code> 就停止。</li>
<li>這邊判斷使用 <code>&lt;=</code> 小於等於確保排序穩定（相同鍵值順序不換）。</li>
<li>將剩餘未進入 <code>ret</code> 的元素，依序複製到 <code>ret</code> 中。</li>
</ol>
<blockquote>
<p><code>slice.copy_from_slice</code> 底層使用 C 的 <code>memcpy</code>，比起 for-loop 一個個賦值，直接複製整塊記憶體比較快了。</p>
</blockquote>
<a class="header" href="#a變形-2" id="a變形-2"><h2>變形</h2></a>
<a class="header" href="#timsort" id="timsort"><h3>Timsort</h3></a>
<p>在真實世界資料中，早有許多部分排序的分區（natural run），倘若跳過排序這些分區的步驟，就可減少許多不必要的操作，<a href="../timsort">Timsort</a> 就是為了完全利用榨乾這些分區的混合排序法。</p>
<a class="header" href="#a參考資料-11" id="a參考資料-11"><h2>參考資料</h2></a>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Merge_sort">Wiki: Merge sort</a></li>
<li><a href="www.cs..html">CMSC 351 Algorithms, Fall, 2011, University of Maryland.</a></li>
<li>Sorting GIF was created By CobaltBlue <a href="https://creativecommons.org/licenses/by-sa/2.5">CC BY-SA 2.5</a> via Wikimedia Commons.</li>
</ul>
<a class="header" href="#a混合排序" id="a混合排序"><h1>混合排序</h1></a>
<ul>
<li><a href="introsort">內省排序 Introsort</a></li>
<li><a href="timsort">自適應合併排序 Timsort</a></li>
<li><a href="pdqsort">模式消除快速排序 Pdqsort</a></li>
</ul>
<a class="header" href="#a內省排序-introsort" id="a內省排序-introsort"><h1>內省排序 Introsort</h1></a>
<p>🚧 🚧 🚧 TBD 🚧 🚧 🚧</p>
<a class="header" href="#a自適應合併排序-timsort" id="a自適應合併排序-timsort"><h1>自適應合併排序 Timsort</h1></a>
<p>🚧 🚧 🚧 TBD 🚧 🚧 🚧</p>
<a class="header" href="#a效能-10" id="a效能-10"><h2>效能</h2></a>
<table><thead><tr><th>              </th><th> Complexity         </th></tr></thead><tbody>
<tr><td> Worst        </td><td> $O(n \log n) $ </td></tr>
<tr><td> Best         </td><td> $O(n) $        </td></tr>
<tr><td> Average      </td><td> $O(n \log n) $ </td></tr>
<tr><td> Worst space  </td><td> $O(n) $ auxiliary   </td></tr>
</tbody></table>
<a class="header" href="#a實作-10" id="a實作-10"><h2>實作</h2></a>
<a class="header" href="#a參考資料-12" id="a參考資料-12"><h2>參考資料</h2></a>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Timsort">Wiki: Timsort</a></li>
<li>http://blog.csdn.net/yangzhongblog/article/details/8184707</li>
<li>https://github.com/rust-lang/rust/pull/38192</li>
<li>https://github.com/python/cpython/blob/master/Objects/listsort.txt</li>
<li>https://youtu.be/uVWGZyekGos</li>
</ul>
<a class="header" href="#a模式消除快速排序-pattern-defeating-quicksort" id="a模式消除快速排序-pattern-defeating-quicksort"><h1>模式消除快速排序 Pattern-defeating Quicksort</h1></a>
<p>🚧 🚧 🚧 TBD 🚧 🚧 🚧</p>
<ul>
<li>Unstable</li>
<li>Adopted in libcore in Rust</li>
</ul>
<a class="header" href="#a參考資料-13" id="a參考資料-13"><h2>參考資料</h2></a>
<ul>
<li>https://news.ycombinator.com/item?id=14661659</li>
<li>https://redd.it/5qa8h6</li>
<li>https://github.com/orlp/pdqsort</li>
<li>https://github.com/stjepang/pdqsort</li>
<li>https://github.com/rust-lang/rust/pull/40601</li>
</ul>
<a class="header" href="#a特殊排序" id="a特殊排序"><h1>特殊排序</h1></a>
<ul>
<li><a href="counting_sort">計數排序 Counting sort</a></li>
<li><a href="bucket_sort">桶排序 Bucket sort</a></li>
<li><a href="radix_sort">基數排序 Radix sort</a></li>
</ul>
<a class="header" href="#a計數排序-counting-sort" id="a計數排序-counting-sort"><h1>計數排序 Counting sort</h1></a>
<p><a href="https://en.wikipedia.org/wiki/Counting_sort">Counting sort</a> 是一個特殊的整數排序法，被視為 <a href="../bucket_sort">Bucket sort</a> 的特例。原理是在已知整數範圍內，計算每個鍵值出現次數，並用額外的陣列保存（Count array）。最後將 Count array 的元素值作為排序資料的新 index。</p>
<p>Counting sort 基本特性如下：</p>
<ul>
<li><strong>非原地排序</strong>：額外花費較大量、非固定的空間來排序。</li>
<li><strong>穩定排序</strong>：相同鍵值的元素，排序後相對位置不改變。</li>
<li><strong>整數排序</strong>：以整數作為排序的鍵值。</li>
<li><strong>分配式排序</strong>：不透過兩兩比較，而是分析鍵值分佈來排序。特定情況下可達線性執行時間。</li>
<li><strong>線型執行時間</strong>：當輸入資料量 <strong>n</strong> 與已知範圍上下界之差值相近，執行時間接近線型（<strong>O(n)</strong>）</li>
<li><strong>預期分佈</strong>：預期輸入資料是落在已知範圍內的整數（例如 0 到 k）。</li>
<li><strong>適用範圍</strong>：僅適用於小範圍整數（額外空間需求大）。</li>
</ul>
<a class="header" href="#a步驟-9" id="a步驟-9"><h2>步驟</h2></a>
<ol>
<li><strong>Count occurrence</strong>：計算每個 key 的出現次數。</li>
<li><strong>Prefix sum as start index</strong>：計算前綴和（Prefix sum），並作為該元素的 start index。</li>
<li><strong>Copy output</strong>：利用步驟二的前綴和，遍歷輸入資料，取得元素排序後的索引。</li>
</ol>
<a class="header" href="#a說明-8" id="a說明-8"><h2>說明</h2></a>
<p>這裡有資料需要透過正整數的 key 來排序。key 的範圍在 0 - 9 之間，格式為 <code>(key, value)</code>。</p>
<pre><code>Input: (1, A) (5, B) (8, C) (2, D) (2, E) (9, F)
</code></pre>
<p><strong>1. Count occurrence</strong>：首先，先計算每個 key 的出現頻率，儲存在額外的 count array 中。</p>
<pre><code>Key  : 0 1 2 3 4 5 6 7 8 9
Count: 0 1 2 0 0 1 0 0 1 1
</code></pre>
<p><strong>2. Prefix sum as start index</strong>：再計算 prefix sum，也就是將當前 index 前累計的 key 數量加總。例如 <strong>key 5</strong> 的 prefix sum <strong>1 + 2 = 3</strong>。</p>
<p>這裡的 prefix sum 等同於每筆資料排序後的位置（index）。例如排序後，<strong>8</strong> 位於陣列第四位。</p>
<pre><code>Key       : 0 1 2 3 4 5 6 7 8 9
Prefix Sum: 0 0 1 3 3 3 4 4 4 5
</code></pre>
<p><strong>3. Copy output</strong>：透過 key 與 prefix sum 的映射關係，找到原始資料對應的位置。</p>
<p>實作上，每筆資料找到對應的 start index（prefix sum） 後，要將<strong>該 index 之值 +1</strong>，使得重複的元素可取得正確的 index offset（對唯一的 key 沒有影響）。</p>
<pre><code>(1, A)
--&gt; prefix sum 為 0，寫入 array[0]，並將 prefix sum + 1

+--------+--------+--------+--------+--------+--------+
| (1, A) |        |        |        |        |        |
+--------+--------+--------+--------+--------+--------+

(5, B)
--&gt; prefix sum 為 3，寫入 array[3]，並將 prefix sum + 1

+--------+--------+--------+--------+--------+--------+
| (1, A) |        |        | (5, B) |        |        |
+--------+--------+--------+--------+--------+--------+

(8, C)
--&gt; prefix sum 為 4，寫入 array[4]，並將 prefix sum + 1

+--------+--------+--------+--------+--------+--------+
| (1, A) |        |        | (5, B) | (8, C) |        |
+--------+--------+--------+--------+--------+--------+

(2, D)
--&gt; prefix sum 為 2，寫入 array[4]，並將 prefix sum + 1

+--------+--------+--------+--------+--------+--------+
| (1, A) | (2, D) |        | (5, B) | (8, C) |        |
+--------+--------+--------+--------+--------+--------+

(2, E)
--&gt; prefix sum 為 3（前一步驟 + 1），寫入 array[3]，並將 prefix sum + 1

+--------+--------+--------+--------+--------+--------+
| (1, A) | (2, D) | (2, E) | (5, B) | (8, C) |        |
+--------+--------+--------+--------+--------+--------+

(9, F)
--&gt; prefix sum 為 5，寫入 array[5]，並將 prefix sum + 1

+--------+--------+--------+--------+--------+--------+
| (1, A) | (2, D) | (2, E) | (5, B) | (8, C) | (9, F) |
+--------+--------+--------+--------+--------+--------+
</code></pre>
<p>這樣就完成排序了。此外，觀察 <strong>(2, D)</strong> 與 <strong>(2, E)</strong> 排序前後的位置，會發現 counting sort 是個實實在在的穩定排序，很棒。</p>
<a class="header" href="#a效能-11" id="a效能-11"><h2>效能</h2></a>
<table><thead><tr><th>              </th><th> Complexity      </th></tr></thead><tbody>
<tr><td> Worst        </td><td> $O(n + k) $ </td></tr>
<tr><td> Best         </td><td> $O(n + k) $ </td></tr>
<tr><td> Average      </td><td> $O(n + k) $ </td></tr>
<tr><td> Worst space  </td><td> $O(n + k) $ auxiliary </td></tr>
</tbody></table>
<blockquote>
<p>k 為資料已知範圍上下界之差。</p>
</blockquote>
<a class="header" href="#time-complexity-3" id="time-complexity-3"><h3>Time Complexity</h3></a>
<p>Counting sort 沒有用到任何遞迴，可以直觀地分析複雜度。在步驟一，建立 count array 與步驟三輸出排序結果，都需要遍歷 $n $ 個輸入的資料，因此複雜度為 $O(n) $；步驟二計算 prefix sum，，以及 count array 自身的初始化則需執行 $k + 1 $ 次（給定的資料範圍），這部分的複雜度為 $O(k) $。由於 $n $ 與 $k $ 的權重會因輸入資料及實作的不同而有所改變，我們無法捨棄任何一個因子，可得知 counting sort 的複雜度為 $O(n + k) $。</p>
<a class="header" href="#space-complexity-2" id="space-complexity-2"><h3>Space complexity</h3></a>
<p>Counting sort 並非 in-place sort，排序後的結果會另外輸出為新的記憶體空間，因此 $O(n) $ 的額外（auxiliary）空間複雜度絕對免不了。再加上需要長度為 $k $ 的 count array 保存每個 key 的出現次數，因此需再加上 $O(k) $。除了原始的輸入 array，總共需花費 $O(n + k) $ 的額外空間複雜度。</p>
<blockquote>
<p>如果欲排序資料就是整數鍵值自身，可以將「計算前綴和」與「複製輸出」兩步驟最佳化，直接覆寫原始陣列，額外空間複雜度會下降至 $O(k) $，但也因此成為不穩定排序法。</p>
</blockquote>
<a class="header" href="#a實作-11" id="a實作-11"><h2>實作</h2></a>
<p>由於 Counting sort 屬於分布式排序（Distribution sort），這裡使用泛型，以彰顯分布式排序的特色。</p>
<a class="header" href="#function-signature" id="function-signature"><h3>Function Signature</h3></a>
<p>首先，我們先看函式如何宣告（function signature）。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn counting_sort&lt;F, T&gt;(arr: &amp;mut [T], min: usize, max: usize, key: F) 
    where F: Fn(&amp;T) -&gt; usize, 
          T: Clone,
#}</code></pre></pre>
<p>這裡使用了四個參數：</p>
<ul>
<li><code>arr</code>：待排序陣列。</li>
<li><code>min</code>、<code>max</code>：整數排序的上下界。</li>
<li><code>key</code>：由於資料不一定是整數，需要一個 function 從資料擷取鍵值做排</li>
</ul>
<p>另外，也使用兩個泛型型別：</p>
<ul>
<li><code>F</code>：<code>key</code> extactor 的型別，回傳的 <code>usize</code> 必須落在 <code>[min, max)</code> 之間。</li>
<li><code>T</code>：陣列元素的型別，實作 <code>Clone</code> 是由於 Counting sort 需要將 output 再複製回原本的參數 <code>arr</code> 上，達成「偽」原地排序。</li>
</ul>
<a class="header" href="#prefix-sums-array" id="prefix-sums-array"><h3>Prefix Sums Array</h3></a>
<p>再來，了解如何建立一個元素出現次數的陣列。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
fn counting_sort() {
    // ...

    let mut prefix_sums = {
        // 1. Initialize the count array with default value 0.
        let len = max - min;
        let mut count_arr = Vec::with_capacity(len);
        count_arr.resize(len, 0);

        // 2. Scan elements to collect counts.
        for value in arr.iter() {
            count_arr[key(value)] += 1;
        }

        // 3. Calculate prefix sum.
        count_arr.into_iter().scan(0, |state, x| {
                *state += x;
                Some(*state - x)
            }).collect::&lt;Vec&lt;usize&gt;&gt;()
    };
    // ...
}
#}</code></pre></pre>
<ol>
<li>建立一個長度為上下界之差的 count array。注意，這裡使用了 <code>Vec.resize</code>，因為 Rust initialize 空的 <code>Vec</code> 時並不會插入 0 或其他預設值。</li>
<li>遍歷整個輸入資料，利用 <code>key</code> function 取出每筆資料的鍵值，出現一次就 +1。</li>
<li>利用 Iterator 上的 <code>scan</code> method 計算每個鍵值的 prefix sum。需要注意的是，每個元素對應的 prefix sum 不包含自身，例如 key 3 的計算結果就是 1 與 2 的出現總次數，如此一來，prefix sum 才會直接對應到排序後的位置。</li>
</ol>
<a class="header" href="#prefix-sums-as-start-index" id="prefix-sums-as-start-index"><h3>Prefix Sums as Start Index</h3></a>
<p>最後一步就是將 prefix sum 當作每個 element 的正確位置，把資料重頭排序。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
fn counting_sort() {
    // ...

    for value in arr.to_vec().iter() {            // 1
        let index = key(value);
        arr[prefix_sums[index]] = value.clone();  // 2
        prefix_sums[index] += 1;                  // 3
    }
}
#}</code></pre></pre>
<ol>
<li>將輸入資料透過 <code>to_vec</code> 複製起來迭代，需要複製 <code>arr</code> 是因為之後要直接在 <code>arr</code> 插入新值，需要另一份原始輸入的拷貝。</li>
<li>利用 <code>key</code> 擷取鍵值後，把資料複製給 <code>arra</code> 上對應 <code>prefix_sums[index]</code> 的位置。</li>
<li>將該 <code>prefix_sums[index]</code> 的值加一，以便元素重複時，可以正常複製到下一個位置。</li>
</ol>
<p>完成了！這裡再貼一次完整的程式碼。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn counting_sort&lt;F, T&gt;(arr: &amp;mut [T], min: usize, max: usize, key: F) 
    where F: Fn(&amp;T) -&gt; usize,
          T: Clone,
{
    let mut prefix_sums = {
        // 1. Initialize the count array with default value 0.
        let len = max - min;
        let mut count_arr = Vec::with_capacity(len);
        count_arr.resize(len, 0);

        // 2. Scan elements to collect counts.
        for value in arr.iter() {
            count_arr[key(value)] += 1;
        }

        // 3. Calculate prefix sum.
        count_arr.into_iter().scan(0, |state, x| {
                *state += x;
                Some(*state - x)
            }).collect::&lt;Vec&lt;usize&gt;&gt;()
    };

    // 4. Use prefix sum as index position of output element.
    for value in arr.to_vec().iter() {
        let index = key(value);
        arr[prefix_sums[index]] = value.clone();
        prefix_sums[index] += 1;
    }
}
#}</code></pre></pre>
<a class="header" href="#a參考資料-14" id="a參考資料-14"><h2>參考資料</h2></a>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Counting_sort">Wiki: Counting sort</a></li>
<li><a href="http://www.growingwiththeweb.com/2014/05/counting-sort.html">Growing with the web: Counting sort</a></li>
</ul>
<a class="header" href="#a桶排序-bucket-sort" id="a桶排序-bucket-sort"><h1>桶排序 Bucket sort</h1></a>
<p><a href="https://en.wikipedia.org/wiki/Bucket_sort">Bucket sort</a>，是一個非比較排序。原理是建立一些桶子，每個桶子對應一資料區間，在將待排序資料分配到不同的桶中，桶子內部各自排序。由於並非<a href="https://en.wikipedia.org/wiki/Comparison_sort">比較排序</a>，使用 Bucket sort 需要事先知道資料的範圍與分佈，才能決定桶子對應的區間。</p>
<p>Bucket sort 基本特性如下：</p>
<ul>
<li>又稱 <strong>bin sort</strong>。</li>
<li><strong>穩定排序</strong>：相同鍵值的元素，排序後相對位置不改變。</li>
<li><strong>分配式排序</strong>：不透過兩兩比較，而是分析鍵值分佈來排序。特定情況下可達線性執行時間。</li>
<li><strong>預期分佈</strong>：資料為<strong>均勻分佈</strong>。</li>
</ul>
<a class="header" href="#a步驟-10" id="a步驟-10"><h2>步驟</h2></a>
<p>假設要排序 $n $ 個元素的陣列，這些元素的值平均散落在某個<strong>已知的預期範圍內</strong>，例如 1 到 100。</p>
<ol>
<li><strong>Create buckets</strong>：建立 $k $ 個桶子（bucket）的陣列。每個桶子<strong>對應預期範圍的某區間</strong>，如第一個桶子放 1 到 10，第二個放 11 到 20。</li>
<li><strong>Scatter</strong>：將每個元素依照該值放入對應的桶子中。</li>
<li><strong>Inner sort</strong>：排序所有非空的桶子。</li>
<li><strong>Gather</strong>：依序走訪所有桶子，將桶內的元素放回原本的陣列中。</li>
</ol>
<a class="header" href="#a說明-9" id="a說明-9"><h2>說明</h2></a>
<p>以下用 ASCII diagram 視覺化解釋：</p>
<p>這裡有一些整數，落在 1 至 100 之間。我們有 $n = 10 $ 的陣列要排序。</p>
<pre><code>Original array

+-------------------------------------------------+
|  6 | 28 | 96 | 14 | 74 | 37 |  9 | 71 | 91 | 36 |
+-------------------------------------------------+
</code></pre>
<p><strong>1. Create buckets</strong>：建立一定數量的桶子，這裡我們建立與原始陣列相同數量的桶子（10）。每個桶子對應 $n - 1 * 10 $ 到 $n * 10 $ 的區間。</p>
<pre><code>Bucket array

+-------------------------------------------------+
|    |    |    |    |    |    |    |    |    |    |
+-------------------------------------------------+
  ^    ^
  |    |
  |    |
  |    holds values in range 11 to 20
  holds values in range 1 to 10
</code></pre>
<p><strong>2. Scatter</strong>：將原始陣列中的元素，放入對應的桶中。</p>
<pre><code>Bucket array

  6,9  14   28   37,36               74,71     96,91
  |    |    |    |                   |         |
+-v----v----v----v-------------------v---------v--+
|    |    |    |    |    |    |    |    |    |    |
+-------------------------------------------------+
</code></pre>
<p><strong>3. Inner sort</strong>：排序所有非空桶子中的元素，桶內排序可用任意排序法，通常選用「insertion sort」，可確保排序穩定性，並降低額外開銷。</p>
<pre><code>Bucket array

  sort sort sort sort                sort      sort
  ---  --   --   -----               -----     -----
  6,9  14   28   36,37               71,74     91,96
  |    |    |    |                   |         |
+-v----v----v----v-------------------v---------v--+
|    |    |    |    |    |    |    |    |    |    |
+-------------------------------------------------+
</code></pre>
<p><strong>4. Gather</strong>：排序完後，再將所有桶中元素依序放回原始的陣列。</p>
<pre><code>Original array
+-------------------------------------------------+
|  6 |  9 | 14 | 28 | 36 | 37 | 71 | 74 | 91 | 96 |
+-------------------------------------------------+
</code></pre>
<a class="header" href="#a效能-12" id="a效能-12"><h2>效能</h2></a>
<table><thead><tr><th>              </th><th> Complexity      </th></tr></thead><tbody>
<tr><td> Worst        </td><td> $O(n^2) $   </td></tr>
<tr><td> Best         </td><td> $O(n + k) $ </td></tr>
<tr><td> Average      </td><td> $O(n + k) $ </td></tr>
<tr><td> Worst space  </td><td> $O(n + k) $ auxiliary </td></tr>
</tbody></table>
<blockquote>
<p>$k $ = 桶子的數量（number of buckets）
$n $ = 資料筆數</p>
</blockquote>
<a class="header" href="#worst-case" id="worst-case"><h3>Worst case</h3></a>
<p>Bucket sort 是一個分配式排序法，對資料分佈有既定的預期：「<strong>所有元素平均分佈在每個 bucket 的區間內</strong>」。可想而知，最差的狀況是所有元素都聚集（clustering）在同一個 bucket 中，整個 bucket sort 的會退化成單一一個 inner sort 的複雜度。而桶內排序通常選用 insertion sort（最差 $O(n^2) $），所以最差的時間複雜度為「 $O(n^2) $」。</p>
<a class="header" href="#best-case" id="best-case"><h3>Best case</h3></a>
<p>最佳的狀況則是完全符合預期的平均分佈，一個蘿蔔一個坑，每個桶內排序的最佳時間複雜度為 $O(n / k) $，再乘上桶子總數 $k $，僅需 $O(k \cdot (n / k)) = O(n) $。計算結果看起來非常合理，但實際上最佳時間複雜度為 $O(n + k) $，為什麼呢？</p>
<p>無庸置疑，桶內排序最佳時間複雜度為 $O(n / k) $，但別忘了這是省略常數項過後式子，進行符號運算時，較精確的表達是 $c_0 O(n / k) + c_1 $，對於實作層面的常數 $c_0 $ 和 $c_1 $ 則予以保留。</p>
<p>當我們乘上 $k $，試著算出總運算量時，</p>
<p>$$k \cdot (c_0(n / k) + c_1) $$</p>
<p>會得到：</p>
<p>$$ c_0n + c_1k $$</p>
<p>可以得知，整個計算與 $k $ 有關，所以需要耗時 $O(n + k) $。</p>
<p>撇開數學，我們從 pseudo code 來看。最佳情況下，將所有元素蒐集回陣列的步驟（Gather）如下：</p>
<pre><code>for (each bucket b in all k buckets)
  for (each element x in b)
    append x to the array
</code></pre>
<p>最外層的迴圈依桶子數 $k $ 而定，至少需要執行 $k $ 次，複雜度為 $O(k) $。內層的迴圈則是每個桶內的元素都會執行，而我們的資料時均勻分布，因此執行時間與元素總數 $n $ 相關，為 $O(n) $。兩者加起來就是我們所說的 $O(n + k) $ 的最佳複雜度。</p>
<p><strong>那 $k $ 究竟會是多少，影響會比 $n $ 大嗎？</strong></p>
<p>端看桶子總數而定，若桶子總數很大，比元素個數 $n $ 大得多，則桶子總數對執行時間的影響恐較劇烈，就算大多數為空桶子，仍須挨家挨戶查看是否需要執行桶內排序。</p>
<a class="header" href="#space-complexity-3" id="space-complexity-3"><h3>Space Complexity</h3></a>
<p>Bucket sort 須額外建立 $k $ 個桶子，每個桶子需要配置長度為 $n $ 的 array，因此空間複雜度為 $O(n \cdot k) $。如果以 dynamic array 實作 bucket，並考慮平攤分析（Amortized analysis），則空間複雜度降至 $O(n + k) $，這也是大多數人接受的分析結果，畢竟不會有人無聊到預先配置 $n \cdot k $ 個 empty bucket。</p>
<a class="header" href="#a實作-12" id="a實作-12"><h2>實作</h2></a>
<a class="header" href="#bucket" id="bucket"><h3>Bucket</h3></a>
<p>Bucket sort 有許多種各異的實作法，差異最大之處就是桶子 bucket 這部分。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
/// Bucket to store elements.
struct Bucket&lt;H, T&gt; {
    hash: H,
    values: Vec&lt;T&gt;,
}

impl&lt;H, T&gt; Bucket&lt;H, T&gt; {
    /// Create a new bucket and insert its first value.
    ///
    /// * `hash` - Hash value generated by hasher param of `bucket_sort`.
    /// * `value` - Value to be put in the bucket.
    pub fn new(hash: H, value: T) -&gt; Bucket&lt;H, T&gt; {
        Bucket {
            hash: hash,
            values: vec![value],
        }
    }
}
#}</code></pre></pre>
<p>這裡的桶子實作兩個 struct fields：</p>
<ul>
<li><code>values</code>：使用 <a href="https://doc.rust-lang.org/stable/std/vec/struct.Vec.html"><code>Vec</code></a> 儲存對應範圍內的元素</li>
<li><code>hash</code>：Bucket Sort 主函式有一個 <code>hasher</code> 函式，會計算出對應各個桶子的雜湊值，因此要確保桶子的雜湊值有唯一性。</li>
</ul>
<a class="header" href="#sorting" id="sorting"><h3>Sorting</h3></a>
<p>接下來就是排序主函式。依照慣例，先看看函式的宣告（function signature）。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn bucket_sort&lt;H, F, T&gt;(arr: &amp;mut [T], hasher: F)
    where H: Ord,
          F: Fn(&amp;T) -&gt; H,
          T: Ord + Clone,
#}</code></pre></pre>
<p>這個 <code>bucket_sort</code> 函式使用了不少泛型：</p>
<ul>
<li><code>H</code>：<code>hasher</code> 函式的回傳型別，用來辨識不同的桶子。</li>
<li><code>F</code>：<code>hasher</code> 函式自身，只需要一個參數 <code>&amp;T</code>，回傳一個 <code>H</code>。</li>
<li><code>T</code>：欲排序資料的型別。</li>
</ul>
<p>函式自身稍微複雜一點，但仍不脫離<a href="#%E6%AD%A5%E9%A9%9F">四步驟</a>：Create buckets、Scatter、Inner sort，還有 Gather。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn bucket_sort() {
    // ...

    // 1. Create buckets.
    let mut buckets: Vec&lt;Bucket&lt;H, T&gt;&gt; = Vec::new();

    // 2. Scatter
    for value in arr.iter() {
        let hash = hasher(&amp;value); // 2.1.

        let value = value.clone();
        // 2.2.
        match buckets.binary_search_by(|bucket| bucket.hash.cmp(&amp;hash)) {
            // If exists, push the value to the bucket.
            Ok(index) =&gt; buckets[index].values.push(value),
            // If none, create and new bucket and insert value in.
            Err(index) =&gt; buckets.insert(index, Bucket::new(hash, value)),
        }
    }

    // 3. Inner sort and gather
    let ret = buckets.into_iter().flat_map(|mut bucket| {
        bucket.values.sort(); // 3.1.
        bucket.values
    }).collect::&lt;Vec&lt;T&gt;&gt;();   // 3.2.

    arr.clone_from_slice(&amp;ret); // 4 Copy to original array
}
#}</code></pre></pre>
<ol>
<li>一般來說，第一步會配置完所有桶子，但這裡實作僅建立儲存桶子們的容器 <code>buckets</code>，這是由於實作了 <code>hasher</code> 函式，元素對應桶子的邏輯交由外部決定，因此桶子不需事先配置，而是交給第二步驟時 <strong>on-the-fly</strong> 建立。</li>
<li>迭代輸入的 <code>arr</code>，將元素散佈到桶子中。
<ol>
<li>使用元素值 <code>value</code> 取得雜湊值。</li>
<li>從一堆桶子內 <code>buckets</code> 尋找對應雜湊值的桶子，如有對應桶子，則將待排序元素插入桶中；若無對應桶子，則馬上建立桶子，並插入待排序元素。</li>
</ol>
</li>
<li>由於桶子們 <code>buckets</code> 是一個二維陣列集合，我們使用 <code>flat_map</code> 將之壓平。
<ol>
<li>使用 Rust 內建 sort（Timsort 的變形）作為我們 inner sort 的實作，將桶內所有元素排好序</li>
<li>別忘了 Rust 的 Iterator 很 lazy，記得要使用 <code>collect</code> 蒐集 iterator 實作後的結果。</li>
</ol>
</li>
<li>由於要模擬 in-place 原地排序法的特性，將排序好的資料再次拷貝到 <code>arr</code> 上。這也是為什麼函式元素泛型 <code>T</code> 需要 <code>Clone</code> trait 的原因了。</li>
</ol>
<p>有關於步驟 2.2.，這部分可以用 <code>HashMap</code> 的變形 <a href="https://github.com/bluss/indexmap">IndexMap</a>（一個保存插入順序的有序 HashMap）保存雜湊值對應桶子的資訊，使得外界更容易依雜湊值找到桶子。但為了保持範例程式的簡潔，決定不引入第三方的 crate（Rust 語言第三方模組的代稱），且 <code>binary_search_by</code> 的複雜度為 $O(\log n) $，對 Bucket sort 最差複雜度並無影響。</p>
<a class="header" href="#a參考資料-15" id="a參考資料-15"><h2>參考資料</h2></a>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Bucket_sort">Wiki: Bucket sort</a></li>
<li><a href="https://en.wikipedia.org/wiki/Amortized_analysis">Wiki: Amortized analysis</a></li>
<li><a href="https://stackoverflow.com/questions/7311415">How is the complexity of bucket sort is O(n+k) if we implement buckets using linked lists?</a></li>
<li><a href="https://codereview.stackexchange.com/questions/145113/bucket-sort-in-rust">Bucket sort in Rust</a></li>
</ul>
<a class="header" href="#a基數排序-radix-sort" id="a基數排序-radix-sort"><h1>基數排序 Radix sort</h1></a>
<p>如果你對 <a href="../counting_sort">Counting sort</a> 與 <a href="../bucket_sort">Bucket sort</a> 有認識，應該知道這兩個排序都能突破比較排序法複雜度 $O(n \log n) $ 限制的特殊排序法。<a href="https://en.wikipedia.org/wiki/Radix_sort">Radix sort</a> 同樣是個特殊的<a href="https://en.wikipedia.org/wiki/Integer_sorting">整數排序法</a>，效能同樣可達突破限制。差別在於，前兩者僅依據一個鍵值排序，而 Radix sort 則是依據多個鍵值排序。</p>
<p>舉例來說，欲排序一群範圍在 0 - 999 的整數，若以 Counting sort 排序，則需建立一個「1000 元素的陣列」來計算每個整數的出現次數；若使用以 10 為基數的 Radix sort，則僅需以個位數、十位數、百位數作為鍵值分別排序三次。通常 Radix sort 的排序副程式（Sorting subroutine）會選用 Counting sort 或 Bucket sort，而以 10 為基數的鍵值範圍僅 0 - 9，這種小範圍整數非常適合 Counting sort 作為排序副程式，節省了配置 <code>int arr[1000]</code> 的 count array 的時空間。</p>
<p>Radix sort 基本特性如下：</p>
<ul>
<li><strong>整數排序法</strong>：以整數作為排序的鍵值。</li>
<li><strong>分配式排序法</strong>：不透過兩兩比較，而是分析鍵值分佈來排序。特定情況下可達線性執行時間。</li>
<li><strong>穩定性</strong>：採用 LSD 的 Radix sort 屬穩定排序法（Stable sort）；透過優化，採用 MSD 也可以是穩定排序法。</li>
</ul>
<a class="header" href="#a步驟-11" id="a步驟-11"><h2>步驟</h2></a>
<p>常見的 Radix sort 依據整數的每個位數來排序，依照位數排序的先後順序，可分為兩種：</p>
<ul>
<li><strong>Least significant digit (LSD)</strong>：從最低有效鍵值開始排序（最小位數排到大）。</li>
<li><strong>Most significant digit (MSD)</strong>：從最高有效鍵值開始排序（最大位數排到小）。</li>
</ul>
<p>簡單的 LSD Radix sort 步驟如下：</p>
<ol>
<li><strong>LSD of each key</strong>：取得每個資料鍵值的最小位數（LSD）。</li>
<li><strong>Sorting subroutine</strong>：依據該位數大小排序資料。</li>
<li><strong>Repeating</strong>：取得下一個有效位數，並重複步驟二，至最大位數（MSD）為止。</li>
</ol>
<p>而 MSD Radix sort 的步驟相似，但取得資料鍵值的方向相反。</p>
<ol>
<li><strong>MSD of each key</strong>：取得每個資料鍵值的最大位數（MSD）。</li>
<li><strong>Sorting subroutine</strong>：依據該位數大小排序資料。</li>
<li><strong>Repeating</strong>：取得下一個有效位數，並重複步驟二，至最小位數（LSD）為止。</li>
</ol>
<blockquote>
<p>由於 MSD Radix sort 先排序最大位數，會出現 <strong>8 &gt; 126</strong> 的結果，這種順序通常稱為 <a href="https://en.wikipedia.org/wiki/Lexicographical_order">Lexicographical order</a>，有如字典一般，越前面的字母排序權重越重，也因此，基本版的 MSD Radix sort 並非穩定排序法。</p>
</blockquote>
<a class="header" href="#a說明-10" id="a說明-10"><h2>說明</h2></a>
<p>我們選用 LSD Radix sort 示範，並且為了增加可讀性，將基數設為 10。需注意在現實場景中，有時使用 bytes 作為基數可能更適合。</p>
<p>待排序的數列如下。</p>
<pre><code>[170, 45, 75, 90, 802, 2, 24, 66]
</code></pre>
<blockquote>
<p>Radix sort 的排序副程式，通常選用 counting sort 或 bucket sort，因此，開始排序前，需建立供其使用的 buckets（或 count array）。這屬於其他排序法的範疇，有興趣可看 <a href="../counting_sort">Counting sort</a> 或 <a href="../bucket_sort">Bucket sort</a>。</p>
</blockquote>
<p>首先，從最小位數開始排序。
注意，同樣鍵值的資料，相對位置不會改變（穩定排序）。</p>
<pre><code>   0   5   5   0    2  2   4   6
   _   _   _   _    _  _   _   _
[170, 45, 75, 90, 802, 2, 24, 66]

sort by rightmost digit --&gt;

   0   0    2  2   4   5   5   6
   _   _    _  _   _   _   _   _
[170, 90, 802, 2, 24, 45, 75, 66]
</code></pre>
<p>再來，對下一個位數排序資料。位數不足的資料，予以補 0。</p>
<pre><code>  7   9    0   0  2   4   7   6
  _   _    _      _   _   _   _
[170, 90, 802, 2, 24, 45, 75, 66]

sort by next digit --&gt;

  0   0  2   4   6    7   7   9
  _      _   _   _    _   _   _
[802, 2, 24, 45, 66, 170, 75, 90]
</code></pre>
<p>最終，對最後一個位數進行排序。大功告成！</p>
<pre><code> 8    0  0   0   0   1    0   0
 _                   _
[802, 2, 24, 45, 66, 170, 75, 90]

sort by leftmost digit --&gt;

 0  0   0   0   0   0   1    8
                        _    _
[2, 24, 45, 66, 75, 90, 170, 802]
</code></pre>
<a class="header" href="#a效能-13" id="a效能-13"><h2>效能</h2></a>
<table><thead><tr><th>              </th><th> Complexity   </th></tr></thead><tbody>
<tr><td> Worst        </td><td> $O(dn) $ </td></tr>
<tr><td> Best         </td><td> $O(dn) $ </td></tr>
<tr><td> Average      </td><td> $O(dn) $ </td></tr>
<tr><td> Worst space  </td><td> $O(d + n) $ auxiliary </td></tr>
</tbody></table>
<blockquote>
<p>$n $：資料筆數。<br />
$d $：number of digit，資料中最多有幾個位數（或鍵值）。<br />
$k $：基數，就是一個位數最多有幾種可能的值。</p>
</blockquote>
<a class="header" href="#time-complexity-4" id="time-complexity-4"><h3>Time complexity</h3></a>
<p>欲分析 Radix sort 的時間複雜度，我們可以逐一擊破，先從排序副程式開始分析。</p>
<p>Radix sort 的 subroutine 通常採用 Counting sort 或 Bucket sort，因此每個 subroutine 的複雜度為 $O(n + k) $， $k $ 為 key 的範圍，以 10 為基數，就是 0 - 9 之間 $k = 10 $。</p>
<p>再來，我們分析整個主程式，Radix sort 每個位數各需排序一次，若最多位數的資料有 $d $ 位數，時間複雜度需乘上 $d $，為 $O(d (n + k)) $，那這個 $k $ 是否可以捨去呢？</p>
<p>分析 Counting sort 或 Bucket sort 時，範圍 $k $ 會隨輸入資料而變化，若 $k $ 過大，對複雜度的影響甚至會超過 $n $，因此分析複雜度時無法將 $k $ 捨去。而在 Radix sort， $k $ 通常為一個已知的常數，例如以 bytes 為基數 $k = 8 $， $k $ 可以捨去。最後可得 Radix sort 的時間複雜度為 $O(d \cdot n) $。</p>
<a class="header" href="#space-complexity-4" id="space-complexity-4"><h3>Space complexity</h3></a>
<p>Radix sort 的空間複雜度同樣取決於排序副程式，Counting sort 與 Bucket sort 的空間複雜度皆為 $O(n \cdot k) $。Radix sort 的 $k $ 是常數，予以捨去。再乘上 $d $ 個位數，最差的空間複雜度為 $O(d \cdot n) $。</p>
<a class="header" href="#a實作-13" id="a實作-13"><h2>實作</h2></a>
<p>這裡示範實作以 10 為基數，用來排序非負整數的 Radix sort。</p>
<p>首先，我們的排序副程式使用 Counting sort。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
// 0. Include counting sort.
use ::sorting::counting_sort;
#}</code></pre></pre>
<p>再來，就是 Radix sort 本體了。為了凸顯 Radix sort 的概念，簡化了函式參數數量，除去泛型宣告，並將基數選擇寫死在函式裡。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn radix_sort(arr: &amp;mut [i32]) {
    let radix = 10;             // 1
    let mut digit = 1;          // 2
    let max_value = arr         // 3
      .iter()
      .max()
      .unwrap_or(&amp;0)
      .clone();
    while digit &lt;= max_value {  // 4
        counting_sort(arr, 0, 9, |t| (t / digit % radix) as usize); // 5
        digit *= radix;         // 6
    }
}
#}</code></pre></pre>
<ol>
<li>設定基數為 10。</li>
<li>設定一個旗標，記錄當前在排序哪一位數，1 表示從最小位數（個位數）開始。</li>
<li>先找到輸入資料的最大值，作為之後副程式迴圈結束的條件。尋找最大值的複雜度為 $O(n)$，因此不影響 Radix Sort 的複雜度。如果 <code>arr</code> 為空序列，則最大值設為 0，在第四步驟就會自動結束排序。</li>
<li>判斷當前排序的位數是否大於最大值，例如當前排序百分位，<code>digit</code> 為 <code>100</code>，而最大值 <code>x</code> 為 26，則不需再排序百分位。</li>
<li>使用 Counting sort 作為排序副程式，只需要有 0 - 9 十個桶子。而 <code>key</code> 參數則取出當前欲比較的位數。</li>
<li>位數乘上基數，移至下一個位數繼續比較。</li>
</ol>
<blockquote>
<p>小提醒：這是簡單又容易理解的實作，相對有許多額外的運算開銷（例如尋找最大值）。實務上，會在對資料有些了解才採用 Radix sort，因此實作並不會這麼 naive。</p>
</blockquote>
<a class="header" href="#a參考資料-16" id="a參考資料-16"><h2>參考資料</h2></a>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Radix_sort">Wiki: Radix sort</a></li>
<li><a href="https://www.cs.princeton.edu/%7Ers/AlgsDS07/18RadixSort.pdf">Princeton University DSA Course: Radix sort</a></li>
<li><a href="https://www.byvoid.com/zht/blog/sort-radix">ByVoid: 三種線性排序算法 計數排序、桶排序與基數排序</a></li>
</ul>
<a class="header" href="#data-structures" id="data-structures"><h1>Data Structures</h1></a>
<p>🚧 🚧 🚧 TBD 🚧 🚧 🚧</p>
<a class="header" href="#a堆疊與佇列-1" id="a堆疊與佇列-1"><h1>堆疊與佇列</h1></a>
<ul>
<li><a href="stack">🚧 堆疊 Stack</a></li>
<li><a href="queue">🚧 佇列 Queue</a></li>
<li><a href="deque">🚧 雙端佇列 Deque</a></li>
</ul>
<a class="header" href="#a堆疊-stack" id="a堆疊-stack"><h1>堆疊 Stack</h1></a>
<a class="header" href="#a參考資料-17" id="a參考資料-17"><h2>參考資料</h2></a>
<a class="header" href="#a佇列-queue" id="a佇列-queue"><h1>佇列 Queue</h1></a>
<a class="header" href="#a參考資料-18" id="a參考資料-18"><h2>參考資料</h2></a>
<a class="header" href="#a雙端佇列-deque" id="a雙端佇列-deque"><h1>雙端佇列 Deque</h1></a>
<a class="header" href="#a參考資料-19" id="a參考資料-19"><h2>參考資料</h2></a>
<a class="header" href="#a鏈結串列-linked-list" id="a鏈結串列-linked-list"><h1>鏈結串列 Linked list</h1></a>
<p>鏈結串列是一種基本線性資料集合，每一個資料元素都是獨立的物件。儲存資料的方式和一般陣列配置連續物理記憶體空間不同，而是在各節點儲存額外的指標指向下一個節點。</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/6/6d/Singly-linked-list.svg/612px-Singly-linked-list.svg.png" alt="" /></p>
<p><em>(單向鏈結串列示意圖）</em></p>
<a class="header" href="#a特性" id="a特性"><h2>特性</h2></a>
<p>鏈結串列有以下特性與優點：</p>
<ul>
<li>不需事先知道資料型別大小，充分利用動態記憶體管理。</li>
<li>以常數時間插入／刪除，不需重新配置記憶體（reallocation）。</li>
<li>不同的串列若有資料相同時，可以共享節點或資料，節省空間。</li>
</ul>
<p>但也因動態配置記憶體等因素，連帶產生一些缺陷：</p>
<ul>
<li><strong>空間開銷大</strong>：每個元素需儲存額外的指標空間。</li>
<li><strong>較差的 CPU 快取</strong>：不連續存取的特性，不利於 <a href="https://en.wikipedia.org/wiki/CPU_cache">CPU 快取</a>。</li>
<li><strong>不允許隨機存取（random access）</strong>：搜尋特定索引下的節點仍需線性時間。</li>
</ul>
<a class="header" href="#a適用場景" id="a適用場景"><h2>適用場景</h2></a>
<p>大多數的場景其實不太常使用鏈結串列，Rust 內建的 <a href="https://doc.rust-lang.org/std/collections/struct.LinkedList.html"><code>LinkedList</code></a> 文件也建議，除非肯定要用鏈結串列，不然建議優先考慮其他類似的資料結構如 <a href="https://doc.rust-lang.org/std/collections/vec_deque/struct.VecDeque.html"><code>VecDeque</code></a>。話雖如此，鏈結串列仍有不少應用場景：</p>
<ul>
<li>需要頻繁地插入與刪除資料。</li>
<li>需要頻繁分離與合併（split and merge）資料。</li>
<li>不需要隨機存取的資料。</li>
<li>遞迴友好，因此成為大多函數式語言中基本資料型別之一。</li>
<li>教學上，常用於實作抽象資料型別，如<a href="../stack">堆疊</a>與<a href="../queue">佇列</a>等等。</li>
</ul>
<a class="header" href="#a術語" id="a術語"><h2>術語</h2></a>
<a class="header" href="#node" id="node"><h3>Node</h3></a>
<p>又稱「節點」，為組成鏈結串列的基本元素，節點包含資料儲存區與指標儲存區，指標儲存區用以儲存指向其他節點位址的變數。此外，最後一個節點的不指向其他節點位址的指標成為 null pointer，慣例以 NULL 表示。</p>
<p><img src="../singly_linked_list/node-box.svg" alt="node-box" /></p>
<p><em>（節點示意圖）</em></p>
<a class="header" href="#head-and-tail" id="head-and-tail"><h3>Head and tail</h3></a>
<p>Head 為指向整個串列第一個節點的指標。而 tail 則為指向最後一個節點的指標。用 ASCII 圖表示如下：</p>
<pre><code>   head                      tail
    |                         |
    v                         v
+--------+   +--------+   +--------+
|        |   |        |   |        |
| node 0 |--&gt;| node 1 |--&gt;| node 2 |--&gt; NULL
|        |   |        |   |        |
+--------+   +--------+   +--------+
</code></pre>
<a class="header" href="#sentinel-node" id="sentinel-node"><h3>Sentinel node</h3></a>
<p>Sentinal node 一個特殊的節點，資料值為 NULL 的節點，用意代表鏈結串列的端點。也就是說，sentinel node 指向串列第一個節點，而串列最後一個節點也會指向 sentinel node，就像哨兵一樣守著串列前後，因而得名。</p>
<p>實作鏈結串列時，常常因為判斷節點是否為 NULL 而讓程式變得複雜，而 sentinel node 可減少程式操作步驟，也能增加程式可讀性。詳細資訊可以參考這篇 <a href="https://stackoverflow.com/questions/5384358/">NULL 與 sentinel node 的比較討論</a>。</p>
<pre><code>    +-----------------------------------------------+
    |                                               |
    v                                               |
+---------+   +--------+   +--------+   +--------+  |
|sentinel |   |        |   |        |   |        |  |
|         |--&gt;| node 0 |--&gt;| node 1 |--&gt;| node 3 |--+
|  node   |   |        |   |        |   |        |
+---------+   +--------+   +--------+   +--------+
</code></pre>
<a class="header" href="#a種類" id="a種類"><h2>種類</h2></a>
<p>依據每個節點的鏈結多寡，可分為</p>
<p><a href="singly">單向鏈結串列</a>，每個節點只有一個指標，指向下一個節點。</p>
<pre><code>+--------+   +--------+   +--------+
|        |   |        |   |        |
| node 0 |--&gt;| node 1 |--&gt;| node 2 |--&gt; NULL
|        |   |        |   |        |
+--------+   +--------+   +--------+
</code></pre>
<p><a href="doubly">雙向鏈結串列</a>，每個節點有兩個指標，分別指向前後一個節點。</p>
<pre><code>        +--------+   +--------+   +--------+
        |        |--&gt;|        |--&gt;|        |--&gt; NULL
        | node 0 |   | node 1 |   | node 2 |
NULL &lt;--|        |&lt;--|        |&lt;--|        |
        +--------+   +--------+   +--------+
</code></pre>
<p>倘若該鏈結串列末端節點的指標指向第一個的節點，形成一個循環，則稱之為「<a href="circular">循環鏈結串列</a>」。</p>
<pre><code>Singly linked list as circular

+-----------------------------------------+
|                                         |
|   +--------+   +--------+   +--------+  |
|   |        |   |        |   |        |  |
+--&gt;| node 0 |--&gt;| node 1 |--&gt;| node 3 |--+
    |        |   |        |   |        |
    +--------+   +--------+   +--------+
</code></pre>
<p>詳細說明與實作請點選各個連結。</p>
<a class="header" href="#a參考資料-20" id="a參考資料-20"><h2>參考資料</h2></a>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Linked_list">Wiki: Linked list</a></li>
<li>Singly linked list SVG By Lasindi [Public domain], via Wikimedia Commons.</li>
</ul>
<a class="header" href="#a單向鏈結串列-singly-linked-list" id="a單向鏈結串列-singly-linked-list"><h1>單向鏈結串列 Singly linked list</h1></a>
<p>單向鏈結串列是鏈結串列家族中最簡單的版本，特色是每兩個節點間只有一個單向的鏈結。</p>
<pre><code>   head
    |
    v
+--------+   +--------+   +--------+
|        |   |        |   |        |
| node 0 |--&gt;| node 1 |--&gt;| node 2 |--&gt; NULL
|        |   |        |   |        |
+--------+   +--------+   +--------+
</code></pre>
<a class="header" href="#a架構設計" id="a架構設計"><h2>架構設計</h2></a>
<a class="header" href="#node-1" id="node-1"><h3>Node</h3></a>
<p>先建立最基本的節點 Node。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
// cannot compile
struct Node&lt;T&gt; {
    elem: T,
    next: Node&lt;T&gt;,
}
#}</code></pre></pre>
<p><code>Node.elem</code> 很直觀地儲存實際資料。而 <code>Node.next</code> 則是指向下個 Node。但這樣編譯不會成功，Rust 編譯時需要決定每個型別該配置多少記憶體空間，這種遞迴型別使得編譯器無限循環，無法決定配置大小。</p>
<p><img src="node-recursive.svg" alt="node-recursive" /></p>
<p>很簡單，我們使用 <a href="https://doc.rust-lang.org/std/boxed/index.html"><code>Box&lt;T&gt;</code></a> 這個智慧指標，直接將 Node 配置在記憶體 heap 上。如此以來，編譯器就會知道 <code>next</code> 只佔了一個指標的空間。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
struct Node&lt;T&gt; {
    elem: T,
    next: Box&lt;Node&lt;T&gt;&gt;,
}
#}</code></pre></pre>
<p><img src="node-box.svg" alt="node-box" /></p>
<p>由於 Rust 沒有 null pointer，但照鏈結串列的定義，<code>Node.next</code> 可以是 NULL，因此我們使用 <a href="https://doc.rust-lang.org/std/option/index.html"><code>Option&lt;T&gt;</code></a> 模擬 null pointer 的行為。最後，Node 的定義如下：</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
struct Node&lt;T&gt; {
    elem: T,
    next: Option&lt;Box&lt;Node&lt;T&gt;&gt;&gt;,
}
#}</code></pre></pre>
<a class="header" href="#singlylinkedlist" id="singlylinkedlist"><h3>SinglyLinkedList</h3></a>
<p>在開始實作各種增刪節點的操作之前，我們需要建立一個 struct 存放指向鏈結串列 head 的指標，同時，各種操作也會實作在這個 struct 上。事實上，這個 struct 就是對外公開的資料結構。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub struct SinglyLinkedList&lt;T&gt; {
    head: Option&lt;Box&lt;Node&lt;T&gt;&gt;&gt;,
}
#}</code></pre></pre>
<p>選擇把操作串列的函式寫在另一個 struct 而非 Node 上有幾個原因，1）外部並不需知道串列內部如何實作，公開 Node 會暴露實作。2）每個 Node 都帶有成員函式的話，函式指標會佔用太多額外資源。</p>
<a class="header" href="#a基本操作" id="a基本操作"><h2>基本操作</h2></a>
<p>串列的基本操作如下：</p>
<ul>
<li><code>new</code>：初始化一個空串列。</li>
<li><code>push_front</code>：新增節點到開頭的位置。</li>
<li><code>pop_front</code>：將開頭第一個節點移除。</li>
<li><code>insert_after</code>：在指定索引位置後插入一個新節點。</li>
<li><code>remove</code>：移除任意索引下的節點。</li>
<li><code>clear</code>：清除所有節點。</li>
<li><code>is_empty</code>：檢查串列是否沒有任何節點。</li>
<li><code>reverse</code>：反轉整個串列（head 變成 tail）。</li>
</ul>
<a class="header" href="#a初始化與清除資料" id="a初始化與清除資料"><h3>初始化與清除資料</h3></a>
<p>實做初始化與清除資料非常直觀。其中清除其實就只是將 <code>self</code> 指向新的串列實例。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
impl&lt;T&gt; SinglyLinkedList&lt;T&gt; {
    pub fn new() -&gt; Self {
        Self { head: None }
    }

    pub fn clear(&amp;mut self) {
        *self = Self::new();
    }
}
#}</code></pre></pre>
<p>你可能會想，在清除所有資料時，資源需不需要手動釋放？</p>
<p>和 C++ 的 RAII 一樣，Rust 有一個名叫 <code>drop</code> 的解構式，只要程式執行離開了資源擁有者的可視範圍（out of scope），就會自動呼叫 <code>drop</code>。我們在 <a href="#drop-trait">Drop trait</a> 一節會再深入探討。</p>
<a class="header" href="#a增刪首個節點" id="a增刪首個節點"><h3>增刪首個節點</h3></a>
<p>單向鏈結串列在第一個節點前增加新節點，或是刪除第一個節點，都可以在常數時間完成。新增節點 <code>push_front</code> 的概念很簡單，1）建立新的節點，並把新節點 <code>next</code> 指標指向串列第一個節點。2）把串列的 head 指向新建立的節點。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn push_front(&amp;mut self, elem: T) {
    let next = self.head.take(); // 1
    self.head = Some(Box::new(Node { elem, next })); // 2
}
#}</code></pre></pre>
<ol>
<li>釋放 SinglyLinkedList 對第一個節點的所有權</li>
<li>建立一新節點，並將原本第一個節點所有權轉移給新節點。再將新節點所有權轉移到串列本身。</li>
</ol>
<p>刪除第一個節點 <code>pop_front</code> 的實作步驟如下：首先取得第一個節點的所有權，再將 head 指向第一個節點 <code>Node.next</code> 下一個節點，再返回第一個節點的資料給呼叫端。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn pop_front(&amp;mut self) -&gt; Option&lt;T&gt; {
    let head = self.head.take(); // 1
    match head {
        Some(node) =&gt; {
            self.head = node.next;  // 2
            Some(node.elem)         // 3
        }
        None =&gt; None,
    }
}
#}</code></pre></pre>
<ol>
<li>取得第一個元素的所有權。</li>
<li>將 head 指向下一個節點。</li>
<li>返回即將刪除節點的資料。</li>
</ol>
<a class="header" href="#a插入刪除任意節點" id="a插入刪除任意節點"><h3>插入刪除任意節點</h3></a>
<p>鏈結串列新增和刪除第一個節點都可以在 $O(1)$ 時間內做完，那為什麼插入刪除任意節點沒有辦法呢？原因是鏈結串列不支援隨機存取（random access），就是無法透過索引在常數時間內取得資料，每次的搜尋都只能從 head 開始。因此，當我們需要在某個索引的節點後新增一筆資料，我們會需要最差 $O(n)$ 的複雜度。</p>
<p>實作插入 <code>insert_after</code> 分為幾個步驟：</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn insert_after(&amp;mut self, pos: usize, elem: T) -&gt; Result&lt;(), usize&gt; {
    let mut curr = &amp;mut self.head;
    let mut pos_ = pos;

    while pos_ &gt; 0 {                        // 1
        curr = match curr.as_mut() {
            Some(node) =&gt; &amp;mut node.next,
            None =&gt; return Err(pos - pos_),
        };
        pos_ -= 1;
    }

    match curr.take() {                     // 2
        Some(mut node) =&gt; {   // Node A
            let new_node = Box::new(Node {  // 3: Node B
                elem,
                next: node.next,
            });
            node.next = Some(new_node);     // 4
            *curr = Some(node);             // 5
        }
        None =&gt; return Err(pos - pos_)
    }
    Ok(())
}
#}</code></pre></pre>
<ol>
<li>找到對應索引值的節點 A，若找不到則回傳這個串列的資料長度。</li>
<li>先取得節點 A 的所有權，才能修改它的值。</li>
<li>建立新節點 B，同時將節點 B 的 <code>next</code> 指向 A 的後一個節點。</li>
<li>將新節點 B 做為節點 A 後一個節點 <code>next</code>。</li>
<li>把修改過的節點 A，重新賦值給指向節點 A 的指標 <code>curr</code>（可視為歸還所有權）。</li>
</ol>
<p>而實作刪除任意索引下的節點 <code>remove</code> 和插入非常相似。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn remove(&amp;mut self, pos: usize) -&gt; Option&lt;T&gt; {
    let mut curr = &amp;mut self.head;
    let mut pos = pos;

    while pos &gt; 0 {                // 1
        curr = match curr.as_mut() {
            Some(node) =&gt; &amp;mut node.next,
            None =&gt; return None,
        };
        pos -= 1;
    }

    match curr.take() {            // 2
        Some(node) =&gt; { // Node A
            *curr = node.next;     // 3: node.next is Node B
            Some(node.elem)        // 4
        }
        None =&gt; None
    }
}
#}</code></pre></pre>
<ol>
<li>找到對應索引值的節點 A，若找不到則回傳 <code>None</code>。</li>
<li>先取得節點 A 的所有權，才能修改它的值。</li>
<li>把節點 A 的後一個節點 B 賦值給原本指向節點 A 的指標 <code>curr</code>。</li>
<li>回傳節點 A 的值。</li>
</ol>
<a class="header" href="#a反轉" id="a反轉"><h3>反轉</h3></a>
<p>反轉鏈結串列是工作面試時很常見的考題，這裡來實作看看。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn reverse(&amp;mut self) {
    let mut prev = None;              // 1: prev -&gt; Node P
    let mut curr = self.head.take();  // 2
    while let Some(mut node) = curr { // 3: node -&gt; Node A
        let next = node.next;         // 3-1: next -&gt; Node B
        node.next = prev.take();      // 3-2
        prev = Some(node);            // 3-3
        curr = next;                  // 3-4
    }
    self.head = prev.take(); // 4
}
#}</code></pre></pre>
<ol>
<li>先建立一個暫時變數 <code>prev</code>，儲存迭代時的前一個節點。</li>
<li>從串列 head 取得第一個節點的所有權。</li>
<li>依序迭代整個串列
<ol>
<li>將節點 A 的後一個節點 B 暫存起來。</li>
<li>節點 A 的 <code>next</code> 指向暫存在變數 <code>prev</code> 的節點 P。</li>
<li>節點 A 暫存在變數 <code>prev</code> 內，保留到下一個迭代使用。</li>
<li>將節點 B 儲存在變數 <code>curr</code> 內。此時<br />
<code>prev</code>：節點 A，A 的 <code>next</code> 指向 P，<br />
<code>curr</code>：節點 B，B 的 <code>next</code> 指向 A。</li>
</ol>
</li>
<li>最後一次迭代時，變數 <code>prev</code> 會儲存原始串列末端節點，這時轉移所有權到 head，完成反轉。</li>
</ol>
<a class="header" href="#traits" id="traits"><h2>Traits</h2></a>
<p>除了基本操作，<code>SinglyLinkedList</code> 實作了許多 trait，使用上更方便更符合 Rust 的慣例。</p>
<a class="header" href="#drop-trait" id="drop-trait"><h3>Drop trait</h3></a>
<p>如果一個 struct 有許多成員，則會遞迴呼叫 struct 的 <code>drop</code> 成員函式。因此，一個串列的解構式很可能發生深層的巢狀遞迴：</p>
<pre><code># a linked list
a -&gt; b -&gt; c -&gt; x -&gt; y -&gt; z

# call stack when `drop` being called

(a.drop
  (b.drop
    (c.drop
      (x.drop
        (y.drop
          (z.drop
          (z.dropped
        (y.dropped
      (x.dropped
    (c.dropped
  (b.dropped
(a.dropped
</code></pre>
<p>如果節點一多，肯定會 stack overflow，太可怕了！</p>
<p>既然如此，那麼就透過 <a href="https://doc.rust-lang.org/std/ops/trait.Drop.html">Drop trait</a>，實作一個迭代版本的解構式，消弭可怕的 call stack 吧。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
impl&lt;T&gt; Drop for SinglyLinkedList&lt;T&gt; {
    fn drop(&amp;mut self) {
        let mut link = self.head.take();  // 1
        while let Some(mut node) = link { // 2
            link = node.next.take();      // 3
        }                                 // 4
    }
}
#}</code></pre></pre>
<ol>
<li>取得 head 的所有權。</li>
<li>透過 pattern matching 取得 Node 裡面 Box 的所有權。</li>
<li>取得下一個 Node 的所有權，並將它指向共用的變數 <code>link</code>。</li>
<li>離開了 <code>node</code> 的 scope，<code>node</code> 呼叫 <code>drop</code> 釋放自身資源。</li>
</ol>
<blockquote>
<p>詳細思路過程可查看 Learning Rust With Entirely Too Many Linked Lists 的 <a href="http://cglab.ca/%7Eabeinges/blah/too-many-lists/book/first-drop.html">Drop</a> 章節，該章完整闡述為什麼不能用 tail recursive 來實作，但最大的原因是 Rust core team 暫時延緩實踐 <a href="https://github.com/rust-lang/rfcs/pull/1888">tail call optimization</a>。</p>
</blockquote>
<a class="header" href="#iterator-and-intoiterator-traits" id="iterator-and-intoiterator-traits"><h3>Iterator and IntoIterator traits</h3></a>
<p>既然鏈結串列是一種序列（sequence，有序的資料結構），少不了實作 <a href="https://doc.rust-lang.org/std/iter/trait.Iterator.html">Iterator</a>、<a href="https://doc.rust-lang.org/std/iter/trait.IntoIterator.html">IntoIterator</a> 等 trait，使串列可以輕鬆使用 for-in loop 遍歷（traverse）。</p>
<p>首先，先定義幾個迭代器的 struct。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub struct IntoIter&lt;T&gt;(SinglyLinkedList&lt;T&gt;);

pub struct Iter&lt;'a, T: 'a&gt; {
    next: Option&lt;&amp;'a Node&lt;T&gt;&gt;,
}

pub struct IterMut&lt;'a, T: 'a&gt; {
    next: Option&lt;&amp;'a mut Node&lt;T&gt;&gt;,
}
#}</code></pre></pre>
<p>建立這三個 iterator struct 是常見的 Rust 設計模式。</p>
<ul>
<li><code>IntoIter</code>：產生 <code>T</code>，實作會吃掉元素所有權的 <code>IntoIterator</code> trait</li>
<li><code>Iter</code>：產生 <code>&amp;T</code>，實作提供 immutable borrow 的 <code>Iterator</code> trait。</li>
<li><code>IterMut</code>：產生 <code>&amp;mut T</code>，實作提供 mutable borrow 的 <code>Iterator</code> trait。</li>
</ul>
<p>相對應的，<code>SinglyLinkedList</code> 則新增三個成員函式：</p>
<ul>
<li><code>fn into_iter(self) -&gt; IntoIter&lt;T&gt;</code>：轉移所有權的迭代器。<em>Into</em> 一詞慣例上指涉所有權移轉。</li>
<li><code>fn iter(&amp;self) -&gt; Iter&lt;T&gt;</code>：以 immutable reference 迭代串列。</li>
<li><code>fn iter_mut(&amp;mut self) -&gt; IterMut&lt;T&gt;</code>：以 mutable reference 迭代串列。</li>
</ul>
<p>先來看 <code>IntoIter</code> 實作。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub struct IntoIter&lt;T&gt;(SinglyLinkedList&lt;T&gt;);      // 1

impl&lt;T&gt; Iterator for IntoIter&lt;T&gt; {                // 2
    type Item = T;
    fn next(&amp;mut self) -&gt; Option&lt;Self::Item&gt; {
        self.0.pop_front()
    }
}

impl&lt;T&gt; IntoIterator for SinglyLinkedList&lt;T&gt; {    // 3
    type Item = T;
    type IntoIter = IntoIter&lt;T&gt;;
    fn into_iter(self) -&gt; Self::IntoIter {
        IntoIter(self)
    }
}
#}</code></pre></pre>
<ol>
<li>宣告一個 tuple struct，唯一的成員是 <code>SinglyLinkedList</code>。</li>
<li>實作 <code>Iterator</code> trait 的 required method <code>next</code>，為了達成 <em>Into</em> 會消耗原始資料，轉換所有權的特性，我們利用 <code>pop_front()</code> 將節點的資料依序刪除（pop）。</li>
<li><code>IntoInterator</code> 的 required method 傳遞 <code>self</code> 進來，所以無論怎麼實作 <code>IntoIter</code> struct，呼叫 <code>into_iter()</code> 後，外部就無法再次存取此 <code>SinglyLinkedList</code> 實例，達到所有權轉移的目標。</li>
</ol>
<blockquote>
<p>可能有人會疑惑，<code>IntoIter</code> 並沒有內部狀態記錄欄位，迭代器如何依據狀態產生下一筆資料？受惠於 <code>IntoIterator</code> 傳遞所有權的特性，<code>IntoIter</code> 可直接改變原始串列的內部狀態，例如 <code>pop_front</code> 會移除原始串列的節點。因此，相較於 <code>Iter</code>、<code>IterMut</code> 額外記錄狀態，<code>IntoIter</code> 不需自行記錄迭代器的迭代狀態。</p>
</blockquote>
<p>再來看看 <code>Iter</code> 怎麼實踐。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub struct Iter&lt;'a, T: 'a&gt; {                    // 1
    next: Option&lt;&amp;'a Node&lt;T&gt;&gt;,
}

impl&lt;T&gt; Iterator for Iter&lt;'a, T&gt; {
    type Item = &amp;'a T;                          // 2
    fn next(&amp;mut self) -&gt; Option&lt;Self::Item&gt; {
        match self.next {
            Some(node) =&gt; {
                self.next = node.next.as_ref().map(|node| &amp;**node); // 3, 4
                Some(&amp;node.elem)
            }
            None =&gt; None,
        }
    }
}

impl&lt;T&gt; SinglyLinkedList&lt;T&gt; {
    // ...

    pub fn iter(&amp;self) -&gt; Iter&lt;T&gt; {             // 5
        Iter { next: self.head.as_ref().map(|node| &amp;**node) } // 6
    }
}
#}</code></pre></pre>
<ol>
<li>這個 struct 的 <code>next</code> 是為了儲存 <code>Node</code> 資訊，方便記錄迭代器當前的狀態。加上生命週期 <code>'a</code> 是因編譯器無法推敲 <code>Option&lt;&amp;Node&lt;T&gt;&gt;</code> 會活多久，需要顯著標明 <code>&amp;Node</code> 至少與該迭代器同生共死。</li>
<li>由於 <code>Iter</code> 是為了實作產生 <code>&amp;T</code> 的迭代器，associated type 設為  <code>&amp;'a T</code>。</li>
<li>將當前節點的後一個節點設為 <code>Iter</code> 迭代器的狀態。並回傳當前節點的資料。<br />
這邊用了 <code>as_ref()</code> 肇因於 <code>Option.map</code> 的泛型型別與 <code>Option&lt;T&gt;</code> 一樣，所以會產生所有權轉移至 <code>map</code> 的 <code>FnOnce</code> 內部。<code>as_ref()</code> 將 <code>Option&lt;T&gt;</code> 轉換成 <code>Option&lt;&amp;T&gt;</code>，<code>map</code> 就不會發生所有權的問題。</li>
<li>此外，<code>map</code> 連續使用兩個 deref 與一個轉為 reference 的操作，是將型別以下列順序轉換。
<ul>
<li><code>Option&lt;&amp;Box&lt;Node&lt;T&gt;&gt;&gt;</code> → <code>map</code></li>
<li>→ <code>&amp;Box&lt;Node&lt;T&gt;&gt;</code> → <code>*node</code></li>
<li>→ <code>Box&lt;Node&lt;T&gt;&gt;</code> → <code>**node</code></li>
<li>→ <code>Node&lt;T&gt;</code> → <code>&amp;**node</code></li>
<li>→ <code>&amp;Node&lt;T&gt;</code>（至此型別才符合回傳值）</li>
</ul>
</li>
<li>在 <code>SinglyLinkedList</code> 上加 <code>iter()</code> 成員函式回傳 <code>Iter</code> 迭代器。</li>
<li>產生迭代器初始化狀態，和第三步一模一樣。</li>
</ol>
<p>最後，<code>IterMut</code> 與 <code>Iter</code> 迭代器實作上大同小異。把 <code>Iter</code> 用到 <code>Option.as_ref()</code> 改為 <code>Option.as_mut()</code>，其他 <code>&amp;</code> 改成 <code>&amp;mut</code> 即可。</p>
<a class="header" href="#partialeq-trait" id="partialeq-trait"><h3>PartialEq trait</h3></a>
<p><a href="https://doc.rust-lang.org/std/cmp/trait.PartialEq.html">PartialEq trait</a> 是用來實現兩個串列是否能夠比較，而我們在此定義如下：</p>
<p>有兩個 <code>SinglyLinkedList</code> Sa、Sb，Sa、Sb 的元素皆符合 <code>PartialEq</code> trait。當</p>
<ul>
<li>Sa 的總節點數 等於 Sb 的總節點數，</li>
<li>Sa 所有元素依序等於 Sb 所有元素，</li>
</ul>
<p>則稱 Sa 與 Sb 有 partial equiavalence（<code>Sa == Sb</code>）。</p>
<p>實作上我們用了 <code>iter</code> 成員函式把兩個串列 <code>zip</code> 在一起，在用 <code>all</code> 確認元素兩兩相等，十分 Rust 風格的作法。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
impl&lt;T: PartialEq&gt; PartialEq for SinglyLinkedList&lt;T&gt; {
    fn eq(&amp;self, other: &amp;Self) -&gt; bool {
        if self.len() != other.len() {
            return false;
        }
        self.iter()
            .zip(other.iter())
            .all(|pair| pair.0 == pair.1)
    }
}
#}</code></pre></pre>
<a class="header" href="#debug-trait" id="debug-trait"><h3>Debug trait</h3></a>
<p>為了方便修復臭蟲，通常會實作 <a href="https://doc.rust-lang.org/std/fmt/trait.Debug.html">Debug trait</a> 印出有助於解決問題的資料。歸功於 <code>Iterator</code> 的實踐，我們可以快速用 <code>self.iter()</code> 印出所有節點內的元素，客製化 <code>Debug</code> 的顯示方式。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
impl&lt;T: std::fmt::Debug&gt; std::fmt::Debug for SinglyLinkedList&lt;T&gt; {
    fn fmt(&amp;self, f: &amp;mut std::fmt::Formatter) -&gt; std::fmt::Result {
        for elem in self.iter() {
            write!(f, &quot;{:?} -&gt; &quot;, elem)?
        }
        Ok(())
    }
}
#}</code></pre></pre>
<a class="header" href="#a效能-14" id="a效能-14"><h2>效能</h2></a>
<table><thead><tr><th> Operation </th><th> Complexity                                      </th></tr></thead><tbody>
<tr><td> get       </td><td> $O(n)$                                      </td></tr>
<tr><td> insert    </td><td> 節點已知：$O(1)$ ；節點未知：$O(n - i)$ </td></tr>
<tr><td> remove    </td><td> 節點已知：$O(1)$ ；節點未知：$O(n - i)$ </td></tr>
<tr><td> append    </td><td> $O(n)$                                      </td></tr>
<tr><td> prepend   </td><td> $O(1)$                                      </td></tr>
<tr><td> pop first </td><td> $O(1)$                                      </td></tr>
<tr><td> pop last  </td><td> $O(n)$                                      </td></tr>
<tr><td> space     </td><td> $O(n)$ + 各節點額外一個指標 $n$ 個      </td></tr>
</tbody></table>
<blockquote>
<p>$n$：資料筆數。<br />
$i$：相對於整個容器的索引位置。</p>
</blockquote>
<p>值得觀察的是，許多操作因為單向鏈結串列只能從 head 開始搜索的緣故，執行時間都呈線性，使用上要特別注意。</p>
<a class="header" href="#a參考資料-21" id="a參考資料-21"><h2>參考資料</h2></a>
<ul>
<li><a href="https://doc.rust-lang.org/src/alloc/linked_list.rs.html">Rust Documentation: LinkedList</a></li>
<li><a href="http://cglab.ca/%7Eabeinges/blah/too-many-lists/book/README.html">Learning Rust With Entirely Too Many Linked Lists</a></li>
<li><a href="https://stackoverflow.com/questions/51134192/">Duscussions at Stackoverflow</a></li>
<li><a href="https://codereview.stackexchange.com/questions/150906">StackExchange: Reversal of a singly-linked list in Rust</a></li>
<li>SVG of node memory representation modified from <a href="https://doc.rust-lang.org/book/2018-edition">The Rust Programming Language</a></li>
</ul>
<a class="header" href="#a雙向鏈結串列-doubly-linked-list" id="a雙向鏈結串列-doubly-linked-list"><h1>雙向鏈結串列 Doubly linked list</h1></a>
<a class="header" href="#a操作" id="a操作"><h2>操作</h2></a>
<a class="header" href="#a效能-15" id="a效能-15"><h2>效能</h2></a>
<a class="header" href="#a循環鏈結串列-circular-linked-list" id="a循環鏈結串列-circular-linked-list"><h1>循環鏈結串列 Circular linked list</h1></a>
<a class="header" href="#a操作-1" id="a操作-1"><h2>操作</h2></a>
<a class="header" href="#a效能-16" id="a效能-16"><h2>效能</h2></a>
<a class="header" href="#a關聯容器-associative-container" id="a關聯容器-associative-container"><h1>關聯容器 Associative Container</h1></a>
<p>關聯容器是一種抽象資料型別，儲存鍵與值配對關係（key-value pair）的集合，並透過鍵存取元素，所謂「鍵值對」好比身份證字號與公民，戶政單位知道一個人證號，就可在關聯容器內，透過證號查找是否有這個公民，以及此證號對應的公民基本資訊。</p>
<p>關聯容器有許多別名，例如字典（dictionary）、關聯陣列（associative array）、映射（map）、表（table）等。在大多數程式語言函式庫中，關聯容器通常是最基本的容器型別之一，如 Python 的 <code>dict</code>，JavaScript 的 <code>Map</code>，以及 Rust 的 <code>HashMap</code>。</p>
<p>方便起見，本文以「<strong>映射表</strong>」統稱這類集合型別。</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/5/5a/Hash_table_5_0_1_1_1_1_0_LL.svg/1280px-Hash_table_5_0_1_1_1_1_0_LL.svg.png" alt="" /></p>
<p><em>（雜湊表示意圖）</em></p>
<a class="header" href="#a特性-1" id="a特性-1"><h2>特性</h2></a>
<p>一般來說，映射表有以下特性：</p>
<ul>
<li><strong>鍵值對為單向關係</strong>：可透過鍵取得其唯一值；但無法確保一值僅對應唯一的鍵。</li>
<li><strong>鍵值唯一性</strong>：同個映射表內，同個鍵不重複，只會出現一次。</li>
<li><strong>元素組合性</strong>：映射表內每個元素都是「鍵值對」，鍵或值無法單獨存在。</li>
<li><strong>操作開銷小</strong>：合理實作下，基本操作開銷相對較小，不高於線性時間。</li>
</ul>
<blockquote>
<p>註：多重映射表為一對多的例外。</p>
</blockquote>
<p>映射表會有以下幾種基本操作：</p>
<ul>
<li><strong>新增</strong>：配對鍵值關聯，又稱為綁定 binding。</li>
<li><strong>修改</strong>：修改任意鍵之下的值。</li>
<li><strong>移除</strong>：透過任意鍵移除該鍵值對，又稱 unbinding。</li>
<li><strong>查找</strong>：透過任意鍵搜尋該鍵值對。</li>
</ul>
<p>不難看出，基本操作都是透過鍵取得值。事實上，合理實作的映射表，只要透過鍵來操作，就能有良好效能，甚至上述操作能達到 $O(1)$ 複雜度。</p>
<a class="header" href="#a適用場景-1" id="a適用場景-1"><h2>適用場景</h2></a>
<p>雖然映射表依實作不同，效能有所權衡。但其最大優勢仍是可「高效地透過鍵尋找值」，只要有映射關係的資料，都非常適合使用映射表。例如，快取暫存機制需透過特定鍵快速查找暫存值。此外，現代常用的 JSON、TOML 等資料交換格式，都是「鍵—值對」的形式，非常適合使用映射表處理。而應用映射表最有名的實際案例莫過於資料庫的索引，透過索引，我們可以大大降低搜尋的成本，從線性時間直落到對數甚至常數時間，不過相對就需要付出額外時空間建立索引。</p>
<p>我們再次把應用場景條列出來，方便懶人帶著走。</p>
<ul>
<li>有映射關係，處理「鍵—值」配對的資料結構。</li>
<li>處理 JSON、TOML 等資料交換，資料序列化。</li>
<li>實作快取（cache）機制。</li>
<li>資料庫索引的實作方法之一。</li>
<li>查找操作頻率遠高於其他操作時。</li>
</ul>
<p>總的來說，只要資料有對應綁定關係，就可以考慮使用映射表處理。</p>
<a class="header" href="#a種類-1" id="a種類-1"><h2>種類</h2></a>
<p>以下簡單介紹常見的映射表，詳情請點擊各連結。</p>
<a class="header" href="#a雜湊表-hash-map" id="a雜湊表-hash-map"><h3>雜湊表 Hash Map</h3></a>
<p><a href="../hash_map">雜湊表</a>是以雜湊函數實作的映射表。透過<a href="../../hash">雜湊函數</a>將任意資料轉換為固定長度的雜湊值，並將此鍵與一筆資料綁定，再映射到內部資料結構的某位置。理論上，只要雜湊函數品質過得去，雜湊表的基本操作都能在常數時間完成。</p>
<a class="header" href="#a有序映射表-ordered-map" id="a有序映射表-ordered-map"><h3>有序映射表 Ordered Map</h3></a>
<p><a href="../ordered_map">有序映射表</a>係一種有特定排序方式的映射表。常見兩種排序方式，其一是依照插入映射表的先後順序；其二則是依照鍵的大小。不同排序的底層資料結構各異，操作複雜度也不盡相同，如依鍵大小排序的映射表通常使用搜索樹實作，因此「新增」操作的複雜度為較差的 $O(\log n)$。</p>
<a class="header" href="#a多重映射表-multimap" id="a多重映射表-multimap"><h3>多重映射表 Multimap</h3></a>
<p><a href="../multimap">多重映射表</a>允許鍵值對重複，一個鍵可對應多個值（一對多）。類似於映射表內放入陣列，但能以較方便輕鬆的接口操作或迭代整張映射表。</p>
<a class="header" href="#a集合-set" id="a集合-set"><h3>集合 Set</h3></a>
<p><a href="set">集合</a>實際上並無鍵值「關聯」，可將其想像成普通的映射表。只關心鍵而值不重要。集合借用了數學<a href="https://en.wikipedia.org/wiki/Set_theory">集合論（set theory）</a>中有限集合的概念，常應用於需要操作交集、聯集、差集等集合運算場景。</p>
<a class="header" href="#a參考資料-22" id="a參考資料-22"><h2>參考資料</h2></a>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Associative_array">Wiki: Associative array</a></li>
<li><a href="https://en.wikipedia.org/wiki/Associative_containers">Wiki: Associative containers</a></li>
<li><a href="https://en.cppreference.com/w/cpp/container/map">cpprefernce.com: std::map</a></li>
<li><a href="https://doc.rust-lang.org/stable/std/collections/">Rust documentation: std::colledtion</a></li>
<li>Map graph by Jorge Stolfi <a href="http://creativecommons.org/licenses/by-sa/3.0/">CC-BY-SA-3.0</a> via Wikimedia Commons.</li>
</ul>
<a class="header" href="#a雜湊表-hash-map-1" id="a雜湊表-hash-map-1"><h1>雜湊表 Hash Map</h1></a>
<p>雜湊表是以雜湊函數實作的關聯容器。透過雜湊函數，計算鍵（key）對應到容器內部的索引位置，進而找到對應的值（value）。一般來說，雜湊表最常見的實作是以一個簡單陣列儲存資料。</p>
<p>雜湊表的優勢是：</p>
<ul>
<li>在資料量大時，仍然維持常數時間的高效能。</li>
<li>若資料數量上限已知，就可避免重新配置記憶體，效能更佳。</li>
<li>若資料形態已知，就可針對該資料形態找尋適合的雜湊函數最佳化。</li>
</ul>
<p>而雜湊表相對有以下短處：</p>
<ul>
<li>資料量不夠大時，單一操作需要雜湊計算，開銷相對高。</li>
<li>效能與雜湊函數息息相關，較差的函數容易雜湊碰撞，較佳函數計算成本通常較高。</li>
<li>只能以某種偽隨機的順序迭代雜湊表。</li>
</ul>
<a class="header" href="#a概念" id="a概念"><h2>概念</h2></a>
<p>建立雜湊表的第一步，就是配置一定大小的陣列（通常稱為 bucket array），來儲存對應索引的鍵值對。我們以建立電話簿為例，儲存人名與號碼的對應關係。</p>
<pre><code>Create an empty phone book with some blank slots.

          +--------------+
          | 0:           |
          +--------------+
          | 1:           |
          +--------------+
          | 2:           |
          +--------------+
          | 3:           |
          +--------------+
</code></pre>
<p>我們嘗試插入第一筆資料，記錄 Frodo 以及他的手機號碼 88-7-666。</p>
<ol>
<li>透過雜湊函數，計算出 Frodo 的索引值為 1。</li>
<li>將 88-7-666 插入 table[1] 的位置上。</li>
</ol>
<blockquote>
<p>table[1] 這種 bucket array 下的個別索引空間，通常稱為一個 slot 或 bucket。</p>
</blockquote>
<pre><code>Fordo: hash_function(Frodo) --&gt; 1

          +-------------+
          | 0:          |
          +-------------+
Frodo --&gt; | 1: 88-7-666 |
          +-------------+
          | 2:          |
          +-------------+
          | 3:          |
          +-------------+
</code></pre>
<p>嘗試插入另外二筆資料，記錄 Sam 的手機 11-2-333，以及 Gollum 的手機 00-0-000。</p>
<ol>
<li>透過雜湊函數，計算出 Sam 的索引值為 2。</li>
<li>將 11-2-333 插入 table[2] 的位置上。</li>
<li>透過雜湊函數，計算出 Gollumn 的索引值為 0。</li>
<li>將 00-0-000 插入 table[0] 的位置上。</li>
</ol>
<pre><code>Sam: hash_function(Sam) --&gt; 2

          +-------------+
          | 0:          |
          +-------------+
          | 1: 88-7-666 |
          +-------------+
Sam   --&gt; | 2: 11-2-333 |
          +-------------+
          | 3:          |
          +-------------+


Gollum: hash_function(Gollum) --&gt; 0

          +-------------+
Gollum -&gt; | 0: 00-0-000 |
          +-------------+
          | 1: 88-7-666 |
          +-------------+
          | 2: 11-2-333 |
          +-------------+
          | 3:          |
          +-------------+
</code></pre>
<p>若需要取得 Sam 的手機號碼，只要</p>
<ol>
<li>透過雜湊函數，計算出 Sam 的索引值為 2。</li>
<li>從 table[2] 的索引位置上，找到 Sam 的手機號碼</li>
</ol>
<pre><code>Sam: hash_function(Sam) --&gt; 2

          +-------------+
          | 0: 00-0-000 |
          +-------------+
          | 1: 88-7-666 |
          +-------------+
Sam   --&gt; | 2: 11-2-333 | --&gt; Sam's phone number
          +-------------+
          | 3:          |
          +-------------+
</code></pre>
<p>這就是最基本，以陣列實作的雜湊表了。</p>
<p>然而，你可能已經開始好奇了。</p>
<ul>
<li>雜湊是什麼？怎麼知道要映射到哪個索引位置？</li>
<li>雜湊函數是否會計算出相同的索引值？要如何解決？</li>
<li>若預先配置的陣列填滿了，該如何處理？</li>
</ul>
<p>接下來，將探討這幾個魔術般的因子，從簡單介紹雜湊函數，到如何解決雜湊碰撞，最後探討陣列塞滿重配置解決方案。</p>
<blockquote>
<p>註：雜湊表也可以搜尋樹等其他資料結構實作，在此不深入討論。</p>
</blockquote>
<a class="header" href="#a雜湊" id="a雜湊"><h3>雜湊</h3></a>
<p>所謂的雜湊函數，就是一種將「較寬的定義域映射到較窄值域」的函數。簡單來說，就是輸入任意值到此函數，則輸出值會落在一已知範圍。再白話一點，雜湊函數就是用來「化繁為簡」，把複雜多變的東西，透過函數生成簡化版本。此外，相同的輸入鍵，必須得到相同的輸出雜湊值，這是雜湊函數很重要的一個特性，以虛擬碼表示：</p>
<pre><code>key1 == key2 -&gt; hash(key1) == hash(key2)
</code></pre>
<p>「映射」這部分只是使用雜湊的一小步。雜湊表根據程式實作的不同，底層儲存資料的形式也不盡相同，為了完全放入陣列中，通常會對雜湊值（雜湊函數的計算結果）取模（modulo）。也就是說：假設有長度為 <em>n</em> 的陣列。1）先對 key 取雜湊值。2）再對雜湊值取模，確認索引值落在陣列內部。</p>
<pre><code>Assumed: array_size = n

hash_value = hash_function(key) // 1

index = hash_value % array_size // 2
</code></pre>
<p>如此一來，所有可能的值都會落在陣列內，這就是最簡單普遍的雜湊兩步驟：計算雜湊值﹢取模。</p>
<a class="header" href="#a選擇雜湊函數" id="a選擇雜湊函數"><h3>選擇雜湊函數</h3></a>
<p>接下來，你會緊接著向問第二個問題「函數計算出相同索引值該怎麼辦？」不同輸入產生相同雜湊值，多個值映射到同個索引上，這種狀況科學家稱之<strong>雜湊碰撞（hash collision）</strong>。</p>
<p>首先，要瞭解雜湊函數本身就是時空間的權衡，如果記憶體空間夠多，那讓輸入值與雜湊值呈一對一的完美關係，就不會出現碰撞；大多數情況，尤其是實作泛用的雜湊函式庫，無法預期輸入資料的範圍，實務上會鎖定一個輸出雜湊值的範圍，僧多粥少，難免碰撞。</p>
<p>好的雜湊函數還必須符合一些條件：</p>
<ol>
<li>同一筆輸入資料，必須得到相同的雜湊值。</li>
<li>結果必須能夠高效的計算出來（預期為常數時間）。</li>
<li>任意輸入資料所得之雜湊值在值域內需接近<a href="https://en.wikipedia.org/wiki/Uniform_distribution_(continuous)">均勻分佈（uniform distribution）</a>，才能減少碰撞機率。</li>
</ol>
<p>但總歸一句，欲達成上述條件，就是一種權衡取捨，例如，<a href="https://en.wikipedia.org/wiki/Cryptographic_hash_function">加密雜湊函數（cryptographic hash function）</a>即是非常優秀的雜湊函數，但相對需付出更高的計算成本。</p>
<p>更多雜湊函數相關的討論，會另撰<a href="../../hash">專文</a>。</p>
<a class="header" href="#a處理雜湊碰撞" id="a處理雜湊碰撞"><h3>處理雜湊碰撞</h3></a>
<p>既然雜湊函數人生在世難免碰撞，科學家也研究幾個處理雜湊碰撞的策略，分別是 separate chaining 與 open addressing。</p>
<p><strong>Separate chaining</strong> 可以說是最直觀的做法，就是設法讓同一個索引下，可以儲存多個碰撞的值。依據儲存資料的形式，可分為幾種實作：</p>
<ul>
<li><strong>鏈結串列</strong>：以<a href="../linked_list">鏈結串列（linked list）</a>儲存元素。發生碰撞時，新的元素串接在既有元素之後。</li>
<li><strong>動態陣列</strong>：新增元素時，在該位址配置<a href="../dynamic_array">動態陣列（dynamic array）</a>儲存元素。發生碰撞時，直接將新元素加在陣列尾端。</li>
</ul>
<p>不同實作方式有各自優缺點，例如串列版本容易實作，但需額外儲存指標資訊；用動態陣列，則會有更好的 CPU caching，但相對地碰撞過多則需要重配置陣列。</p>
<p>以 ASCII 表述使用串列實作 separate chaining 示意圖如下：</p>
<pre><code>... assumed hash values of Gimli and Gollum collided.

                          +----------------+
                      +-&gt; |Gollum, 00-0-000| (linked list)
                      |   +----------------+
                      |            |
Gimli -+              |            v
       |              |   +---------------+
       |  +--------+  |   |Gimli, 99-9-999|
Gollum --&gt;|0: ptr  |--+   +---------------+
          +--------+
Frodo  --&gt;|1: ptr  |----&gt; +---------------+ 
          +--------+      |Frodo, 88-7-666|
Sam    --&gt;|2: ptr  |--+   +---------------+
          +--------+  |
          |3: null |  +-&gt; +---------------+
          +--------+      | Sam, 11-2-333 |
     (main bucket array)  +---------------+
</code></pre>
<p>而這邊也有精美的實作示意圖，將串列首個元素 head 直接放置在 slot 中的作法，減少一次指標操作。</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/5/5a/Hash_table_5_0_1_1_1_1_0_LL.svg/1280px-Hash_table_5_0_1_1_1_1_0_LL.svg.png" alt="" /></p>
<p><em>(利用 separate chaining 實作的雜湊表，並將串列第一個元素放在 bucket array 中)</em></p>
<p>另一方面 <strong>Open addressing</strong> 則走完全不同的套路，不額外配置儲存空間給碰撞的元素，而是繼續在同個陣列內「探測」其他可用的 slot，再把資料塞進尚未被佔據的 slot 中。而 Open addressing 依據不同探測序列（probe sequence）有不同實作，常見的有：</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Linear_probing"><strong>Linear probing</strong></a>：從發生碰撞索引開始，依序往下一個 slot 探測是否可用，因此得名「線性」。</li>
<li><a href="https://en.wikipedia.org/wiki/Quadratic_probing"><strong>Quadratic probing</strong></a>：從碰撞索引開始，間隔以二次式增加往下探測可用 slot，如 $i + 1^2, i + 2^2, i + 3^2$。</li>
<li><a href="https://en.wikipedia.org/wiki/Double_hashing"><strong>Double hashing</strong></a>：以固定間隔大小 $k$（probe distance），依序探測 $i + k, i + k \cdot 2 ...$ 的 slot 是否為空。而這個間隔是以另外一個雜湊函數計算所得，因此得名「雙雜湊」。</li>
</ul>
<blockquote>
<p>$i$ 為發生碰撞的索引位置。</p>
</blockquote>
<p>這些方法的差異主要在於 CPU caching 的效能，以及 HashMap 資料的群聚效應（clustering）的敏感程度。當然，論 caching 絕對非 linear probing 莫屬，但 linear probing 以線性一個挨一個探勘，效能較容易受雜湊值群聚影響。</p>
<p>以下是 linear probing（間隔 = 1）的示意圖。</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/9/90/HASHTB12.svg/1280px-HASHTB12.svg.png" alt="" /></p>
<a class="header" href="#a動態調整雜湊表大小" id="a動態調整雜湊表大小"><h3>動態調整雜湊表大小</h3></a>
<p>若資料的筆數已知，那初始配置的陣列大小設定與資料筆數成比例，就不必擔心雜湊表空間不夠，需要重新配置（reallocate）儲存空間的困擾。倘若資料量未知，而最初配置的 bucket array 滿了，該如何重新配置呢？</p>
<p>動態調整大小對雜湊表來說，不同於一般動態陣列，舊的雜湊表若要對應到新雜湊表，是每個鍵都需要重新計算雜湊值（rehash），成本相對較高。因此，減少動態調整的次數，可說是調教雜湊表的重點之一。說到調教雜湊表，必定要瞭解一個重要指標：<em>load factor</em>。</p>
<p>$$\text{load factor} = \frac{n}{k}$$</p>
<blockquote>
<p>$n$：已放入雜湊表內的資料總數。
$k$：雜湊表配置的儲存空間（bucket 總數）。</p>
</blockquote>
<p>Load factor 代表目前雜湊表的「使用率」，若三筆資料放在四個 bucket 內，則 load factor 為 $3/4 = 75%$。Load factor 太大會更容易碰撞，會有效能上的影響；太小則代表過多冗餘空間沒有使用。如何維持 load factor 在一定範圍內至關重要。一般來說，75% 的 load factor 就可以準備重新配置雜湊表了，當然，這個門檻仍要以實作經驗為主，例如 Rust 的 <a href="https://doc.rust-lang.org/stable/std/collections/hash_map/index.html"><code>HashMap</code></a> 使用了 <a href="https://doc.rust-lang.org/stable/src/std/collections/hash/map.rs.html#82-103">Robin Hood Hashing</a>，將 load factor 調教到 90%。</p>
<p>重配置雜湊表與動態陣列的動態調整大小雷同，達到某個門檻值，就會將底層陣列大小翻倍。為了避免開銷過高，通常元素減少時，不會主動調整大小，而是提供一個 <code>shrink_to_fit</code> 一類的方法，讓呼叫端自行決定釋放多餘空間的時機。</p>
<a class="header" href="#a架構設計-1" id="a架構設計-1"><h2>架構設計</h2></a>
<p>在介紹架構設計之前，我們先來瞭解 Rust 雜湊相關的觀念與 trait。</p>
<a class="header" href="#hash-and-eq" id="hash-and-eq"><h3>Hash and Eq</h3></a>
<p>要實作雜湊函數，當然可以自幹計算雜湊值的函式來用，那為什麼還要使用 Rust 定義好的 <a href="https://doc.rust-lang.org/std/hash/trait.Hash.html"><code>Hash</code></a> 呢？當然是希望將雜湊的介面抽象化，只要型別宣告符合 <code>Hash</code> trait，任何人都可以輕鬆計算雜湊值。而實作 <a href="https://doc.rust-lang.org/std/hash/trait.Hash.html"><code>Hash</code></a> 很簡單，只要寫一個 <code>fn hash()</code>，呼叫端就能透過它計算雜湊，例如：</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
use std::hash::{Hash, Hasher};

struct Car {
  brand: String,
}

impl Hash for Car {
    fn hash&lt;H: Hasher&gt;(&amp;self, state: &amp;mut H) {
        self.brand.hash(state);
    }
}
#}</code></pre></pre>
<p>光是計算雜湊值還不夠，要確定「當鍵相等時，其雜湊值也相等」這極為重要的雜湊特性，這時候除了實作 <code>Hash</code> trait，<code>Eq</code> trait 也要同時實作，該型別才能夠「被比較」，標準函式庫的 <code>HashMap</code> 的鍵就是實作 <code>Hash + Eq</code> 的型別，詳情請參閱 trait 的文件說明。</p>
<p>綜合以上，可以大膽定論，我們將實作的雜湊表的 key 一定符合 <code>K: Hash + Eq</code>，key 本身才能相互比較（實作 <code>Eq</code>），並開放呼叫端自定義型別實作不同的雜湊計算方式（實作 <code>Hash</code>）。</p>
<p>為了方便計算雜湊值，我們寫了一個輔助函式，以達成雜湊兩步驟：<strong>計算雜湊值﹢取模</strong>。其中，我們使用了 Rust 預設的雜湊演算法 <a href="https://doc.rust-lang.org/std/collections/hash_map/struct.DefaultHasher.html">DefaultHasher</a>，省下實作雜湊函數的功夫。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
fn make_hash&lt;X&gt;(x: &amp;X, len: usize) -&gt; usize
    where X: Hash + ?Sized,                   // 1
{
    let mut hasher = DefaultHasher::new();    // 2
    x.hash(&amp;mut hasher);
    hasher.finish() as usize % len
}
#}</code></pre></pre>
<ol>
<li><code>X</code> 泛型參數除了 <code>Hash</code>，還必須是 <a href="https://doc.rust-lang.org/book/2018-edition/ch19-04-advanced-types.html#dynamically-sized-types-and-the-sized-trait">Dynamically sized type</a>（DSTs，型別記作 <code>?Sized</code>）</li>
<li>Rust 的 hasher 是一狀態機，每餵他吃資料，<code>hasher.finish()</code> 產生的雜湊值就不同，為了確保雜湊相同，這裡每次呼叫就建立一個全新的 hasher。</li>
</ol>
<blockquote>
<p>所謂 <strong>Dynamically sized type</strong> 是指無法靜態得知大小的型別，例如 slice，或是一個函式的參數接受實作某個 trait 型別（<a href="https://doc.rust-lang.org/book/2018-edition/ch17-02-trait-objects.html">trait object</a>），而在 Rust 幾乎所有基礎型別預設都是 <code>Sized</code> 編譯期就可得知大小。而在這裡我們不關心知道實作該型別可否靜態決定大小，只需知道它是否實作 <code>Hash</code>，所以明確添加 <code>?Sized</code> 表示接受 DST。</p>
</blockquote>
<a class="header" href="#a記憶體佈局" id="a記憶體佈局"><h3>記憶體佈局</h3></a>
<p>我們嘗試建立可以儲存 key-value pair 的結構體，裡面配置一個 bucket array <code>buckets</code>。其中 <code>K</code> 泛型參數是準備計算雜湊的鍵，而 <code>V</code> 則是與鍵配對的資料。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub struct HashMap&lt;K, V&gt; where K: Hash + Eq {
    buckets: Vec&lt;(K, V)&gt;,
}
#}</code></pre></pre>
<p>可是，用單一 <code>Vec</code> 儲存所有資料，萬一雜湊碰撞，不同鍵指向同個索引值該如何？這次先挑選相對容易的方案 separate chaining 處理碰撞，並以 <code>Vec</code> 動態陣列作為每個 bucket 儲存碰撞元素的容器，因此，<code>buckets</code> 陣列裡面改存 <code>Bucket</code> 陣列，而 <code>Bucket</code> 則儲存真正的 key-value pair。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
type Bucket&lt;K, V&gt; = Vec&lt;(K, V)&gt;;              // 1

pub struct HashMap&lt;K, V&gt; where K: Hash + Eq {
   buckets: Vec&lt;Bucket&lt;K, V&gt;&gt;,                // 2
   len: usize,                                // 3
}
#}</code></pre></pre>
<ol>
<li>宣告 bucket 的型別 <code>Bucket</code>，實際上是一個 type alias 指向儲存鍵值 <code>(K, V)</code> 的動態陣列。</li>
<li>將 <code>HashMap.buckets</code> 改為儲存 <code>Bucket</code> 的動態陣列。</li>
<li>新增 <code>len</code> 記錄容器當前鍵值對數目，在增刪資料時， <code>len</code> 都會同步更新。</li>
</ol>
<p>之所以使用額外的成員記錄資料數目，是為了計算數目能在 O(1) 時間內完成，nested array 動態迭代每個 <code>Bucket</code> 計算的成本太高。</p>
<p>這就是 <strong>Vector-based separate chaining HashMap</strong> 的記憶體佈局，來看張精美的雜湊表架構佈局圖吧！</p>
<p><img src="layout.svg" alt="" /></p>
<a class="header" href="#a基本操作-1" id="a基本操作-1"><h2>基本操作</h2></a>
<p>雜湊表有以下幾個基本操作：</p>
<ul>
<li><code>new</code>：初始化一個空雜湊表。</li>
<li><code>with_capacity</code>：配置特定數量 bucket 的雜湊表。</li>
<li><code>get</code>：取得指定鍵對應的資料。</li>
<li><code>get_mut</code>：取得指定鍵對應的資料，並可寫入修改（mutable）。</li>
<li><code>insert</code>：在任意位置插入一組鍵值對。</li>
<li><code>remove</code>：移除任意位置下的鍵值對。</li>
<li><code>clear</code>：清除所有鍵值對。</li>
<li><code>is_empty</code>：檢查雜湊表是否沒有任何鍵值對。</li>
<li><code>len</code>：檢查目前鍵值對的數目。</li>
<li><code>bucket_count</code>：檢查目前 bucket 的數目。</li>
</ul>
<p>以及幾個內部方法：</p>
<ul>
<li><code>try_resize</code>：根據給定條件，決定調整 bucket 數目的時機，讓 load factor 維持最適狀態。</li>
<li><code>make_hash</code>：從輸入資料產生雜湊值，再模除 bucket 數，得到輸入資料對應的索引位置。</li>
</ul>
<p>接下來解釋實作的重點。</p>
<a class="header" href="#a初始化與預設值" id="a初始化與預設值"><h3>初始化與預設值</h3></a>
<p>雜湊表初始化相對容易，一樣慣例使用 <code>new</code>。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
impl&lt;K, V&gt; HashMap&lt;K, V&gt; where K: Hash + Eq {
    pub fn new() -&gt; Self {
        Default::default()
    }
    /// ...
}

impl&lt;K, V&gt; Default for HashMap&lt;K, V&gt; 
    where K: Hash + Eq 
{
    fn default() -&gt; Self { 
        Self { buckets: Vec::&lt;Bucket&lt;K, V&gt;&gt;::new(), len: 0 }
    }
}
#}</code></pre></pre>
<p>這裡為了符合人因工程，使用了 <a href="https://doc.rust-lang.org/std/default/trait.Default.html"><code>Default</code></a> trait 設定初始值。此外，由於 Rust 的容器型別慣例上沒有任何元素時，不會配置任何記憶體空間，僅有初始的 pointer。 HashMap 初始化後，記憶體空間僅需</p>
<ul>
<li><code>buckets</code> 的 <code>Vec</code> 佔據 3 個 usize 大小（一個 heap 指標，兩個記錄容量與長度的 usize。</li>
<li><code>len</code> 本身佔據 1 個 usize 大小。</li>
</ul>
<p>所以預設初始化的 HashMap 在 64bit machine 上佔 4 * usize = 32 bytes。</p>
<p>為了後續實作 resize 容易些，同時實作了指定 bucket 數目的建構式。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn with_capacity(cap: usize) -&gt; Self {
    let mut buckets: Vec&lt;Bucket&lt;K, V&gt;&gt; =  Vec::new();
    for _ in 0..cap {
        buckets.push(Bucket::new());
    }
    Self { buckets, len: 0 }
} 
#}</code></pre></pre>
<p>很清楚地，同樣建立一個空的 bucket array，再預先配置給定數量的 <code>Bucket</code> 。<code>len</code> 則因為沒有開始增加新值，而設定為 0。</p>
<a class="header" href="#a存取單一元素" id="a存取單一元素"><h3>存取單一元素</h3></a>
<p>存取元素的實作也非常直觀，</p>
<ol>
<li>使用 <code>make_hash</code> 計算出 key 對應的索引位置，</li>
<li>再透過 <code>Vec::get</code> 取得該索引下的 bucket，找不到時則返回 <code>None</code>，</li>
<li>找到 bucket 後則對整個 bucket 線性搜索與 key 相同的鍵值對。</li>
</ol>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn get(&amp;self, key: &amp;K) -&gt; Option&lt;&amp;V&gt; {
    let index = self.make_hash(key);
    self.buckets.get(index).and_then(|bucket|
        bucket.iter()
            .find(|(k, _)| *k == *key)
            .map(|(_, v)| v)
    )
}
#}</code></pre></pre>
<p>事實上，這個 <code>get</code> 不是非常方便使用，當我們透過 <code>HashMep::get</code> 搜尋特定鍵時，必須傳入一模一樣的型別，例如 <code>HashMap&lt;&amp;str, u8&gt;</code> 就只能透過相同的 borrowed value <code>&amp;str</code> 搜索，而不能透過 owned value <code>&amp;String</code> 尋找，就算兩個型別可無痛轉換也無法。而 Rust 標準函式庫有做到這一點，因為其泛型參數 <code>K</code> 實作了 <a href="https://doc.rust-lang.org/stable/std/borrow/trait.Borrow.html">Borrow</a> trait，抽象化 owned 與 borrowed 間的型別，讓呼叫端無論傳 owned 或 borrowed 型別都可以有相同的行為。</p>
<blockquote>
<p>歡迎直接貢獻，將這段程式改為符合人因工程，方便使用的版本。</p>
</blockquote>
<!--  -->
<blockquote>
<p><code>fn get_mut()</code> 與 <code>fn get()</code> 的差異只在於呼叫了 <code>self.bucket.get_mut</code> 取得 mutable reference，這裡就不多做說明。</p>
</blockquote>
<a class="header" href="#a插入與刪除元素" id="a插入與刪除元素"><h3>插入與刪除元素</h3></a>
<p>插入與刪除比較特別，需要做些額外的功夫：</p>
<ul>
<li>在操作完成之後需依據操作結果增減 <code>HashMap.len</code>，確保 <code>len</code> 永遠記錄正確的鍵值對數目。</li>
<li>在執行插入之前，需額外「動態調整」儲存空間，確保記憶體配置足夠空間新增元素。</li>
</ul>
<p>先來看看刪除怎麼實作。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn remove(&amp;mut self, key: &amp;K) -&gt; Option&lt;V&gt; {
    let index = self.make_hash(key);                    // 1
    self.buckets.get_mut(index).and_then(|bucket| {     // 2
        bucket.iter_mut()
            .position(|(k, _)| *k == *key)
            .map(|index| bucket.swap_remove(index).1)
    }).map(|v| {                                        // 3
        self.len -= 1; // Length decreases by one.
        v
    })
}
#}</code></pre></pre>
<ol>
<li>所有涉及搜尋的操作，第一步一定是計算雜湊值。</li>
<li>建立 mutable 的迭代器，利用 <a href="https://doc.rust-lang.org/stable/std/iter/trait.Iterator.html#method.position"><code>posiion</code></a> 找到對應的鍵值對，再呼叫 <code>Vec::swap_remove</code> 移除。</li>
<li>前一步驟若有 return value 產生，表示移除一個元素，因此 <code>self.len</code> 需手動減一。</li>
</ol>
<blockquote>
<p><code>Vec::swap_remove</code> 不需要 resize array，而是取得最後一個元素填補該空間，由於雜湊表的排序不重要，我們選擇 <code>swap_remove</code> 減少一點開銷。</p>
</blockquote>
<p>而插入與移除非常相似。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn insert(&amp;mut self, key: K, value: V) -&gt; Option&lt;V&gt; {
    self.try_resize();                                      // 1
    let index = self.make_hash(&amp;key);                       // 2
    self.buckets.get_mut(index).and_then(|bucket|
        match bucket.iter_mut().find(|(k, _)| *k == key) {  // 3
            Some((_ , v)) =&gt;  Some(mem::replace(v, value)), // 3.1
            None =&gt; {                                       // 3.2
                bucket.push((key , value));
                None
            }
        }
    ).or_else(|| { //  Length increase by one.              // 4
        self.len += 1;
        None
    })
}
#}</code></pre></pre>
<ol>
<li>嘗試調整雜湊表大小，以確保 load factor 在閾值之間。</li>
<li>同樣地，根據鍵計算雜湊值，以取得對應的內部 bucket 位置。</li>
<li>迭代整個 bucket 尋找鍵相同的鍵值對。
<ol>
<li>若找到，使用 <a href="https://doc.rust-lang.org/stable/std/mem/fn.replace.html"><code>mem::replace</code></a> 取代資料部分，不需取代整個鍵值對。</li>
<li>若找無，則新增一組新鍵值對到該 bucket 中。</li>
</ol>
</li>
<li>決定是否該將長度記錄加一。若插入操作實際上是更新（update）原有鍵值對的資料，則會回傳被更新的舊資料 <code>Some((K, V))</code>；若是實際新增元素（push），我們回傳一個 <code>None</code>，<code>or_else</code> 就可以根據 <code>None</code> 判斷需要將長度加一。</li>
</ol>
<a class="header" href="#a動態調整儲存空間" id="a動態調整儲存空間"><h3>動態調整儲存空間</h3></a>
<p>動態調整儲存空間大概是整個實作中最 tricky 的一部分。首先，我們需要知道</p>
<ul>
<li>容器內鍵值對的總數：透過 <code>self.len</code>，我們將取得 <code>self.len</code> 的邏輯包裝在 <code>fn len(&amp;self)</code>，以免未來長度移動至別處儲存計算。</li>
<li>容器內 bucket 的總數：計算 <code>self.bucket.len()</code>，同樣地，將之包裝在 <code>fn bucket_count(&amp;self)</code>，並開放給外界呼叫。</li>
<li>Load factor 閾值：記錄在 <code>const LOAD_FACTOR</code>，設定為 0.75。</li>
</ul>
<p>前情提要完畢，接下來就是程式碼的部分了。</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
fn try_resize(&amp;mut self) {
    let entry_count = self.len();                               // 1
    let capacity = self.bucket_count();

    // Initialization.
    if capacity == 0 {                                          // 2
        self.buckets.push(Bucket::new());
        return
    }

    if entry_count as f64 / capacity as f64 &gt; LOAD_FACTOR {     // 3
        // Resize. Rehash. Reallocate!
        let mut new_map = Self::with_capacity(capacity &lt;&lt; 1);   // 4
        self.buckets.iter_mut()                                 // 5
            .flat_map(|bucket| mem::replace(bucket, vec![]))
            .for_each(|(k, v)| { new_map.insert(k, v); });
        *self = new_map;                                        // 6
    }
}
#}</code></pre></pre>
<ol>
<li>取得所有需要用到的長度資料。</li>
<li>若當前容量為 0，表示尚未新增任何元素，我們 push 一個空 bucket 進去，讓其他操作可以正常新增鍵值對。</li>
<li>判斷 load factor，決定需不需要動態調整大小。</li>
<li>透過 <code>HashMap::with_capacity</code> 建立容量兩倍大的空雜湊表。</li>
<li>開始迭代舊的 bucket，並利用 <a href="https://doc.rust-lang.org/stable/std/iter/trait.Iterator.html#method.flat_map"><code>flat_map</code></a> 打平 nested vector，在利用 <a href="https://doc.rust-lang.org/stable/std/iter/trait.Iterator.html#method.for_each"><code>for_each</code></a> 將每個元素重新 insert 到新雜湊表。</li>
<li>把 <code>self</code> 的值指向新雜湊表，舊雜湊表的記憶體空間會被釋放。</li>
</ol>
<a class="header" href="#a效能-17" id="a效能-17"><h2>效能</h2></a>
<p>以陣列實作的雜湊表各操作複雜度如下</p>
<table><thead><tr><th> Operation    </th><th> Best case    </th><th> Worst case </th></tr></thead><tbody>
<tr><td> add(k, v)    </td><td> $O(1)$~  </td><td> $O(n)$ </td></tr>
<tr><td> update(k, v) </td><td> $O(1)$   </td><td> $O(n)$ </td></tr>
<tr><td> remove(k)    </td><td> $O(1)$~  </td><td> $O(n)$ </td></tr>
<tr><td> search(k)    </td><td> $O(1)$   </td><td> $O(n)$ </td></tr>
</tbody></table>
<blockquote>
<p>$n$：資料筆數。<br />
$k$：欲綁定資料的鍵。<br />
$v$：欲與鍵綁定的資料。<br />
<strong>~</strong>：平攤後的複雜度（amortized）。</p>
</blockquote>
<a class="header" href="#a時間複雜度" id="a時間複雜度"><h3>時間複雜度</h3></a>
<p>在預期情況下，只要雜湊函數品質穩定，大部分操作都可達到在常數時間， 但由於部分操作，尤其是新增或刪除元素的操作，會需要調整 bucket array 的空間，重新配置記憶體空間，所以需要平攤計算複雜度。</p>
<p>而最差複雜度出現在每個元素都發生雜湊碰撞。若使用 open addressing 處理碰撞，則會把雜湊表配置的每個位置都填滿，而所有操作都從同個位置開始，搜尋對應的鍵，複雜度與陣列的線性搜索相同為 $O(n)$；若使用 separate chaining，碰撞代表所有元素都會在同一個 bucket 裡面，也就是只有一個 bucket 上會有一個長度為 <em>n</em> ，被塞滿的陣列或鏈結串列，結果同樣是線性搜索的 $O(n)$。</p>
<p>我們嘗試使用數學表示搜索的複雜度。另</p>
<ul>
<li>$n$：已放入雜湊表內的資料總數。</li>
<li>$k$：雜湊表配置的儲存空間（bucket 總數）。</li>
<li>$\text{load factor} = \frac{n}{k}$
<ul>
<li>預期每個 bucket 儲存的資料筆數</li>
</ul>
</li>
</ul>
<p>則預期執行時間為</p>
<p>$$\Theta(1+\frac{n}{k}) = O(1) \ \text{ if } \frac{n}{k} = O(1)$$</p>
<p>而 <strong>1</strong> 為計算雜湊與取得索引（random access）的執行時間，$\frac{n}{k}$ 則是搜尋陣列的執行時間。只要 load factor 越接近 $n$，執行時間就相對增加。</p>
<a class="header" href="#a空間複雜度" id="a空間複雜度"><h3>空間複雜度</h3></a>
<p>雜湊表的空間複雜度取決於實作預先配置的陣列大小，並與維持 <em>load factor</em> 息息相關。一般來說，仍與資料筆數成線性關係，因此空間複雜度只有資料本身 $O(n)$。而以 separate chaining 會額外配置陣列或鏈結串列儲存碰撞元素，理論上需負擔更多額外的指標儲存空間。</p>
<a class="header" href="#a參考資料-23" id="a參考資料-23"><h2>參考資料</h2></a>
<ul>
<li><a href="https://doc.rust-lang.org/stable/std/collections/hash_map/index.html">Rust Documentation: HashMap</a></li>
<li><a href="https://en.wikipedia.org/wiki/Hash_table">Wiki: Hash table</a></li>
<li><a href="https://en.wikipedia.org/wiki/Open_addressing">Wiki: Open addressing</a></li>
<li><a href="https://algs4.cs.princeton.edu/34hash/">Algorithms, 4th Edition by R. Sedgewick and K. Wayne: 3.4 Hash Tables</a></li>
<li><a href="https://courses.csail.mit.edu/6.006/fall11/notes.shtml">MIT 6.006: Introduction to Algorithms, fall 2011: Unit 3 Hashing</a></li>
<li>Map graph by Jorge Stolfi <a href="http://creativecommons.org/licenses/by-sa/3.0/">CC-BY-SA-3.0</a> via Wikimedia Commons.</li>
</ul>
<a class="header" href="#a有序映射表-ordered-map-1" id="a有序映射表-ordered-map-1"><h1>有序映射表 Ordered Map</h1></a>
<p>有特定排序方式的映射表。</p>
<a class="header" href="#a多重映射表-multimap-1" id="a多重映射表-multimap-1"><h1>多重映射表 Multimap</h1></a>
<p>允許鍵值對重複，一個鍵可對應多個值（一對多）映射表。</p>
<a class="header" href="#a集合-set-1" id="a集合-set-1"><h1>集合 Set</h1></a>
<p>只有鍵沒有值的映射表。</p>
<a class="header" href="#contributing" id="contributing"><h1>Contributing</h1></a>
<p>Thank you for your interest in contributing to Rust Algorithm Club! We appreciate all kinds of contributions. Here are some tips to contribute.</p>
<ul>
<li>Please search <a href="https://github.com/weihanglo/rust-algorithm-club/search?q=&amp;type=Issues&amp;utf8=%E2%9C%93">existing issues</a> before filing a new one, as maybe there are some similar issues already reported.</li>
<li>If there is no duplicate issue, feel free to report bugs or send pull requests.</li>
<li>When making changes on features under construction 🚧, file an issue to notify others you would take it.</li>
</ul>
<p>MIT License</p>
<p>Copyright (c) 2017 - 2018 Weihang Lo</p>
<p>Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the “Software”), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:</p>
<p>The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.</p>
<p>THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        

                        

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                

                
            </nav>

        </div>

        

        

        
        <script src="ace.js" type="text/javascript" charset="utf-8"></script>
        <script src="editor.js" type="text/javascript" charset="utf-8"></script>
        <script src="mode-rust.js" type="text/javascript" charset="utf-8"></script>
        <script src="theme-dawn.js" type="text/javascript" charset="utf-8"></script>
        <script src="theme-tomorrow_night.js" type="text/javascript" charset="utf-8"></script>
        

        
        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        

        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        

        
        
        <script type="text/javascript">
        window.addEventListener('load', function() {
            MathJax.Hub.Register.StartupHook('End', function() {
                window.setTimeout(window.print, 100);
            });
        });
        </script>
        
        

    </body>
</html>
